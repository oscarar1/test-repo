{"version":3,"file":"index.cjs.js","sources":["../src/stages/generate/helpers.ts","../src/stages/generate/techdocs.ts","../src/stages/generate/generators.ts","../src/git-auth.ts","../src/default-branch.ts","../src/helpers.ts","../src/stages/prepare/dir.ts","../src/stages/prepare/commonGit.ts","../src/stages/prepare/url.ts","../src/stages/prepare/preparers.ts","../src/stages/publish/helpers.ts","../src/stages/publish/awsS3.ts","../src/stages/publish/azureBlobStorage.ts","../src/stages/publish/googleStorage.ts","../src/stages/publish/local.ts","../src/stages/publish/openStackSwift.ts","../src/stages/publish/publish.ts"],"sourcesContent":["/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity } from '@backstage/catalog-model';\nimport { spawn } from 'child_process';\nimport fs from 'fs-extra';\nimport yaml, { DEFAULT_SCHEMA, Type } from 'js-yaml';\nimport { isAbsolute, normalize } from 'path';\nimport { PassThrough, Writable } from 'stream';\nimport { Logger } from 'winston';\nimport { ParsedLocationAnnotation } from '../../helpers';\nimport { RemoteProtocol } from '../prepare/types';\nimport { SupportedGeneratorKey } from './types';\n\n// TODO: Implement proper support for more generators.\nexport function getGeneratorKey(entity: Entity): SupportedGeneratorKey {\n  if (!entity) {\n    throw new Error('No entity provided');\n  }\n\n  return 'techdocs';\n}\n\nexport type RunCommandOptions = {\n  command: string;\n  args: string[];\n  options: object;\n  logStream?: Writable;\n};\n\n/**\n *\n * @param options the options object\n * @param options.command the command to run\n * @param options.args the arguments to pass the command\n * @param options.options options used in spawn\n * @param options.logStream the log streamer to capture log messages\n */\nexport const runCommand = async ({\n  command,\n  args,\n  options,\n  logStream = new PassThrough(),\n}: RunCommandOptions) => {\n  await new Promise<void>((resolve, reject) => {\n    const process = spawn(command, args, options);\n\n    process.stdout.on('data', stream => {\n      logStream.write(stream);\n    });\n\n    process.stderr.on('data', stream => {\n      logStream.write(stream);\n    });\n\n    process.on('error', error => {\n      return reject(error);\n    });\n\n    process.on('close', code => {\n      if (code !== 0) {\n        return reject(`Command ${command} failed, exit code: ${code}`);\n      }\n      return resolve();\n    });\n  });\n};\n\n/**\n * Return true if mkdocs can compile docs with provided repo_url\n *\n * Valid repo_url examples in mkdocs.yml\n * - https://github.com/backstage/backstage\n * - https://gitlab.com/org/repo/\n * - http://github.com/backstage/backstage\n * - A http(s) protocol URL to the root of the repository\n *\n * Invalid repo_url examples in mkdocs.yml\n * - https://github.com/backstage/backstage/blob/master/plugins/techdocs-backend/examples/documented-component\n * - (anything that is not valid as described above)\n *\n * @param {string} repoUrl URL supposed to be used as repo_url in mkdocs.yml\n * @param {RemoteProtocol} locationType Type of source code host - github, gitlab, dir, url, etc.\n * @returns {boolean}\n */\nexport const isValidRepoUrlForMkdocs = (\n  repoUrl: string,\n  locationType: RemoteProtocol,\n): boolean => {\n  // Trim trailing slash\n  const cleanRepoUrl = repoUrl.replace(/\\/$/, '');\n\n  if (locationType === 'github' || locationType === 'gitlab') {\n    // A valid repoUrl to the root of the repository will be split into 5 strings if split using the / delimiter.\n    // We do not want URLs which have more than that number of forward slashes since they will signify a non-root location\n    // Note: This is not the best possible implementation but will work most of the times.. Feel free to improve or\n    // highlight edge cases.\n    return cleanRepoUrl.split('/').length === 5;\n  }\n\n  return false;\n};\n\n/**\n * Return a valid URL of the repository used in backstage.io/techdocs-ref annotation.\n * Return undefined if the `target` is not valid in context of repo_url in mkdocs.yml\n * Alter URL so that it is a valid repo_url config in mkdocs.yml\n *\n * @param {ParsedLocationAnnotation} parsedLocationAnnotation Object with location url and type\n * @returns {string | undefined}\n */\nexport const getRepoUrlFromLocationAnnotation = (\n  parsedLocationAnnotation: ParsedLocationAnnotation,\n): string | undefined => {\n  const { type: locationType, target } = parsedLocationAnnotation;\n\n  // Add more options from the RemoteProtocol type of parsedLocationAnnotation.type here\n  // when TechDocs supports more hosts and if mkdocs can generated an Edit URL for them.\n  const supportedHosts = ['github', 'gitlab'];\n\n  if (supportedHosts.includes(locationType)) {\n    // Trim .git or .git/ from the end of repository url\n    return target.replace(/.git\\/*$/, '');\n  }\n\n  return undefined;\n};\n\nclass UnknownTag {\n  constructor(public readonly data: any, public readonly type?: string) {}\n}\n\nconst MKDOCS_SCHEMA = DEFAULT_SCHEMA.extend([\n  new Type('', {\n    kind: 'scalar',\n    multi: true,\n    representName: o => (o as UnknownTag).type,\n    represent: o => (o as UnknownTag).data ?? '',\n    instanceOf: UnknownTag,\n    construct: (data: string, type?: string) => new UnknownTag(data, type),\n  }),\n]);\n\n/**\n * Validating mkdocs config file for incorrect/insecure values\n * Throws on invalid configs\n *\n * @param {string} mkdocsYmlPath Absolute path to mkdocs.yml or equivalent of a docs site\n */\nexport const validateMkdocsYaml = async (mkdocsYmlPath: string) => {\n  let mkdocsYmlFileString;\n  try {\n    mkdocsYmlFileString = await fs.readFile(mkdocsYmlPath, 'utf8');\n  } catch (error) {\n    throw new Error(\n      `Could not read MkDocs YAML config file ${mkdocsYmlPath} before for validation: ${error.message}`,\n    );\n  }\n\n  const mkdocsYml: any = yaml.load(mkdocsYmlFileString, {\n    schema: MKDOCS_SCHEMA,\n  });\n  if (mkdocsYml.docs_dir && isAbsolute(normalize(mkdocsYml.docs_dir))) {\n    throw new Error(\n      \"docs_dir configuration value in mkdocs can't be an absolute directory path for security reasons. Use relative paths instead which are resolved relative to your mkdocs.yml file location.\",\n    );\n  }\n};\n\n/**\n * Update the mkdocs.yml file before TechDocs generator uses it to generate docs site.\n *\n * List of tasks:\n * - Add repo_url if it does not exists\n * If mkdocs.yml has a repo_url, the generated docs site gets an Edit button on the pages by default.\n * If repo_url is missing in mkdocs.yml, we will use techdocs annotation of the entity to possibly get\n * the repository URL.\n *\n * This function will not throw an error since this is not critical to the whole TechDocs pipeline.\n * Instead it will log warnings if there are any errors in reading, parsing or writing YAML.\n *\n * @param {string} mkdocsYmlPath Absolute path to mkdocs.yml or equivalent of a docs site\n * @param {Logger} logger\n * @param {ParsedLocationAnnotation} parsedLocationAnnotation Object with location url and type\n */\nexport const patchMkdocsYmlPreBuild = async (\n  mkdocsYmlPath: string,\n  logger: Logger,\n  parsedLocationAnnotation: ParsedLocationAnnotation,\n) => {\n  let mkdocsYmlFileString;\n  try {\n    mkdocsYmlFileString = await fs.readFile(mkdocsYmlPath, 'utf8');\n  } catch (error) {\n    logger.warn(\n      `Could not read MkDocs YAML config file ${mkdocsYmlPath} before running the generator: ${error.message}`,\n    );\n    return;\n  }\n\n  let mkdocsYml: any;\n  try {\n    mkdocsYml = yaml.load(mkdocsYmlFileString, { schema: MKDOCS_SCHEMA });\n\n    // mkdocsYml should be an object type after successful parsing.\n    // But based on its type definition, it can also be a string or undefined, which we don't want.\n    if (typeof mkdocsYml === 'string' || typeof mkdocsYml === 'undefined') {\n      throw new Error('Bad YAML format.');\n    }\n  } catch (error) {\n    logger.warn(\n      `Error in parsing YAML at ${mkdocsYmlPath} before running the generator. ${error.message}`,\n    );\n    return;\n  }\n\n  // Add repo_url to mkdocs.yml if it is missing. This will enable the Page edit button generated by MkDocs.\n  if (!('repo_url' in mkdocsYml)) {\n    const repoUrl = getRepoUrlFromLocationAnnotation(parsedLocationAnnotation);\n    if (repoUrl !== undefined) {\n      // mkdocs.yml will not build with invalid repo_url. So, make sure it is valid.\n      if (isValidRepoUrlForMkdocs(repoUrl, parsedLocationAnnotation.type)) {\n        mkdocsYml.repo_url = repoUrl;\n      }\n    }\n  }\n\n  try {\n    await fs.writeFile(\n      mkdocsYmlPath,\n      yaml.dump(mkdocsYml, { schema: MKDOCS_SCHEMA }),\n      'utf8',\n    );\n  } catch (error) {\n    logger.warn(\n      `Could not write to ${mkdocsYmlPath} after updating it before running the generator. ${error.message}`,\n    );\n    return;\n  }\n};\n\n/**\n * Update the techdocs_metadata.json to add a new build timestamp metadata. Create the .json file if it doesn't exist.\n *\n * @param {string} techdocsMetadataPath File path to techdocs_metadata.json\n */\nexport const addBuildTimestampMetadata = async (\n  techdocsMetadataPath: string,\n  logger: Logger,\n): Promise<void> => {\n  // check if file exists, create if it does not.\n  try {\n    await fs.access(techdocsMetadataPath, fs.constants.F_OK);\n  } catch (err) {\n    // Bootstrap file with empty JSON\n    await fs.writeJson(techdocsMetadataPath, JSON.parse('{}'));\n  }\n  // check if valid Json\n  let json;\n  try {\n    json = await fs.readJson(techdocsMetadataPath);\n  } catch (err) {\n    const message = `Invalid JSON at ${techdocsMetadataPath} with error ${err.message}`;\n    logger.error(message);\n    throw new Error(message);\n  }\n\n  json.build_timestamp = Date.now();\n  await fs.writeJson(techdocsMetadataPath, json);\n  return;\n};\n\n/**\n * Update the techdocs_metadata.json to add etag of the prepared tree (e.g. commit SHA or actual Etag of the resource).\n * This is helpful to check if a TechDocs site in storage has gone outdated, without maintaining an in-memory build info\n * per Backstage instance.\n *\n * @param {string} techdocsMetadataPath File path to techdocs_metadata.json\n * @param {string} etag\n */\nexport const storeEtagMetadata = async (\n  techdocsMetadataPath: string,\n  etag: string,\n): Promise<void> => {\n  const json = await fs.readJson(techdocsMetadataPath);\n  json.etag = etag;\n  await fs.writeJson(techdocsMetadataPath, json);\n};\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ContainerRunner } from '@backstage/backend-common';\nimport { Config } from '@backstage/config';\nimport path from 'path';\nimport { PassThrough } from 'stream';\nimport { Logger } from 'winston';\nimport {\n  addBuildTimestampMetadata,\n  patchMkdocsYmlPreBuild,\n  runCommand,\n  storeEtagMetadata,\n  validateMkdocsYaml,\n} from './helpers';\nimport { GeneratorBase, GeneratorRunOptions } from './types';\n\ntype TechdocsGeneratorOptions = {\n  // This option enables users to configure if they want to use TechDocs container\n  // or generate without the container.\n  // This is used to avoid running into Docker in Docker environment.\n  runGeneratorIn: string;\n};\n\nconst createStream = (): [string[], PassThrough] => {\n  const log = [] as Array<string>;\n\n  const stream = new PassThrough();\n  stream.on('data', chunk => {\n    const textValue = chunk.toString().trim();\n    if (textValue?.length > 1) log.push(textValue);\n  });\n\n  return [log, stream];\n};\n\nexport class TechdocsGenerator implements GeneratorBase {\n  private readonly logger: Logger;\n  private readonly containerRunner: ContainerRunner;\n  private readonly options: TechdocsGeneratorOptions;\n\n  constructor({\n    logger,\n    containerRunner,\n    config,\n  }: {\n    logger: Logger;\n    containerRunner: ContainerRunner;\n    config: Config;\n  }) {\n    this.logger = logger;\n    this.options = {\n      runGeneratorIn:\n        config.getOptionalString('techdocs.generators.techdocs') ?? 'docker',\n    };\n    this.containerRunner = containerRunner;\n  }\n\n  public async run({\n    inputDir,\n    outputDir,\n    parsedLocationAnnotation,\n    etag,\n  }: GeneratorRunOptions): Promise<void> {\n    const [log, logStream] = createStream();\n\n    // TODO: In future mkdocs.yml can be mkdocs.yaml. So, use a config variable here to find out\n    // the correct file name.\n    // Do some updates to mkdocs.yml before generating docs e.g. adding repo_url\n    const mkdocsYmlPath = path.join(inputDir, 'mkdocs.yml');\n    if (parsedLocationAnnotation) {\n      await patchMkdocsYmlPreBuild(\n        mkdocsYmlPath,\n        this.logger,\n        parsedLocationAnnotation,\n      );\n    }\n\n    await validateMkdocsYaml(mkdocsYmlPath);\n\n    // Directories to bind on container\n    const mountDirs = {\n      [inputDir]: '/input',\n      [outputDir]: '/output',\n    };\n\n    try {\n      switch (this.options.runGeneratorIn) {\n        case 'local':\n          await runCommand({\n            command: 'mkdocs',\n            args: ['build', '-d', outputDir, '-v'],\n            options: {\n              cwd: inputDir,\n            },\n            logStream,\n          });\n          this.logger.info(\n            `Successfully generated docs from ${inputDir} into ${outputDir} using local mkdocs`,\n          );\n          break;\n        case 'docker':\n          await this.containerRunner.runContainer({\n            imageName: 'spotify/techdocs',\n            args: ['build', '-d', '/output'],\n            logStream,\n            mountDirs,\n            workingDir: '/input',\n            // Set the home directory inside the container as something that applications can\n            // write to, otherwise they will just fail trying to write to /\n            envVars: { HOME: '/tmp' },\n          });\n          this.logger.info(\n            `Successfully generated docs from ${inputDir} into ${outputDir} using techdocs-container`,\n          );\n          break;\n        default:\n          throw new Error(\n            `Invalid config value \"${this.options.runGeneratorIn}\" provided in 'techdocs.generators.techdocs'.`,\n          );\n      }\n    } catch (error) {\n      this.logger.debug(\n        `Failed to generate docs from ${inputDir} into ${outputDir}`,\n      );\n      this.logger.error(`Build failed with error: ${log}`);\n      throw new Error(\n        `Failed to generate docs from ${inputDir} into ${outputDir} with error ${error.message}`,\n      );\n    }\n\n    /**\n     * Post Generate steps\n     */\n\n    // Add build timestamp to techdocs_metadata.json\n    // Creates techdocs_metadata.json if file does not exist.\n    await addBuildTimestampMetadata(\n      path.join(outputDir, 'techdocs_metadata.json'),\n      this.logger,\n    );\n\n    // Add etag of the prepared tree to techdocs_metadata.json\n    // Assumes that the file already exists.\n    if (etag) {\n      await storeEtagMetadata(\n        path.join(outputDir, 'techdocs_metadata.json'),\n        etag,\n      );\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ContainerRunner } from '@backstage/backend-common';\nimport { Entity } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { Logger } from 'winston';\nimport { getGeneratorKey } from './helpers';\nimport { TechdocsGenerator } from './techdocs';\nimport {\n  GeneratorBase,\n  GeneratorBuilder,\n  SupportedGeneratorKey,\n} from './types';\n\nexport class Generators implements GeneratorBuilder {\n  private generatorMap = new Map<SupportedGeneratorKey, GeneratorBase>();\n\n  static async fromConfig(\n    config: Config,\n    {\n      logger,\n      containerRunner,\n    }: { logger: Logger; containerRunner: ContainerRunner },\n  ): Promise<GeneratorBuilder> {\n    const generators = new Generators();\n\n    const techdocsGenerator = new TechdocsGenerator({\n      logger,\n      containerRunner,\n      config,\n    });\n    generators.register('techdocs', techdocsGenerator);\n\n    return generators;\n  }\n\n  register(generatorKey: SupportedGeneratorKey, generator: GeneratorBase) {\n    this.generatorMap.set(generatorKey, generator);\n  }\n\n  get(entity: Entity): GeneratorBase {\n    const generatorKey = getGeneratorKey(entity);\n    const generator = this.generatorMap.get(generatorKey);\n\n    if (!generator) {\n      throw new Error(`No generator registered for entity: \"${generatorKey}\"`);\n    }\n\n    return generator;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport parseGitUrl from 'git-url-parse';\nimport { Config } from '@backstage/config';\nimport {\n  readGitHubIntegrationConfigs,\n  readGitLabIntegrationConfigs,\n  readAzureIntegrationConfigs,\n  GitHubIntegrationConfig,\n  GitLabIntegrationConfig,\n  AzureIntegrationConfig,\n} from '@backstage/integration';\n\nexport function getGitHost(url: string): string {\n  const { resource } = parseGitUrl(url);\n  return resource;\n}\n\nexport function getGitRepoType(url: string): string {\n  const typeMapping = [\n    { url: /github*/g, type: 'github' },\n    { url: /gitlab*/g, type: 'gitlab' },\n    { url: /azure*/g, type: 'azure/api' },\n  ];\n\n  const type = typeMapping.filter(item => item.url.test(url))[0]?.type;\n\n  return type;\n}\n\nexport const getGitHubIntegrationConfig = (\n  config: Config,\n  host: string,\n): GitHubIntegrationConfig => {\n  const allGitHubConfigs = readGitHubIntegrationConfigs(\n    config.getOptionalConfigArray('integrations.github') ?? [],\n  );\n  const gitHubIntegrationConfig = allGitHubConfigs.find(v => v.host === host);\n  if (!gitHubIntegrationConfig) {\n    throw new Error(`Unable to locate GitHub integration for the host ${host}`);\n  }\n  return gitHubIntegrationConfig;\n};\n\nexport const getGitLabIntegrationConfig = (\n  config: Config,\n  host: string,\n): GitLabIntegrationConfig => {\n  const allGitLabConfigs = readGitLabIntegrationConfigs(\n    config.getOptionalConfigArray('integrations.gitlab') ?? [],\n  );\n  const gitLabIntegrationConfig = allGitLabConfigs.find(v => v.host === host);\n  if (!gitLabIntegrationConfig) {\n    throw new Error(`Unable to locate GitLab integration for the host ${host}`);\n  }\n  return gitLabIntegrationConfig;\n};\n\nexport const getAzureIntegrationConfig = (\n  config: Config,\n  host: string,\n): AzureIntegrationConfig => {\n  const allAzureIntegrationConfig = readAzureIntegrationConfigs(\n    config.getOptionalConfigArray('integrations.azure') ?? [],\n  );\n  const azureIntegrationConfig = allAzureIntegrationConfig.find(\n    v => v.host === host,\n  );\n  if (!azureIntegrationConfig) {\n    throw new Error(`Unable to locate Azure integration for the host ${host}`);\n  }\n  return azureIntegrationConfig;\n};\n\nexport const getTokenForGitRepo = async (\n  repositoryUrl: string,\n  config: Config,\n): Promise<string | undefined> => {\n  const host = getGitHost(repositoryUrl);\n  const type = getGitRepoType(repositoryUrl);\n\n  try {\n    switch (type) {\n      case 'github':\n        return getGitHubIntegrationConfig(config, host).token;\n      case 'gitlab':\n        return getGitLabIntegrationConfig(config, host).token;\n      case 'azure/api':\n        return getAzureIntegrationConfig(config, host).token;\n      default:\n        throw new Error('Failed to get repository type');\n    }\n  } catch (error) {\n    throw error;\n  }\n};\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport fetch from 'cross-fetch';\nimport parseGitUrl from 'git-url-parse';\nimport { Config } from '@backstage/config';\nimport {\n  getGitHubRequestOptions,\n  getGitLabRequestOptions,\n  getAzureRequestOptions,\n} from '@backstage/integration';\nimport {\n  getGitHost,\n  getGitRepoType,\n  getGitHubIntegrationConfig,\n  getGitLabIntegrationConfig,\n  getAzureIntegrationConfig,\n} from './git-auth';\n\ninterface IGitlabBranch {\n  name: string;\n  merged: boolean;\n  protected: boolean;\n  default: boolean;\n  developers_can_push: boolean;\n  developers_can_merge: boolean;\n  can_push: boolean;\n  web_url: string;\n  commit: {\n    author_email: string;\n    author_name: string;\n    authored_date: string;\n    committed_date: string;\n    committer_email: string;\n    committer_name: string;\n    id: string;\n    short_id: string;\n    title: string;\n    message: string;\n    parent_ids: string[];\n  };\n}\n\nfunction getGithubApiUrl(config: Config, url: string): URL {\n  const { resource, owner, name } = parseGitUrl(url);\n  const providerConfigs =\n    config.getOptionalConfigArray('integrations.github') ?? [];\n\n  const hostConfig = providerConfigs.filter(\n    providerConfig => providerConfig.getOptionalString('host') === resource,\n  );\n\n  const apiBaseUrl =\n    hostConfig[0]?.getOptionalString('apiBaseUrl') ?? 'https://api.github.com';\n  const apiRepos = 'repos';\n\n  return new URL(`${apiBaseUrl}/${apiRepos}/${owner}/${name}`);\n}\n\nfunction getGitlabApiUrl(url: string): URL {\n  const { protocol, resource, full_name: fullName } = parseGitUrl(url);\n  const apiProjectsBasePath = 'api/v4/projects';\n  const project = encodeURIComponent(fullName);\n  const branches = 'repository/branches';\n\n  return new URL(\n    `${protocol}://${resource}/${apiProjectsBasePath}/${project}/${branches}`,\n  );\n}\n\nfunction getAzureApiUrl(url: string): URL {\n  const { protocol, resource, organization, owner, name } = parseGitUrl(url);\n  const apiRepoPath = '_apis/git/repositories';\n  const apiVersion = 'api-version=6.0';\n\n  return new URL(\n    `${protocol}://${resource}/${organization}/${owner}/${apiRepoPath}/${name}?${apiVersion}`,\n  );\n}\n\nasync function getGithubDefaultBranch(\n  repositoryUrl: string,\n  config: Config,\n): Promise<string> {\n  const path = getGithubApiUrl(config, repositoryUrl).toString();\n  const host = getGitHost(repositoryUrl);\n\n  const integrationConfig = getGitHubIntegrationConfig(config, host);\n  const options = getGitHubRequestOptions(integrationConfig);\n\n  try {\n    const raw = await fetch(path, options);\n\n    if (!raw.ok) {\n      throw new Error(\n        `Failed to load url: ${raw.status} ${raw.statusText}. Make sure you have permission to repository: ${repositoryUrl}`,\n      );\n    }\n\n    const { default_branch: branch } = await raw.json();\n\n    if (!branch) {\n      throw new Error('Not found github default branch');\n    }\n\n    return branch;\n  } catch (error) {\n    throw new Error(`Failed to get github default branch: ${error}`);\n  }\n}\n\nasync function getGitlabDefaultBranch(\n  repositoryUrl: string,\n  config: Config,\n): Promise<string> {\n  const path = getGitlabApiUrl(repositoryUrl).toString();\n  const host = getGitHost(repositoryUrl);\n\n  const integrationConfig = getGitLabIntegrationConfig(config, host);\n  const options = getGitLabRequestOptions(integrationConfig);\n\n  try {\n    const raw = await fetch(path, options);\n\n    if (!raw.ok) {\n      throw new Error(\n        `Failed to load url: ${raw.status} ${raw.statusText}. Make sure you have permission to repository: ${repositoryUrl}`,\n      );\n    }\n\n    const result = await raw.json();\n    const { name } = (result || []).find(\n      (branch: IGitlabBranch) => branch.default === true,\n    );\n\n    if (!name) {\n      throw new Error('Not found gitlab default branch');\n    }\n\n    return name;\n  } catch (error) {\n    throw new Error(`Failed to get gitlab default branch: ${error}`);\n  }\n}\n\nasync function getAzureDefaultBranch(\n  repositoryUrl: string,\n  config: Config,\n): Promise<string> {\n  const path = getAzureApiUrl(repositoryUrl).toString();\n  const host = getGitHost(repositoryUrl);\n\n  const integrationConfig = getAzureIntegrationConfig(config, host);\n  const options = getAzureRequestOptions(integrationConfig);\n\n  try {\n    const urlResponse = await fetch(path, options);\n    if (!urlResponse.ok) {\n      throw new Error(\n        `Failed to load url: ${urlResponse.status} ${urlResponse.statusText}. Make sure you have permission to repository: ${repositoryUrl}`,\n      );\n    }\n    const urlResult = await urlResponse.json();\n\n    const idResponse = await fetch(urlResult.url, options);\n    if (!idResponse.ok) {\n      throw new Error(\n        `Failed to load url: ${idResponse.status} ${idResponse.statusText}. Make sure you have permission to repository: ${urlResult.repository.url}`,\n      );\n    }\n    const idResult = await idResponse.json();\n    const name = idResult.defaultBranch;\n\n    if (!name) {\n      throw new Error('Not found Azure DevOps default branch');\n    }\n\n    return name;\n  } catch (error) {\n    throw new Error(`Failed to get Azure DevOps default branch: ${error}`);\n  }\n}\n\nexport const getDefaultBranch = async (\n  repositoryUrl: string,\n  config: Config,\n): Promise<string> => {\n  const type = getGitRepoType(repositoryUrl);\n\n  try {\n    switch (type) {\n      case 'github':\n        return await getGithubDefaultBranch(repositoryUrl, config);\n      case 'gitlab':\n        return await getGitlabDefaultBranch(repositoryUrl, config);\n      case 'azure/api':\n        return await getAzureDefaultBranch(repositoryUrl, config);\n\n      default:\n        throw new Error('Failed to get repository type');\n    }\n  } catch (error) {\n    throw error;\n  }\n};\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Git, UrlReader } from '@backstage/backend-common';\nimport { InputError } from '@backstage/errors';\nimport { Entity, parseLocationReference } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport fs from 'fs-extra';\nimport parseGitUrl from 'git-url-parse';\nimport os from 'os';\nimport path from 'path';\nimport { Logger } from 'winston';\nimport { getDefaultBranch } from './default-branch';\nimport { getGitRepoType, getTokenForGitRepo } from './git-auth';\nimport { PreparerResponse, RemoteProtocol } from './stages/prepare/types';\n\nexport type ParsedLocationAnnotation = {\n  type: RemoteProtocol;\n  target: string;\n};\n\nexport const parseReferenceAnnotation = (\n  annotationName: string,\n  entity: Entity,\n): ParsedLocationAnnotation => {\n  const annotation = entity.metadata.annotations?.[annotationName];\n  if (!annotation) {\n    throw new InputError(\n      `No location annotation provided in entity: ${entity.metadata.name}`,\n    );\n  }\n\n  const { type, target } = parseLocationReference(annotation);\n  return {\n    type: type as RemoteProtocol,\n    target,\n  };\n};\n\nexport const getLocationForEntity = (\n  entity: Entity,\n): ParsedLocationAnnotation => {\n  const { type, target } = parseReferenceAnnotation(\n    'backstage.io/techdocs-ref',\n    entity,\n  );\n\n  switch (type) {\n    case 'github':\n    case 'gitlab':\n    case 'azure/api':\n    case 'url':\n      return { type, target };\n    case 'dir':\n      if (path.isAbsolute(target)) {\n        return { type, target };\n      }\n      return parseReferenceAnnotation(\n        'backstage.io/managed-by-location',\n        entity,\n      );\n    default:\n      throw new Error(`Invalid reference annotation ${type}`);\n  }\n};\n\nexport const getGitRepositoryTempFolder = async (\n  repositoryUrl: string,\n  config: Config,\n): Promise<string> => {\n  const parsedGitLocation = parseGitUrl(repositoryUrl);\n  // removes .git from git location path\n  parsedGitLocation.git_suffix = false;\n\n  if (!parsedGitLocation.ref) {\n    parsedGitLocation.ref = await getDefaultBranch(\n      parsedGitLocation.toString('https'),\n      config,\n    );\n  }\n\n  return path.join(\n    // fs.realpathSync fixes a problem with macOS returning a path that is a symlink\n    fs.realpathSync(os.tmpdir()),\n    'backstage-repo',\n    parsedGitLocation.resource,\n    parsedGitLocation.owner,\n    parsedGitLocation.name,\n    parsedGitLocation.ref,\n  );\n};\n\nexport const checkoutGitRepository = async (\n  repoUrl: string,\n  config: Config,\n  logger: Logger,\n): Promise<string> => {\n  const parsedGitLocation = parseGitUrl(repoUrl);\n  const repositoryTmpPath = await getGitRepositoryTempFolder(repoUrl, config);\n  const token = await getTokenForGitRepo(repoUrl, config);\n\n  // Initialize a git client\n  let git = Git.fromAuth({ logger });\n\n  // Docs about why username and password are set to these specific values.\n  // https://isomorphic-git.org/docs/en/onAuth#oauth2-tokens\n  if (token) {\n    const type = getGitRepoType(repoUrl);\n    switch (type) {\n      case 'github':\n        git = Git.fromAuth({\n          username: 'x-access-token',\n          password: token,\n          logger,\n        });\n        parsedGitLocation.token = `x-access-token:${token}`;\n        break;\n      case 'gitlab':\n        git = Git.fromAuth({\n          username: 'oauth2',\n          password: token,\n          logger,\n        });\n        parsedGitLocation.token = `dummyUsername:${token}`;\n        parsedGitLocation.git_suffix = true;\n        break;\n      case 'azure/api':\n        git = Git.fromAuth({\n          username: 'notempty',\n          password: token,\n          logger: logger,\n        });\n        break;\n      default:\n        parsedGitLocation.token = `:${token}`;\n    }\n  }\n\n  // Pull from repository if it has already been cloned.\n  if (fs.existsSync(repositoryTmpPath)) {\n    try {\n      const currentBranchName = await git.currentBranch({\n        dir: repositoryTmpPath,\n      });\n\n      await git.fetch({ dir: repositoryTmpPath, remote: 'origin' });\n      await git.merge({\n        dir: repositoryTmpPath,\n        theirs: `origin/${currentBranchName}`,\n        ours: currentBranchName || undefined,\n        author: { name: 'Backstage TechDocs', email: 'techdocs@backstage.io' },\n        committer: {\n          name: 'Backstage TechDocs',\n          email: 'techdocs@backstage.io',\n        },\n      });\n      return repositoryTmpPath;\n    } catch (e) {\n      logger.info(\n        `Found error \"${e.message}\" in cached repository \"${repoUrl}\" when getting latest changes. Removing cached repository.`,\n      );\n      fs.removeSync(repositoryTmpPath);\n    }\n  }\n\n  const repositoryCheckoutUrl = parsedGitLocation.toString('https');\n\n  fs.mkdirSync(repositoryTmpPath, { recursive: true });\n  await git.clone({ url: repositoryCheckoutUrl, dir: repositoryTmpPath });\n\n  return repositoryTmpPath;\n};\n\nexport const getLastCommitTimestamp = async (\n  repositoryLocation: string,\n  logger: Logger,\n): Promise<number> => {\n  const git = Git.fromAuth({ logger });\n  const sha = await git.resolveRef({ dir: repositoryLocation, ref: 'HEAD' });\n  const commit = await git.readCommit({ dir: repositoryLocation, sha });\n\n  return commit.commit.committer.timestamp;\n};\n\nexport const getDocFilesFromRepository = async (\n  reader: UrlReader,\n  entity: Entity,\n  opts?: { etag?: string; logger?: Logger },\n): Promise<PreparerResponse> => {\n  const { target } = parseReferenceAnnotation(\n    'backstage.io/techdocs-ref',\n    entity,\n  );\n\n  opts?.logger?.debug(`Reading files from ${target}`);\n  // readTree will throw NotModifiedError if etag has not changed.\n  const readTreeResponse = await reader.readTree(target, { etag: opts?.etag });\n  const preparedDir = await readTreeResponse.dir();\n\n  opts?.logger?.debug(`Tree downloaded and stored at ${preparedDir}`);\n\n  return {\n    preparedDir,\n    etag: readTreeResponse.etag,\n  };\n};\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { UrlReader } from '@backstage/backend-common';\nimport { InputError, NotModifiedError } from '@backstage/errors';\nimport { Entity } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport parseGitUrl from 'git-url-parse';\nimport path from 'path';\nimport { Logger } from 'winston';\nimport {\n  checkoutGitRepository,\n  getLastCommitTimestamp,\n  parseReferenceAnnotation,\n} from '../../helpers';\nimport { PreparerBase, PreparerResponse } from './types';\n\nexport class DirectoryPreparer implements PreparerBase {\n  constructor(\n    private readonly config: Config,\n    private readonly logger: Logger,\n    private readonly reader: UrlReader,\n  ) {\n    this.config = config;\n    this.logger = logger;\n    this.reader = reader;\n  }\n\n  private async resolveManagedByLocationToDir(\n    entity: Entity,\n    options?: { etag?: string },\n  ): Promise<PreparerResponse> {\n    const { type, target } = parseReferenceAnnotation(\n      'backstage.io/managed-by-location',\n      entity,\n    );\n\n    this.logger.debug(\n      `Building docs for entity with type 'dir' and managed-by-location '${type}'`,\n    );\n    switch (type) {\n      case 'url': {\n        const response = await this.reader.readTree(target, {\n          etag: options?.etag,\n        });\n        const preparedDir = await response.dir();\n        return {\n          preparedDir,\n          etag: response.etag,\n        };\n      }\n      case 'github':\n      case 'gitlab':\n      case 'azure/api': {\n        const parsedGitLocation = parseGitUrl(target);\n        const repoLocation = await checkoutGitRepository(\n          target,\n          this.config,\n          this.logger,\n        );\n\n        // Check if etag has changed for cache invalidation.\n        const etag = await getLastCommitTimestamp(repoLocation, this.logger);\n        if (options?.etag === etag.toString()) {\n          throw new NotModifiedError();\n        }\n        return {\n          preparedDir: path.dirname(\n            path.join(repoLocation, parsedGitLocation.filepath),\n          ),\n          etag: etag.toString(),\n        };\n      }\n      case 'file':\n        return {\n          preparedDir: path.dirname(target),\n          // Instead of supporting caching on local sources, use techdocs-cli for local development and debugging.\n          etag: '',\n        };\n      default:\n        throw new InputError(`Unable to resolve location type ${type}`);\n    }\n  }\n\n  async prepare(entity: Entity): Promise<PreparerResponse> {\n    this.logger.warn(\n      'You are using the legacy dir preparer in TechDocs which will be removed in near future (March 2021). ' +\n        'Migrate to URL reader by updating `backstage.io/techdocs-ref` annotation in `catalog-info.yaml` ' +\n        'to be prefixed with `url:`. Read the migration guide and benefits at https://github.com/backstage/backstage/issues/4409 ',\n    );\n\n    const { target } = parseReferenceAnnotation(\n      'backstage.io/techdocs-ref',\n      entity,\n    );\n\n    // This will throw NotModified error if etag has not changed.\n    const response = await this.resolveManagedByLocationToDir(entity);\n\n    return {\n      preparedDir: path.resolve(response.preparedDir, target),\n      etag: response.etag,\n    };\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { NotModifiedError } from '@backstage/errors';\nimport { Entity } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport parseGitUrl from 'git-url-parse';\nimport path from 'path';\nimport { Logger } from 'winston';\nimport {\n  checkoutGitRepository,\n  getLastCommitTimestamp,\n  parseReferenceAnnotation,\n} from '../../helpers';\nimport { PreparerBase, PreparerResponse } from './types';\n\nexport class CommonGitPreparer implements PreparerBase {\n  private readonly config: Config;\n  private readonly logger: Logger;\n\n  constructor(config: Config, logger: Logger) {\n    this.config = config;\n    this.logger = logger;\n  }\n\n  async prepare(\n    entity: Entity,\n    options?: { etag?: string },\n  ): Promise<PreparerResponse> {\n    this.logger.warn(\n      `You are using the legacy git preparer in TechDocs for \\`${entity.metadata.name}\\` which will be removed in near future (March 2021). ` +\n        `Migrate to URL reader by updating \\`backstage.io/techdocs-ref\\` annotation in \\`catalog-info.yaml\\` ` +\n        `to be prefixed with \\`url:\\`. Read the migration guide and benefits at https://github.com/backstage/backstage/issues/4409 `,\n    );\n\n    const { target } = parseReferenceAnnotation(\n      'backstage.io/techdocs-ref',\n      entity,\n    );\n\n    try {\n      // Update repository or do a fresh clone.\n      const repoPath = await checkoutGitRepository(\n        target,\n        this.config,\n        this.logger,\n      );\n      // Check if etag has changed for cache invalidation.\n      const etag = await getLastCommitTimestamp(repoPath, this.logger);\n      if (options?.etag === etag.toString()) {\n        throw new NotModifiedError();\n      }\n\n      const parsedGitLocation = parseGitUrl(target);\n      return {\n        preparedDir: path.join(repoPath, parsedGitLocation.filepath),\n        etag: etag.toString(),\n      };\n    } catch (error) {\n      if (error instanceof NotModifiedError) {\n        this.logger.debug(`Cache is valid for etag ${options?.etag}`);\n      } else {\n        this.logger.debug(`Repo checkout failed with error ${error.message}`);\n      }\n      throw error;\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NotModifiedError } from '@backstage/errors';\nimport { UrlReader } from '@backstage/backend-common';\nimport { Entity } from '@backstage/catalog-model';\nimport { Logger } from 'winston';\nimport { getDocFilesFromRepository } from '../../helpers';\nimport { PreparerBase, PreparerResponse } from './types';\n\nexport class UrlPreparer implements PreparerBase {\n  private readonly logger: Logger;\n  private readonly reader: UrlReader;\n\n  constructor(reader: UrlReader, logger: Logger) {\n    this.logger = logger;\n    this.reader = reader;\n  }\n\n  async prepare(\n    entity: Entity,\n    options?: { etag?: string },\n  ): Promise<PreparerResponse> {\n    try {\n      return await getDocFilesFromRepository(this.reader, entity, {\n        etag: options?.etag,\n        logger: this.logger,\n      });\n    } catch (error) {\n      // NotModifiedError means that etag based cache is still valid.\n      if (error instanceof NotModifiedError) {\n        this.logger.debug(`Cache is valid for etag ${options?.etag}`);\n      } else {\n        this.logger.debug(\n          `Unable to fetch files for building docs ${error.message}`,\n        );\n      }\n\n      throw error;\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { UrlReader } from '@backstage/backend-common';\nimport { Entity } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { Logger } from 'winston';\nimport { parseReferenceAnnotation } from '../../helpers';\nimport { DirectoryPreparer } from './dir';\nimport { CommonGitPreparer } from './commonGit';\nimport { UrlPreparer } from './url';\nimport { PreparerBase, PreparerBuilder, RemoteProtocol } from './types';\n\ntype factoryOptions = {\n  logger: Logger;\n  reader: UrlReader;\n};\n\nexport class Preparers implements PreparerBuilder {\n  private preparerMap = new Map<RemoteProtocol, PreparerBase>();\n\n  static async fromConfig(\n    config: Config,\n    { logger, reader }: factoryOptions,\n  ): Promise<PreparerBuilder> {\n    const preparers = new Preparers();\n\n    const urlPreparer = new UrlPreparer(reader, logger);\n    preparers.register('url', urlPreparer);\n\n    /**\n     * Dir preparer is a syntactic sugar for users to define techdocs-ref annotation.\n     * When using dir preparer, the docs will be fetched using URL Reader.\n     */\n    const directoryPreparer = new DirectoryPreparer(config, logger, reader);\n    preparers.register('dir', directoryPreparer);\n\n    // Common git preparers will be deprecated soon.\n    const commonGitPreparer = new CommonGitPreparer(config, logger);\n    preparers.register('github', commonGitPreparer);\n    preparers.register('gitlab', commonGitPreparer);\n    preparers.register('azure/api', commonGitPreparer);\n\n    return preparers;\n  }\n\n  register(protocol: RemoteProtocol, preparer: PreparerBase) {\n    this.preparerMap.set(protocol, preparer);\n  }\n\n  get(entity: Entity): PreparerBase {\n    const { type } = parseReferenceAnnotation(\n      'backstage.io/techdocs-ref',\n      entity,\n    );\n    const preparer = this.preparerMap.get(type);\n\n    if (!preparer) {\n      throw new Error(`No preparer registered for type: \"${type}\"`);\n    }\n\n    return preparer;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport mime from 'mime-types';\nimport recursiveReadDir from 'recursive-readdir';\n\n/**\n * Helper to get the expected content-type for a given file extension. Also\n * takes XSS mitigation into account.\n */\nconst getContentTypeForExtension = (ext: string): string => {\n  const defaultContentType = 'text/plain; charset=utf-8';\n\n  // Prevent sanitization bypass by preventing browsers from directly rendering\n  // the contents of untrusted files.\n  if (ext.match(/htm|xml|svg/i)) {\n    return defaultContentType;\n  }\n\n  return mime.contentType(ext) || defaultContentType;\n};\n\nexport type responseHeadersType = {\n  'Content-Type': string;\n};\n\n/**\n * Some files need special headers to be used correctly by the frontend. This function\n * generates headers in the response to those file requests.\n * @param {string} fileExtension .html, .css, .js, .png etc.\n */\nexport const getHeadersForFileExtension = (\n  fileExtension: string,\n): responseHeadersType => {\n  return {\n    'Content-Type': getContentTypeForExtension(fileExtension),\n  };\n};\n\n/**\n * Recursively traverse all the sub-directories of a path and return\n * a list of absolute paths of all the files. e.g. tree command in Unix\n *\n * @example\n *\n * /User/username/my_dir\n *     dirA\n *     |   subDirA\n *     |   |   file1\n *     EmptyDir\n *     dirB\n *     |   file2\n *     file3\n *\n * getFileListRecursively('/Users/username/myDir')\n * // returns\n * [\n *   '/User/username/my_dir/dirA/subDirA/file1',\n *   '/User/username/my_dir/dirB/file2',\n *   '/User/username/my_dir/file3'\n * ]\n * @param rootDirPath Absolute path to the root directory.\n */\nexport const getFileTreeRecursively = async (\n  rootDirPath: string,\n): Promise<string[]> => {\n  // Iterate on all the files in the directory and its sub-directories\n  const fileList = await recursiveReadDir(rootDirPath).catch(error => {\n    throw new Error(`Failed to read template directory: ${error.message}`);\n  });\n  return fileList;\n};\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { Entity, EntityName } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport aws, { Credentials } from 'aws-sdk';\nimport { ManagedUpload } from 'aws-sdk/clients/s3';\nimport { CredentialsOptions } from 'aws-sdk/lib/credentials';\nimport express from 'express';\nimport fs from 'fs-extra';\nimport JSON5 from 'json5';\nimport createLimiter from 'p-limit';\nimport path from 'path';\nimport { Readable } from 'stream';\nimport { Logger } from 'winston';\nimport { getFileTreeRecursively, getHeadersForFileExtension } from './helpers';\nimport {\n  PublisherBase,\n  PublishRequest,\n  ReadinessResponse,\n  TechDocsMetadata,\n} from './types';\n\nconst streamToBuffer = (stream: Readable): Promise<Buffer> => {\n  return new Promise((resolve, reject) => {\n    try {\n      const chunks: any[] = [];\n      stream.on('data', chunk => chunks.push(chunk));\n      stream.on('error', reject);\n      stream.on('end', () => resolve(Buffer.concat(chunks)));\n    } catch (e) {\n      throw new Error(`Unable to parse the response data ${e.message}`);\n    }\n  });\n};\n\nexport class AwsS3Publish implements PublisherBase {\n  static fromConfig(config: Config, logger: Logger): PublisherBase {\n    let bucketName = '';\n    try {\n      bucketName = config.getString('techdocs.publisher.awsS3.bucketName');\n    } catch (error) {\n      throw new Error(\n        \"Since techdocs.publisher.type is set to 'awsS3' in your app config, \" +\n          'techdocs.publisher.awsS3.bucketName is required.',\n      );\n    }\n\n    // Credentials is an optional config. If missing, the default ways of authenticating AWS SDK V2 will be used.\n    // 1. AWS environment variables\n    // https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/loading-node-credentials-environment.html\n    // 2. AWS shared credentials file at ~/.aws/credentials\n    // https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/loading-node-credentials-shared.html\n    // 3. IAM Roles for EC2\n    // https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/loading-node-credentials-iam.html\n    const credentialsConfig = config.getOptionalConfig(\n      'techdocs.publisher.awsS3.credentials',\n    );\n    const credentials = AwsS3Publish.buildCredentials(credentialsConfig);\n\n    // AWS Region is an optional config. If missing, default AWS env variable AWS_REGION\n    // or AWS shared credentials file at ~/.aws/credentials will be used.\n    const region = config.getOptionalString('techdocs.publisher.awsS3.region');\n\n    // AWS endpoint is an optional config. If missing, the default endpoint is built from\n    // the configured region.\n    const endpoint = config.getOptionalString(\n      'techdocs.publisher.awsS3.endpoint',\n    );\n\n    // AWS forcePathStyle is an optional config. If missing, it defaults to false. Needs to be enabled for cases\n    // where endpoint url points to locally hosted S3 compatible storage like Localstack\n    const s3ForcePathStyle = config.getOptionalBoolean(\n      'techdocs.publisher.awsS3.s3ForcePathStyle',\n    );\n\n    const storageClient = new aws.S3({\n      credentials,\n      ...(region && { region }),\n      ...(endpoint && { endpoint }),\n      ...(s3ForcePathStyle && { s3ForcePathStyle }),\n    });\n\n    return new AwsS3Publish(storageClient, bucketName, logger);\n  }\n\n  private static buildCredentials(\n    config?: Config,\n  ): Credentials | CredentialsOptions | undefined {\n    if (!config) {\n      return undefined;\n    }\n\n    const accessKeyId = config.getOptionalString('accessKeyId');\n    const secretAccessKey = config.getOptionalString('secretAccessKey');\n    let explicitCredentials: Credentials | undefined;\n    if (accessKeyId && secretAccessKey) {\n      explicitCredentials = new Credentials({\n        accessKeyId,\n        secretAccessKey,\n      });\n    }\n\n    const roleArn = config.getOptionalString('roleArn');\n    if (roleArn) {\n      return new aws.ChainableTemporaryCredentials({\n        masterCredentials: explicitCredentials,\n        params: {\n          RoleSessionName: 'backstage-aws-techdocs-s3-publisher',\n          RoleArn: roleArn,\n        },\n      });\n    }\n\n    return explicitCredentials;\n  }\n\n  constructor(\n    private readonly storageClient: aws.S3,\n    private readonly bucketName: string,\n    private readonly logger: Logger,\n  ) {\n    this.storageClient = storageClient;\n    this.bucketName = bucketName;\n    this.logger = logger;\n  }\n\n  /**\n   * Check if the defined bucket exists. Being able to connect means the configuration is good\n   * and the storage client will work.\n   */\n  async getReadiness(): Promise<ReadinessResponse> {\n    try {\n      await this.storageClient\n        .headBucket({ Bucket: this.bucketName })\n        .promise();\n\n      this.logger.info(\n        `Successfully connected to the AWS S3 bucket ${this.bucketName}.`,\n      );\n\n      return { isAvailable: true };\n    } catch (error) {\n      this.logger.error(\n        `Could not retrieve metadata about the AWS S3 bucket ${this.bucketName}. ` +\n          'Make sure the bucket exists. Also make sure that authentication is setup either by ' +\n          'explicitly defining credentials and region in techdocs.publisher.awsS3 in app config or ' +\n          'by using environment variables. Refer to https://backstage.io/docs/features/techdocs/using-cloud-storage',\n      );\n      this.logger.error(`from AWS client library`, error);\n      return {\n        isAvailable: false,\n      };\n    }\n  }\n\n  /**\n   * Upload all the files from the generated `directory` to the S3 bucket.\n   * Directory structure used in the bucket is - entityNamespace/entityKind/entityName/index.html\n   */\n  async publish({ entity, directory }: PublishRequest): Promise<void> {\n    try {\n      // Note: S3 manages creation of parent directories if they do not exist.\n      // So collecting path of only the files is good enough.\n      const allFilesToUpload = await getFileTreeRecursively(directory);\n\n      const limiter = createLimiter(10);\n      const uploadPromises: Array<Promise<ManagedUpload.SendData>> = [];\n      for (const filePath of allFilesToUpload) {\n        // Remove the absolute path prefix of the source directory\n        // Path of all files to upload, relative to the root of the source directory\n        // e.g. ['index.html', 'sub-page/index.html', 'assets/images/favicon.png']\n        const relativeFilePath = path.relative(directory, filePath);\n\n        // Convert destination file path to a POSIX path for uploading.\n        // S3 expects / as path separator and relativeFilePath will contain \\\\ on Windows.\n        // https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n        const relativeFilePathPosix = relativeFilePath\n          .split(path.sep)\n          .join(path.posix.sep);\n\n        // The / delimiter is intentional since it represents the cloud storage and not the local file system.\n        const entityRootDir = `${entity.metadata.namespace}/${entity.kind}/${entity.metadata.name}`;\n        const destination = `${entityRootDir}/${relativeFilePathPosix}`; // S3 Bucket file relative path\n\n        // Rate limit the concurrent execution of file uploads to batches of 10 (per publish)\n        const uploadFile = limiter(() => {\n          const fileStream = fs.createReadStream(filePath);\n\n          const params = {\n            Bucket: this.bucketName,\n            Key: destination,\n            Body: fileStream,\n          };\n\n          return this.storageClient.upload(params).promise();\n        });\n        uploadPromises.push(uploadFile);\n      }\n      await Promise.all(uploadPromises);\n      this.logger.info(\n        `Successfully uploaded all the generated files for Entity ${entity.metadata.name}. Total number of files: ${allFilesToUpload.length}`,\n      );\n      return;\n    } catch (e) {\n      const errorMessage = `Unable to upload file(s) to AWS S3. ${e}`;\n      this.logger.error(errorMessage);\n      throw new Error(errorMessage);\n    }\n  }\n\n  async fetchTechDocsMetadata(\n    entityName: EntityName,\n  ): Promise<TechDocsMetadata> {\n    try {\n      return await new Promise<TechDocsMetadata>(async (resolve, reject) => {\n        const entityRootDir = `${entityName.namespace}/${entityName.kind}/${entityName.name}`;\n\n        const stream = this.storageClient\n          .getObject({\n            Bucket: this.bucketName,\n            Key: `${entityRootDir}/techdocs_metadata.json`,\n          })\n          .createReadStream();\n\n        try {\n          const techdocsMetadataJson = await streamToBuffer(stream);\n          if (!techdocsMetadataJson) {\n            throw new Error(\n              `Unable to parse the techdocs metadata file ${entityRootDir}/techdocs_metadata.json.`,\n            );\n          }\n\n          const techdocsMetadata = JSON5.parse(\n            techdocsMetadataJson.toString('utf-8'),\n          );\n\n          resolve(techdocsMetadata);\n        } catch (err) {\n          this.logger.error(err.message);\n          reject(new Error(err.message));\n        }\n      });\n    } catch (e) {\n      throw new Error(`TechDocs metadata fetch failed, ${e.message}`);\n    }\n  }\n\n  /**\n   * Express route middleware to serve static files on a route in techdocs-backend.\n   */\n  docsRouter(): express.Handler {\n    return async (req, res) => {\n      // Decode and trim the leading forward slash\n      // filePath example - /default/Component/documented-component/index.html\n      const filePath = decodeURI(req.path.replace(/^\\//, ''));\n\n      // Files with different extensions (CSS, HTML) need to be served with different headers\n      const fileExtension = path.extname(filePath);\n      const responseHeaders = getHeadersForFileExtension(fileExtension);\n\n      const stream = this.storageClient\n        .getObject({ Bucket: this.bucketName, Key: filePath })\n        .createReadStream();\n      try {\n        // Inject response headers\n        for (const [headerKey, headerValue] of Object.entries(\n          responseHeaders,\n        )) {\n          res.setHeader(headerKey, headerValue);\n        }\n\n        res.send(await streamToBuffer(stream));\n      } catch (err) {\n        this.logger.warn(err.message);\n        res.status(404).json(err.message);\n      }\n    };\n  }\n\n  /**\n   * A helper function which checks if index.html of an Entity's docs site is available. This\n   * can be used to verify if there are any pre-generated docs available to serve.\n   */\n  async hasDocsBeenGenerated(entity: Entity): Promise<boolean> {\n    try {\n      const entityRootDir = `${entity.metadata.namespace}/${entity.kind}/${entity.metadata.name}`;\n      await this.storageClient\n        .headObject({\n          Bucket: this.bucketName,\n          Key: `${entityRootDir}/index.html`,\n        })\n        .promise();\n      return Promise.resolve(true);\n    } catch (e) {\n      return Promise.resolve(false);\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { DefaultAzureCredential } from '@azure/identity';\nimport {\n  BlobServiceClient,\n  StorageSharedKeyCredential,\n} from '@azure/storage-blob';\nimport { Entity, EntityName } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport express from 'express';\nimport JSON5 from 'json5';\nimport limiterFactory from 'p-limit';\nimport { default as path, default as platformPath } from 'path';\nimport { Logger } from 'winston';\nimport { getFileTreeRecursively, getHeadersForFileExtension } from './helpers';\nimport {\n  PublisherBase,\n  PublishRequest,\n  ReadinessResponse,\n  TechDocsMetadata,\n} from './types';\n\n// The number of batches that may be ongoing at the same time.\nconst BATCH_CONCURRENCY = 3;\n\nexport class AzureBlobStoragePublish implements PublisherBase {\n  static fromConfig(config: Config, logger: Logger): PublisherBase {\n    let containerName = '';\n    try {\n      containerName = config.getString(\n        'techdocs.publisher.azureBlobStorage.containerName',\n      );\n    } catch (error) {\n      throw new Error(\n        \"Since techdocs.publisher.type is set to 'azureBlobStorage' in your app config, \" +\n          'techdocs.publisher.azureBlobStorage.containerName is required.',\n      );\n    }\n\n    let accountName = '';\n    try {\n      accountName = config.getString(\n        'techdocs.publisher.azureBlobStorage.credentials.accountName',\n      );\n    } catch (error) {\n      throw new Error(\n        \"Since techdocs.publisher.type is set to 'azureBlobStorage' in your app config, \" +\n          'techdocs.publisher.azureBlobStorage.credentials.accountName is required.',\n      );\n    }\n\n    // Credentials is an optional config. If missing, default Azure Blob Storage environment variables will be used.\n    // https://docs.microsoft.com/en-us/azure/storage/common/storage-auth-aad-app\n    const accountKey = config.getOptionalString(\n      'techdocs.publisher.azureBlobStorage.credentials.accountKey',\n    );\n\n    let credential;\n    if (accountKey) {\n      credential = new StorageSharedKeyCredential(accountName, accountKey);\n    } else {\n      credential = new DefaultAzureCredential();\n    }\n\n    const storageClient = new BlobServiceClient(\n      `https://${accountName}.blob.core.windows.net`,\n      credential,\n    );\n\n    return new AzureBlobStoragePublish(storageClient, containerName, logger);\n  }\n\n  constructor(\n    private readonly storageClient: BlobServiceClient,\n    private readonly containerName: string,\n    private readonly logger: Logger,\n  ) {\n    this.storageClient = storageClient;\n    this.containerName = containerName;\n    this.logger = logger;\n  }\n\n  async getReadiness(): Promise<ReadinessResponse> {\n    try {\n      const response = await this.storageClient\n        .getContainerClient(this.containerName)\n        .getProperties();\n\n      if (response._response.status === 200) {\n        return {\n          isAvailable: true,\n        };\n      }\n\n      if (response._response.status >= 400) {\n        this.logger.error(\n          `Failed to retrieve metadata from ${response._response.request.url} with status code ${response._response.status}.`,\n        );\n      }\n    } catch (e) {\n      this.logger.error(`from Azure Blob Storage client library: ${e.message}`);\n    }\n\n    this.logger.error(\n      `Could not retrieve metadata about the Azure Blob Storage container ${this.containerName}. ` +\n        'Make sure that the Azure project and container exist and the access key is setup correctly ' +\n        'techdocs.publisher.azureBlobStorage.credentials defined in app config has correct permissions. ' +\n        'Refer to https://backstage.io/docs/features/techdocs/using-cloud-storage',\n    );\n\n    return { isAvailable: false };\n  }\n\n  /**\n   * Upload all the files from the generated `directory` to the Azure Blob Storage container.\n   * Directory structure used in the container is - entityNamespace/entityKind/entityName/index.html\n   */\n  async publish({ entity, directory }: PublishRequest): Promise<void> {\n    try {\n      // Note: Azure Blob Storage manages creation of parent directories if they do not exist.\n      // So collecting path of only the files is good enough.\n      const allFilesToUpload = await getFileTreeRecursively(directory);\n\n      // Bound the number of concurrent batches. We want a bit of concurrency for\n      // performance reasons, but not so much that we starve the connection pool\n      // or start thrashing.\n      const limiter = limiterFactory(BATCH_CONCURRENCY);\n\n      const promises = allFilesToUpload.map(sourceFilePath => {\n        // Remove the absolute path prefix of the source directory\n        // Path of all files to upload, relative to the root of the source directory\n        // e.g. ['index.html', 'sub-page/index.html', 'assets/images/favicon.png']\n        const relativeFilePath = path.normalize(\n          path.relative(directory, sourceFilePath),\n        );\n\n        // Convert destination file path to a POSIX path for uploading.\n        // Azure Blob Storage expects / as path separator and relativeFilePath will contain \\\\ on Windows.\n        // https://docs.microsoft.com/en-us/rest/api/storageservices/naming-and-referencing-containers--blobs--and-metadata#blob-names\n        const relativeFilePathPosix = relativeFilePath\n          .split(path.sep)\n          .join(path.posix.sep);\n\n        // The / delimiter is intentional since it represents the cloud storage and not the local file system.\n        const entityRootDir = `${entity.metadata.namespace}/${entity.kind}/${entity.metadata.name}`;\n        const destination = `${entityRootDir}/${relativeFilePathPosix}`; // Azure Blob Storage Container file relative path\n        return limiter(async () => {\n          const response = await this.storageClient\n            .getContainerClient(this.containerName)\n            .getBlockBlobClient(destination)\n            .uploadFile(sourceFilePath);\n\n          if (response._response.status >= 400) {\n            return {\n              ...response,\n              error: new Error(\n                `Upload failed for ${sourceFilePath} with status code ${response._response.status}`,\n              ),\n            };\n          }\n          return {\n            ...response,\n            error: undefined,\n          };\n        });\n      });\n\n      const responses = await Promise.all(promises);\n\n      const failed = responses.filter(r => r.error);\n      if (failed.length === 0) {\n        this.logger.info(\n          `Successfully uploaded the ${responses.length} generated file(s) for Entity ${entity.metadata.name}. Total number of files: ${allFilesToUpload.length}`,\n        );\n      } else {\n        throw new Error(\n          failed\n            .map(r => r.error?.message)\n            .filter(Boolean)\n            .join(' '),\n        );\n      }\n    } catch (e) {\n      const errorMessage = `Unable to upload file(s) to Azure Blob Storage. ${e}`;\n      this.logger.error(errorMessage);\n      throw new Error(errorMessage);\n    }\n  }\n\n  private download(containerName: string, blobPath: string): Promise<Buffer> {\n    return new Promise((resolve, reject) => {\n      const fileStreamChunks: Array<any> = [];\n      this.storageClient\n        .getContainerClient(containerName)\n        .getBlockBlobClient(blobPath)\n        .download()\n        .then(res => {\n          const body = res.readableStreamBody;\n          if (!body) {\n            reject(new Error(`Unable to parse the response data`));\n            return;\n          }\n          body\n            .on('error', reject)\n            .on('data', chunk => {\n              fileStreamChunks.push(chunk);\n            })\n            .on('end', () => {\n              resolve(Buffer.concat(fileStreamChunks));\n            });\n        })\n        .catch(reject);\n    });\n  }\n\n  async fetchTechDocsMetadata(\n    entityName: EntityName,\n  ): Promise<TechDocsMetadata> {\n    const entityRootDir = `${entityName.namespace}/${entityName.kind}/${entityName.name}`;\n    try {\n      const techdocsMetadataJson = await this.download(\n        this.containerName,\n        `${entityRootDir}/techdocs_metadata.json`,\n      );\n      if (!techdocsMetadataJson) {\n        throw new Error(\n          `Unable to parse the techdocs metadata file ${entityRootDir}/techdocs_metadata.json.`,\n        );\n      }\n      const techdocsMetadata = JSON5.parse(\n        techdocsMetadataJson.toString('utf-8'),\n      );\n      return techdocsMetadata;\n    } catch (e) {\n      throw new Error(`TechDocs metadata fetch failed, ${e.message}`);\n    }\n  }\n\n  /**\n   * Express route middleware to serve static files on a route in techdocs-backend.\n   */\n  docsRouter(): express.Handler {\n    return (req, res) => {\n      // Decode and trim the leading forward slash\n      // filePath example - /default/Component/documented-component/index.html\n      const filePath = decodeURI(req.path.replace(/^\\//, ''));\n      // Files with different extensions (CSS, HTML) need to be served with different headers\n      const fileExtension = platformPath.extname(filePath);\n      const responseHeaders = getHeadersForFileExtension(fileExtension);\n\n      try {\n        this.download(this.containerName, filePath).then(fileContent => {\n          // Inject response headers\n          for (const [headerKey, headerValue] of Object.entries(\n            responseHeaders,\n          )) {\n            res.setHeader(headerKey, headerValue);\n          }\n          res.send(fileContent);\n        });\n      } catch (e) {\n        this.logger.error(e.message);\n        res.status(404).json(e.message);\n      }\n    };\n  }\n\n  /**\n   * A helper function which checks if index.html of an Entity's docs site is available. This\n   * can be used to verify if there are any pre-generated docs available to serve.\n   */\n  hasDocsBeenGenerated(entity: Entity): Promise<boolean> {\n    const entityRootDir = `${entity.metadata.namespace}/${entity.kind}/${entity.metadata.name}`;\n    return this.storageClient\n      .getContainerClient(this.containerName)\n      .getBlockBlobClient(`${entityRootDir}/index.html`)\n      .exists();\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { Entity, EntityName } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport {\n  FileExistsResponse,\n  Storage,\n  UploadResponse,\n} from '@google-cloud/storage';\nimport express from 'express';\nimport JSON5 from 'json5';\nimport createLimiter from 'p-limit';\nimport path from 'path';\nimport { Logger } from 'winston';\nimport { getFileTreeRecursively, getHeadersForFileExtension } from './helpers';\nimport {\n  PublisherBase,\n  PublishRequest,\n  ReadinessResponse,\n  TechDocsMetadata,\n} from './types';\n\nexport class GoogleGCSPublish implements PublisherBase {\n  static fromConfig(config: Config, logger: Logger): PublisherBase {\n    let bucketName = '';\n    try {\n      bucketName = config.getString('techdocs.publisher.googleGcs.bucketName');\n    } catch (error) {\n      throw new Error(\n        \"Since techdocs.publisher.type is set to 'googleGcs' in your app config, \" +\n          'techdocs.publisher.googleGcs.bucketName is required.',\n      );\n    }\n\n    // Credentials is an optional config. If missing, default GCS environment variables will be used.\n    // Read more here https://cloud.google.com/docs/authentication/production\n    const credentials = config.getOptionalString(\n      'techdocs.publisher.googleGcs.credentials',\n    );\n    let credentialsJson = {};\n    if (credentials) {\n      try {\n        credentialsJson = JSON.parse(credentials);\n      } catch (err) {\n        throw new Error(\n          'Error in parsing techdocs.publisher.googleGcs.credentials config to JSON.',\n        );\n      }\n    }\n\n    const storageClient = new Storage({\n      ...(credentials && {\n        credentials: credentialsJson,\n      }),\n    });\n\n    return new GoogleGCSPublish(storageClient, bucketName, logger);\n  }\n\n  constructor(\n    private readonly storageClient: Storage,\n    private readonly bucketName: string,\n    private readonly logger: Logger,\n  ) {\n    this.storageClient = storageClient;\n    this.bucketName = bucketName;\n    this.logger = logger;\n  }\n\n  /**\n   * Check if the defined bucket exists. Being able to connect means the configuration is good\n   * and the storage client will work.\n   */\n  async getReadiness(): Promise<ReadinessResponse> {\n    try {\n      await this.storageClient.bucket(this.bucketName).getMetadata();\n      this.logger.info(\n        `Successfully connected to the GCS bucket ${this.bucketName}.`,\n      );\n\n      return {\n        isAvailable: true,\n      };\n    } catch (err) {\n      this.logger.error(\n        `Could not retrieve metadata about the GCS bucket ${this.bucketName}. ` +\n          'Make sure the bucket exists. Also make sure that authentication is setup either by explicitly defining ' +\n          'techdocs.publisher.googleGcs.credentials in app config or by using environment variables. ' +\n          'Refer to https://backstage.io/docs/features/techdocs/using-cloud-storage',\n      );\n      this.logger.error(`from GCS client library: ${err.message}`);\n\n      return { isAvailable: false };\n    }\n  }\n\n  /**\n   * Upload all the files from the generated `directory` to the GCS bucket.\n   * Directory structure used in the bucket is - entityNamespace/entityKind/entityName/index.html\n   */\n  async publish({ entity, directory }: PublishRequest): Promise<void> {\n    try {\n      // Note: GCS manages creation of parent directories if they do not exist.\n      // So collecting path of only the files is good enough.\n      const allFilesToUpload = await getFileTreeRecursively(directory);\n\n      const limiter = createLimiter(10);\n      const uploadPromises: Array<Promise<UploadResponse>> = [];\n      allFilesToUpload.forEach(sourceFilePath => {\n        // Remove the absolute path prefix of the source directory\n        // Path of all files to upload, relative to the root of the source directory\n        // e.g. ['index.html', 'sub-page/index.html', 'assets/images/favicon.png']\n        const relativeFilePath = path.relative(directory, sourceFilePath);\n\n        // Convert destination file path to a POSIX path for uploading.\n        // GCS expects / as path separator and relativeFilePath will contain \\\\ on Windows.\n        // https://cloud.google.com/storage/docs/gsutil/addlhelp/HowSubdirectoriesWork\n        const relativeFilePathPosix = relativeFilePath\n          .split(path.sep)\n          .join(path.posix.sep);\n\n        // The / delimiter is intentional since it represents the cloud storage and not the local file system.\n        const entityRootDir = `${entity.metadata.namespace}/${entity.kind}/${entity.metadata.name}`;\n        const destination = `${entityRootDir}/${relativeFilePathPosix}`; // GCS Bucket file relative path\n\n        // Rate limit the concurrent execution of file uploads to batches of 10 (per publish)\n        const uploadFile = limiter(() =>\n          this.storageClient.bucket(this.bucketName).upload(sourceFilePath, {\n            destination,\n          }),\n        );\n        uploadPromises.push(uploadFile);\n      });\n\n      await Promise.all(uploadPromises);\n\n      this.logger.info(\n        `Successfully uploaded all the generated files for Entity ${entity.metadata.name}. Total number of files: ${allFilesToUpload.length}`,\n      );\n    } catch (e) {\n      const errorMessage = `Unable to upload file(s) to Google Cloud Storage. ${e}`;\n      this.logger.error(errorMessage);\n      throw new Error(errorMessage);\n    }\n  }\n\n  fetchTechDocsMetadata(entityName: EntityName): Promise<TechDocsMetadata> {\n    return new Promise((resolve, reject) => {\n      const entityRootDir = `${entityName.namespace}/${entityName.kind}/${entityName.name}`;\n\n      const fileStreamChunks: Array<any> = [];\n      this.storageClient\n        .bucket(this.bucketName)\n        .file(`${entityRootDir}/techdocs_metadata.json`)\n        .createReadStream()\n        .on('error', err => {\n          this.logger.error(err.message);\n          reject(err);\n        })\n        .on('data', chunk => {\n          fileStreamChunks.push(chunk);\n        })\n        .on('end', () => {\n          const techdocsMetadataJson = Buffer.concat(fileStreamChunks).toString(\n            'utf-8',\n          );\n          resolve(JSON5.parse(techdocsMetadataJson));\n        });\n    });\n  }\n\n  /**\n   * Express route middleware to serve static files on a route in techdocs-backend.\n   */\n  docsRouter(): express.Handler {\n    return (req, res) => {\n      // Decode and trim the leading forward slash\n      // filePath example - /default/Component/documented-component/index.html\n      const filePath = decodeURI(req.path.replace(/^\\//, ''));\n\n      // Files with different extensions (CSS, HTML) need to be served with different headers\n      const fileExtension = path.extname(filePath);\n      const responseHeaders = getHeadersForFileExtension(fileExtension);\n\n      // Pipe file chunks directly from storage to client.\n      this.storageClient\n        .bucket(this.bucketName)\n        .file(filePath)\n        .createReadStream()\n        .on('pipe', () => {\n          res.writeHead(200, responseHeaders);\n        })\n        .on('error', err => {\n          this.logger.warn(err.message);\n          // Send a 404 with a meaningful message if possible.\n          if (!res.headersSent) {\n            res.status(404).send(err.message);\n          } else {\n            res.destroy();\n          }\n        })\n        .pipe(res);\n    };\n  }\n\n  /**\n   * A helper function which checks if index.html of an Entity's docs site is available. This\n   * can be used to verify if there are any pre-generated docs available to serve.\n   */\n  async hasDocsBeenGenerated(entity: Entity): Promise<boolean> {\n    return new Promise(resolve => {\n      const entityRootDir = `${entity.metadata.namespace}/${entity.kind}/${entity.metadata.name}`;\n      this.storageClient\n        .bucket(this.bucketName)\n        .file(`${entityRootDir}/index.html`)\n        .exists()\n        .then((response: FileExistsResponse) => {\n          resolve(response[0]);\n        })\n        .catch(() => {\n          resolve(false);\n        });\n    });\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport {\n  PluginEndpointDiscovery,\n  resolvePackagePath,\n} from '@backstage/backend-common';\nimport { Entity, EntityName } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport express from 'express';\nimport fs from 'fs-extra';\nimport os from 'os';\nimport path from 'path';\nimport { Logger } from 'winston';\nimport {\n  PublisherBase,\n  PublishRequest,\n  PublishResponse,\n  ReadinessResponse,\n  TechDocsMetadata,\n} from './types';\nimport { getHeadersForFileExtension } from './helpers';\n\n// TODO: Use a more persistent storage than node_modules or /tmp directory.\n// Make it configurable with techdocs.publisher.local.publishDirectory\nlet staticDocsDir = '';\ntry {\n  staticDocsDir = resolvePackagePath(\n    '@backstage/plugin-techdocs-backend',\n    'static/docs',\n  );\n} catch (err) {\n  // This will most probably never be used.\n  // The try/catch is introduced so that techdocs-cli can import @backstage/techdocs-common\n  // on CI/CD without installing techdocs backend plugin.\n  staticDocsDir = os.tmpdir();\n}\n\n/**\n * Local publisher which uses the local filesystem to store the generated static files. It uses a directory\n * called \"static\" at the root of techdocs-backend plugin.\n */\nexport class LocalPublish implements PublisherBase {\n  // TODO: Use a static fromConfig method to create a LocalPublish instance, similar to aws/gcs publishers.\n  // Move the logic of setting staticDocsDir based on config over to fromConfig,\n  // and set the value as a class parameter.\n  constructor(\n    // @ts-ignore\n    private readonly config: Config,\n    private readonly logger: Logger,\n    private readonly discovery: PluginEndpointDiscovery,\n  ) {\n    this.config = config;\n    this.logger = logger;\n    this.discovery = discovery;\n  }\n\n  async getReadiness(): Promise<ReadinessResponse> {\n    return {\n      isAvailable: true,\n    };\n  }\n\n  publish({ entity, directory }: PublishRequest): Promise<PublishResponse> {\n    const entityNamespace = entity.metadata.namespace ?? 'default';\n\n    const publishDir = path.join(\n      staticDocsDir,\n      entityNamespace,\n      entity.kind,\n      entity.metadata.name,\n    );\n\n    if (!fs.existsSync(publishDir)) {\n      this.logger.info(`Could not find ${publishDir}, creating the directory.`);\n      fs.mkdirSync(publishDir, { recursive: true });\n    }\n\n    return new Promise((resolve, reject) => {\n      fs.copy(directory, publishDir, err => {\n        if (err) {\n          this.logger.debug(\n            `Failed to copy docs from ${directory} to ${publishDir}`,\n          );\n          reject(err);\n        }\n        this.logger.info(`Published site stored at ${publishDir}`);\n        this.discovery\n          .getBaseUrl('techdocs')\n          .then(techdocsApiUrl => {\n            resolve({\n              remoteUrl: `${techdocsApiUrl}/static/docs/${entity.metadata.name}`,\n            });\n          })\n          .catch(reason => {\n            reject(reason);\n          });\n      });\n    });\n  }\n\n  async fetchTechDocsMetadata(\n    entityName: EntityName,\n  ): Promise<TechDocsMetadata> {\n    const metadataPath = path.join(\n      staticDocsDir,\n      entityName.namespace,\n      entityName.kind,\n      entityName.name,\n      'techdocs_metadata.json',\n    );\n\n    try {\n      return await fs.readJson(metadataPath);\n    } catch (err) {\n      this.logger.error(\n        `Unable to read techdocs_metadata.json at ${metadataPath}. Error: ${err}`,\n      );\n      throw new Error(err.message);\n    }\n  }\n\n  docsRouter(): express.Handler {\n    return express.static(staticDocsDir, {\n      // Handle content-type header the same as all other publishers.\n      setHeaders: (res, filePath) => {\n        const fileExtension = path.extname(filePath);\n        const headers = getHeadersForFileExtension(fileExtension);\n        for (const [header, value] of Object.entries(headers)) {\n          res.setHeader(header, value);\n        }\n      },\n    });\n  }\n\n  async hasDocsBeenGenerated(entity: Entity): Promise<boolean> {\n    const namespace = entity.metadata.namespace ?? 'default';\n\n    const indexHtmlPath = path.join(\n      staticDocsDir,\n      namespace,\n      entity.kind,\n      entity.metadata.name,\n      'index.html',\n    );\n\n    // Check if the file exists\n    try {\n      await fs.access(indexHtmlPath, fs.constants.F_OK);\n      return true;\n    } catch (err) {\n      return false;\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { Entity, EntityName } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport express from 'express';\nimport fs from 'fs-extra';\nimport JSON5 from 'json5';\nimport createLimiter from 'p-limit';\nimport path from 'path';\nimport { storage } from 'pkgcloud';\nimport { Readable } from 'stream';\nimport { Logger } from 'winston';\nimport { getFileTreeRecursively, getHeadersForFileExtension } from './helpers';\nimport {\n  PublisherBase,\n  PublishRequest,\n  ReadinessResponse,\n  TechDocsMetadata,\n} from './types';\n\nconst streamToBuffer = (stream: Readable): Promise<Buffer> => {\n  return new Promise((resolve, reject) => {\n    try {\n      const chunks: any[] = [];\n      stream.on('data', chunk => chunks.push(chunk));\n      stream.on('error', reject);\n      stream.on('end', () => resolve(Buffer.concat(chunks)));\n    } catch (e) {\n      throw new Error(`Unable to parse the response data ${e.message}`);\n    }\n  });\n};\n\nexport class OpenStackSwiftPublish implements PublisherBase {\n  static fromConfig(config: Config, logger: Logger): PublisherBase {\n    let containerName = '';\n    try {\n      containerName = config.getString(\n        'techdocs.publisher.openStackSwift.containerName',\n      );\n    } catch (error) {\n      throw new Error(\n        \"Since techdocs.publisher.type is set to 'openStackSwift' in your app config, \" +\n          'techdocs.publisher.openStackSwift.containerName is required.',\n      );\n    }\n\n    const openStackSwiftConfig = config.getConfig(\n      'techdocs.publisher.openStackSwift',\n    );\n\n    const storageClient = storage.createClient({\n      provider: 'openstack',\n      username: openStackSwiftConfig.getString('credentials.username'),\n      password: openStackSwiftConfig.getString('credentials.password'),\n      authUrl: openStackSwiftConfig.getString('authUrl'),\n      keystoneAuthVersion:\n        openStackSwiftConfig.getOptionalString('keystoneAuthVersion') || 'v3',\n      domainId: openStackSwiftConfig.getOptionalString('domainId') || 'default',\n      domainName:\n        openStackSwiftConfig.getOptionalString('domainName') || 'Default',\n      region: openStackSwiftConfig.getString('region'),\n    });\n\n    return new OpenStackSwiftPublish(storageClient, containerName, logger);\n  }\n\n  constructor(\n    private readonly storageClient: storage.Client,\n    private readonly containerName: string,\n    private readonly logger: Logger,\n  ) {\n    this.storageClient = storageClient;\n    this.containerName = containerName;\n    this.logger = logger;\n  }\n\n  /*\n   * Check if the defined container exists. Being able to connect means the configuration is good\n   * and the storage client will work.\n   */\n  getReadiness(): Promise<ReadinessResponse> {\n    return new Promise(resolve => {\n      this.storageClient.getContainer(this.containerName, (err, container) => {\n        if (container) {\n          this.logger.info(\n            `Successfully connected to the OpenStack Swift container ${this.containerName}.`,\n          );\n          resolve({\n            isAvailable: true,\n          });\n        } else {\n          this.logger.error(\n            `Could not retrieve metadata about the OpenStack Swift container ${this.containerName}. ` +\n              'Make sure the container exists. Also make sure that authentication is setup either by ' +\n              'explicitly defining credentials and region in techdocs.publisher.openStackSwift in app config or ' +\n              'by using environment variables. Refer to https://backstage.io/docs/features/techdocs/using-cloud-storage',\n          );\n\n          this.logger.error(`from OpenStack client library: ${err.message}`);\n          resolve({\n            isAvailable: false,\n          });\n        }\n      });\n    });\n  }\n\n  /**\n   * Upload all the files from the generated `directory` to the OpenStack Swift container.\n   * Directory structure used in the bucket is - entityNamespace/entityKind/entityName/index.html\n   */\n  async publish({ entity, directory }: PublishRequest): Promise<void> {\n    try {\n      // Note: OpenStack Swift manages creation of parent directories if they do not exist.\n      // So collecting path of only the files is good enough.\n      const allFilesToUpload = await getFileTreeRecursively(directory);\n      const limiter = createLimiter(10);\n      const uploadPromises: Array<Promise<unknown>> = [];\n      for (const filePath of allFilesToUpload) {\n        // Remove the absolute path prefix of the source directory\n        // Path of all files to upload, relative to the root of the source directory\n        // e.g. ['index.html', 'sub-page/index.html', 'assets/images/favicon.png']\n        const relativeFilePath = path.relative(directory, filePath);\n\n        // Convert destination file path to a POSIX path for uploading.\n        // Swift expects / as path separator and relativeFilePath will contain \\\\ on Windows.\n        // https://docs.openstack.org/python-openstackclient/pike/cli/man/openstack.html\n        const relativeFilePathPosix = relativeFilePath\n          .split(path.sep)\n          .join(path.posix.sep);\n\n        // The / delimiter is intentional since it represents the cloud storage and not the local file system.\n        const entityRootDir = `${entity.metadata.namespace}/${entity.kind}/${entity.metadata.name}`;\n        const destination = `${entityRootDir}/${relativeFilePathPosix}`; // Swift container file relative path\n\n        const params = {\n          container: this.containerName,\n          remote: destination,\n        };\n\n        // Rate limit the concurrent execution of file uploads to batches of 10 (per publish)\n        const uploadFile = limiter(\n          () =>\n            new Promise((res, rej) => {\n              const readStream = fs.createReadStream(filePath, 'utf8');\n\n              const writeStream = this.storageClient.upload(params);\n\n              writeStream.on('error', rej);\n\n              writeStream.on('success', res);\n\n              readStream.pipe(writeStream);\n            }),\n        );\n        uploadPromises.push(uploadFile);\n      }\n      await Promise.all(uploadPromises);\n      this.logger.info(\n        `Successfully uploaded all the generated files for Entity ${entity.metadata.name}. Total number of files: ${allFilesToUpload.length}`,\n      );\n      return;\n    } catch (e) {\n      const errorMessage = `Unable to upload file(s) to OpenStack Swift. ${e}`;\n      this.logger.error(errorMessage);\n      throw new Error(errorMessage);\n    }\n  }\n\n  async fetchTechDocsMetadata(\n    entityName: EntityName,\n  ): Promise<TechDocsMetadata> {\n    try {\n      return await new Promise<TechDocsMetadata>(async (resolve, reject) => {\n        const entityRootDir = `${entityName.namespace}/${entityName.kind}/${entityName.name}`;\n\n        const stream = this.storageClient.download({\n          container: this.containerName,\n          remote: `${entityRootDir}/techdocs_metadata.json`,\n        });\n\n        try {\n          const techdocsMetadataJson = await streamToBuffer(stream);\n          if (!techdocsMetadataJson) {\n            throw new Error(\n              `Unable to parse the techdocs metadata file ${entityRootDir}/techdocs_metadata.json.`,\n            );\n          }\n\n          const techdocsMetadata = JSON5.parse(\n            techdocsMetadataJson.toString('utf-8'),\n          );\n\n          resolve(techdocsMetadata);\n        } catch (err) {\n          this.logger.error(err.message);\n          reject(new Error(err.message));\n        }\n      });\n    } catch (e) {\n      throw new Error(`TechDocs metadata fetch failed, ${e.message}`);\n    }\n  }\n\n  /**\n   * Express route middleware to serve static files on a route in techdocs-backend.\n   */\n  docsRouter(): express.Handler {\n    return async (req, res) => {\n      // Decode and trim the leading forward slash\n      // filePath example - /default/Component/documented-component/index.html\n      const filePath = decodeURI(req.path.replace(/^\\//, ''));\n\n      // Files with different extensions (CSS, HTML) need to be served with different headers\n      const fileExtension = path.extname(filePath);\n      const responseHeaders = getHeadersForFileExtension(fileExtension);\n\n      const stream = this.storageClient.download({\n        container: this.containerName,\n        remote: filePath,\n      });\n\n      try {\n        // Inject response headers\n        for (const [headerKey, headerValue] of Object.entries(\n          responseHeaders,\n        )) {\n          res.setHeader(headerKey, headerValue);\n        }\n\n        res.send(await streamToBuffer(stream));\n      } catch (err) {\n        this.logger.warn(err.message);\n        res.status(404).send(err.message);\n      }\n    };\n  }\n\n  /**\n   * A helper function which checks if index.html of an Entity's docs site is available. This\n   * can be used to verify if there are any pre-generated docs available to serve.\n   */\n  async hasDocsBeenGenerated(entity: Entity): Promise<boolean> {\n    try {\n      const entityRootDir = `${entity.metadata.namespace}/${entity.kind}/${entity.metadata.name}`;\n\n      return new Promise(res => {\n        this.storageClient.getFile(\n          this.containerName,\n          `${entityRootDir}/index.html`,\n          (err, file) => {\n            if (!err && file) {\n              res(true);\n            } else {\n              res(false);\n              this.logger.warn(err.message);\n            }\n          },\n        );\n      });\n    } catch (e) {\n      return Promise.resolve(false);\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PluginEndpointDiscovery } from '@backstage/backend-common';\nimport { Config } from '@backstage/config';\nimport { Logger } from 'winston';\nimport { AwsS3Publish } from './awsS3';\nimport { AzureBlobStoragePublish } from './azureBlobStorage';\nimport { GoogleGCSPublish } from './googleStorage';\nimport { LocalPublish } from './local';\nimport { OpenStackSwiftPublish } from './openStackSwift';\nimport { PublisherBase, PublisherType } from './types';\n\ntype factoryOptions = {\n  logger: Logger;\n  discovery: PluginEndpointDiscovery;\n};\n\n/**\n * Factory class to create a TechDocs publisher based on defined publisher type in app config.\n * Uses `techdocs.publisher.type`.\n */\nexport class Publisher {\n  static async fromConfig(\n    config: Config,\n    { logger, discovery }: factoryOptions,\n  ): Promise<PublisherBase> {\n    const publisherType = (config.getOptionalString(\n      'techdocs.publisher.type',\n    ) ?? 'local') as PublisherType;\n\n    switch (publisherType) {\n      case 'googleGcs':\n        logger.info('Creating Google Storage Bucket publisher for TechDocs');\n        return GoogleGCSPublish.fromConfig(config, logger);\n      case 'awsS3':\n        logger.info('Creating AWS S3 Bucket publisher for TechDocs');\n        return AwsS3Publish.fromConfig(config, logger);\n      case 'azureBlobStorage':\n        logger.info(\n          'Creating Azure Blob Storage Container publisher for TechDocs',\n        );\n        return AzureBlobStoragePublish.fromConfig(config, logger);\n      case 'openStackSwift':\n        logger.info(\n          'Creating OpenStack Swift Container publisher for TechDocs',\n        );\n        return OpenStackSwiftPublish.fromConfig(config, logger);\n      case 'local':\n        logger.info('Creating Local publisher for TechDocs');\n        return new LocalPublish(config, logger, discovery);\n      default:\n        logger.info('Creating Local publisher for TechDocs');\n        return new LocalPublish(config, logger, discovery);\n    }\n  }\n}\n"],"names":["PassThrough","spawn","DEFAULT_SCHEMA","Type","fs","yaml","isAbsolute","normalize","stream","path","parseGitUrl","readGitHubIntegrationConfigs","readGitLabIntegrationConfigs","readAzureIntegrationConfigs","getGitHubRequestOptions","fetch","getGitLabRequestOptions","getAzureRequestOptions","InputError","parseLocationReference","os","Git","NotModifiedError","mime","recursiveReadDir","aws","Credentials","createLimiter","JSON5","StorageSharedKeyCredential","DefaultAzureCredential","BlobServiceClient","limiterFactory","platformPath","Storage","resolvePackagePath","express","streamToBuffer","storage"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;yBA4BgC,QAAuC;AACrE,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM;AAAA;AAGlB,SAAO;AAAA;MAkBI,aAAa,OAAO;AAAA,EAC/B;AAAA,EACA;AAAA,EACA;AAAA,EACA,YAAY,IAAIA;AAAA,MACO;AACvB,QAAM,IAAI,QAAc,CAAC,SAAS,WAAW;AAC3C,UAAM,UAAUC,oBAAM,SAAS,MAAM;AAErC,YAAQ,OAAO,GAAG,QAAQ,YAAU;AAClC,gBAAU,MAAM;AAAA;AAGlB,YAAQ,OAAO,GAAG,QAAQ,YAAU;AAClC,gBAAU,MAAM;AAAA;AAGlB,YAAQ,GAAG,SAAS,WAAS;AAC3B,aAAO,OAAO;AAAA;AAGhB,YAAQ,GAAG,SAAS,UAAQ;AAC1B,UAAI,SAAS,GAAG;AACd,eAAO,OAAO,WAAW,8BAA8B;AAAA;AAEzD,aAAO;AAAA;AAAA;AAAA;MAsBA,0BAA0B,CACrC,SACA,iBACY;AAEZ,QAAM,eAAe,QAAQ,QAAQ,OAAO;AAE5C,MAAI,iBAAiB,YAAY,iBAAiB,UAAU;AAK1D,WAAO,aAAa,MAAM,KAAK,WAAW;AAAA;AAG5C,SAAO;AAAA;MAWI,mCAAmC,CAC9C,6BACuB;AACvB,QAAM,CAAE,MAAM,cAAc,UAAW;AAIvC,QAAM,iBAAiB,CAAC,UAAU;AAElC,MAAI,eAAe,SAAS,eAAe;AAEzC,WAAO,OAAO,QAAQ,YAAY;AAAA;AAGpC,SAAO;AAAA;AAGT,iBAAiB;AAAA,EACf,YAA4B,MAA2B,MAAe;AAA1C;AAA2B;AAAA;AAAA;AAGzD,MAAM,gBAAgBC,oBAAe,OAAO;AAAA,EAC1C,IAAIC,UAAK,IAAI;AAAA,IACX,MAAM;AAAA,IACN,OAAO;AAAA,IACP,eAAe,OAAM,EAAiB;AAAA,IACtC,WAAW,OAAE;AAtJjB;AAsJqB,qBAAiB,SAAjB,YAAyB;AAAA;AAAA,IAC1C,YAAY;AAAA,IACZ,WAAW,CAAC,MAAc,SAAkB,IAAI,WAAW,MAAM;AAAA;AAAA;MAUxD,qBAAqB,OAAO,kBAA0B;AACjE,MAAI;AACJ,MAAI;AACF,0BAAsB,MAAMC,uBAAG,SAAS,eAAe;AAAA,WAChD,OAAP;AACA,UAAM,IAAI,MACR,0CAA0C,wCAAwC,MAAM;AAAA;AAI5F,QAAM,YAAiBC,yBAAK,KAAK,qBAAqB;AAAA,IACpD,QAAQ;AAAA;AAEV,MAAI,UAAU,YAAYC,gBAAWC,eAAU,UAAU,YAAY;AACnE,UAAM,IAAI,MACR;AAAA;AAAA;MAqBO,yBAAyB,OACpC,eACA,QACA,6BACG;AACH,MAAI;AACJ,MAAI;AACF,0BAAsB,MAAMH,uBAAG,SAAS,eAAe;AAAA,WAChD,OAAP;AACA,WAAO,KACL,0CAA0C,+CAA+C,MAAM;AAEjG;AAAA;AAGF,MAAI;AACJ,MAAI;AACF,gBAAYC,yBAAK,KAAK,qBAAqB,CAAE,QAAQ;AAIrD,QAAI,OAAO,cAAc,YAAY,OAAO,cAAc,aAAa;AACrE,YAAM,IAAI,MAAM;AAAA;AAAA,WAEX,OAAP;AACA,WAAO,KACL,4BAA4B,+CAA+C,MAAM;AAEnF;AAAA;AAIF,MAAI,gBAAgB,YAAY;AAC9B,UAAM,UAAU,iCAAiC;AACjD,QAAI,YAAY,QAAW;AAEzB,UAAI,wBAAwB,SAAS,yBAAyB,OAAO;AACnE,kBAAU,WAAW;AAAA;AAAA;AAAA;AAK3B,MAAI;AACF,UAAMD,uBAAG,UACP,eACAC,yBAAK,KAAK,WAAW,CAAE,QAAQ,iBAC/B;AAAA,WAEK,OAAP;AACA,WAAO,KACL,sBAAsB,iEAAiE,MAAM;AAE/F;AAAA;AAAA;MASS,4BAA4B,OACvC,sBACA,WACkB;AAElB,MAAI;AACF,UAAMD,uBAAG,OAAO,sBAAsBA,uBAAG,UAAU;AAAA,WAC5C,KAAP;AAEA,UAAMA,uBAAG,UAAU,sBAAsB,KAAK,MAAM;AAAA;AAGtD,MAAI;AACJ,MAAI;AACF,WAAO,MAAMA,uBAAG,SAAS;AAAA,WAClB,KAAP;AACA,UAAM,UAAU,mBAAmB,mCAAmC,IAAI;AAC1E,WAAO,MAAM;AACb,UAAM,IAAI,MAAM;AAAA;AAGlB,OAAK,kBAAkB,KAAK;AAC5B,QAAMA,uBAAG,UAAU,sBAAsB;AACzC;AAAA;MAWW,oBAAoB,OAC/B,sBACA,SACkB;AAClB,QAAM,OAAO,MAAMA,uBAAG,SAAS;AAC/B,OAAK,OAAO;AACZ,QAAMA,uBAAG,UAAU,sBAAsB;AAAA;;ACtQ3C,MAAM,eAAe,MAA+B;AAClD,QAAM,MAAM;AAEZ,QAAMI,WAAS,IAAIR;AACnB,WAAO,GAAG,QAAQ,WAAS;AACzB,UAAM,YAAY,MAAM,WAAW;AACnC,QAAI,wCAAW,UAAS;AAAG,UAAI,KAAK;AAAA;AAGtC,SAAO,CAAC,KAAKQ;AAAA;wBAGyC;AAAA,EAKtD,YAAY;AAAA,IACV;AAAA,IACA;AAAA,IACA;AAAA,KAKC;AA9DL;AA+DI,SAAK,SAAS;AACd,SAAK,UAAU;AAAA,MACb,gBACE,aAAO,kBAAkB,oCAAzB,YAA4D;AAAA;AAEhE,SAAK,kBAAkB;AAAA;AAAA,QAGZ,IAAI;AAAA,IACf;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,KACqC;AACrC,UAAM,CAAC,KAAK,aAAa;AAKzB,UAAM,gBAAgBC,yBAAK,KAAK,UAAU;AAC1C,QAAI,0BAA0B;AAC5B,YAAM,uBACJ,eACA,KAAK,QACL;AAAA;AAIJ,UAAM,mBAAmB;AAGzB,UAAM,YAAY;AAAA,OACf,WAAW;AAAA,OACX,YAAY;AAAA;AAGf,QAAI;AACF,cAAQ,KAAK,QAAQ;AAAA,aACd;AACH,gBAAM,WAAW;AAAA,YACf,SAAS;AAAA,YACT,MAAM,CAAC,SAAS,MAAM,WAAW;AAAA,YACjC,SAAS;AAAA,cACP,KAAK;AAAA;AAAA,YAEP;AAAA;AAEF,eAAK,OAAO,KACV,oCAAoC,iBAAiB;AAEvD;AAAA,aACG;AACH,gBAAM,KAAK,gBAAgB,aAAa;AAAA,YACtC,WAAW;AAAA,YACX,MAAM,CAAC,SAAS,MAAM;AAAA,YACtB;AAAA,YACA;AAAA,YACA,YAAY;AAAA,YAGZ,SAAS,CAAE,MAAM;AAAA;AAEnB,eAAK,OAAO,KACV,oCAAoC,iBAAiB;AAEvD;AAAA;AAEA,gBAAM,IAAI,MACR,yBAAyB,KAAK,QAAQ;AAAA;AAAA,aAGrC,OAAP;AACA,WAAK,OAAO,MACV,gCAAgC,iBAAiB;AAEnD,WAAK,OAAO,MAAM,4BAA4B;AAC9C,YAAM,IAAI,MACR,gCAAgC,iBAAiB,wBAAwB,MAAM;AAAA;AAUnF,UAAM,0BACJA,yBAAK,KAAK,WAAW,2BACrB,KAAK;AAKP,QAAI,MAAM;AACR,YAAM,kBACJA,yBAAK,KAAK,WAAW,2BACrB;AAAA;AAAA;AAAA;;iBCpI4C;AAAA,EAA7C,cA5BP;AA6BU,wBAAe,IAAI;AAAA;AAAA,eAEd,WACX,QACA;AAAA,IACE;AAAA,IACA;AAAA,KAEyB;AAC3B,UAAM,aAAa,IAAI;AAEvB,UAAM,oBAAoB,IAAI,kBAAkB;AAAA,MAC9C;AAAA,MACA;AAAA,MACA;AAAA;AAEF,eAAW,SAAS,YAAY;AAEhC,WAAO;AAAA;AAAA,EAGT,SAAS,cAAqC,WAA0B;AACtE,SAAK,aAAa,IAAI,cAAc;AAAA;AAAA,EAGtC,IAAI,QAA+B;AACjC,UAAM,eAAe,gBAAgB;AACrC,UAAM,YAAY,KAAK,aAAa,IAAI;AAExC,QAAI,CAAC,WAAW;AACd,YAAM,IAAI,MAAM,wCAAwC;AAAA;AAG1D,WAAO;AAAA;AAAA;;oBCpCgB,KAAqB;AAC9C,QAAM,CAAE,YAAaC,gCAAY;AACjC,SAAO;AAAA;wBAGsB,KAAqB;AA/BpD;AAgCE,QAAM,cAAc;AAAA,IAClB,CAAE,KAAK,YAAY,MAAM;AAAA,IACzB,CAAE,KAAK,YAAY,MAAM;AAAA,IACzB,CAAE,KAAK,WAAW,MAAM;AAAA;AAG1B,QAAM,OAAO,kBAAY,OAAO,UAAQ,KAAK,IAAI,KAAK,MAAM,OAA/C,mBAAmD;AAEhE,SAAO;AAAA;MAGI,6BAA6B,CACxC,QACA,SAC4B;AA9C9B;AA+CE,QAAM,mBAAmBC,yCACvB,aAAO,uBAAuB,2BAA9B,YAAwD;AAE1D,QAAM,0BAA0B,iBAAiB,KAAK,OAAK,EAAE,SAAS;AACtE,MAAI,CAAC,yBAAyB;AAC5B,UAAM,IAAI,MAAM,oDAAoD;AAAA;AAEtE,SAAO;AAAA;MAGI,6BAA6B,CACxC,QACA,SAC4B;AA5D9B;AA6DE,QAAM,mBAAmBC,yCACvB,aAAO,uBAAuB,2BAA9B,YAAwD;AAE1D,QAAM,0BAA0B,iBAAiB,KAAK,OAAK,EAAE,SAAS;AACtE,MAAI,CAAC,yBAAyB;AAC5B,UAAM,IAAI,MAAM,oDAAoD;AAAA;AAEtE,SAAO;AAAA;MAGI,4BAA4B,CACvC,QACA,SAC2B;AA1E7B;AA2EE,QAAM,4BAA4BC,wCAChC,aAAO,uBAAuB,0BAA9B,YAAuD;AAEzD,QAAM,yBAAyB,0BAA0B,KACvD,OAAK,EAAE,SAAS;AAElB,MAAI,CAAC,wBAAwB;AAC3B,UAAM,IAAI,MAAM,mDAAmD;AAAA;AAErE,SAAO;AAAA;MAGI,qBAAqB,OAChC,eACA,WACgC;AAChC,QAAM,OAAO,WAAW;AACxB,QAAM,OAAO,eAAe;AAE5B,MAAI;AACF,YAAQ;AAAA,WACD;AACH,eAAO,2BAA2B,QAAQ,MAAM;AAAA,WAC7C;AACH,eAAO,2BAA2B,QAAQ,MAAM;AAAA,WAC7C;AACH,eAAO,0BAA0B,QAAQ,MAAM;AAAA;AAE/C,cAAM,IAAI,MAAM;AAAA;AAAA,WAEb,OAAP;AACA,UAAM;AAAA;AAAA;;ACnDV,yBAAyB,QAAgB,KAAkB;AAvD3D;AAwDE,QAAM,CAAE,UAAU,OAAO,QAASH,gCAAY;AAC9C,QAAM,kBACJ,aAAO,uBAAuB,2BAA9B,YAAwD;AAE1D,QAAM,aAAa,gBAAgB,OACjC,oBAAkB,eAAe,kBAAkB,YAAY;AAGjE,QAAM,aACJ,uBAAW,OAAX,mBAAe,kBAAkB,kBAAjC,YAAkD;AACpD,QAAM,WAAW;AAEjB,SAAO,IAAI,IAAI,GAAG,cAAc,YAAY,SAAS;AAAA;AAGvD,yBAAyB,KAAkB;AACzC,QAAM,CAAE,UAAU,UAAU,WAAW,YAAaA,gCAAY;AAChE,QAAM,sBAAsB;AAC5B,QAAM,UAAU,mBAAmB;AACnC,QAAM,WAAW;AAEjB,SAAO,IAAI,IACT,GAAG,cAAc,YAAY,uBAAuB,WAAW;AAAA;AAInE,wBAAwB,KAAkB;AACxC,QAAM,CAAE,UAAU,UAAU,cAAc,OAAO,QAASA,gCAAY;AACtE,QAAM,cAAc;AACpB,QAAM,aAAa;AAEnB,SAAO,IAAI,IACT,GAAG,cAAc,YAAY,gBAAgB,SAAS,eAAe,QAAQ;AAAA;AAIjF,sCACE,eACA,QACiB;AACjB,QAAM,OAAO,gBAAgB,QAAQ,eAAe;AACpD,QAAM,OAAO,WAAW;AAExB,QAAM,oBAAoB,2BAA2B,QAAQ;AAC7D,QAAM,UAAUI,oCAAwB;AAExC,MAAI;AACF,UAAM,MAAM,MAAMC,0BAAM,MAAM;AAE9B,QAAI,CAAC,IAAI,IAAI;AACX,YAAM,IAAI,MACR,uBAAuB,IAAI,UAAU,IAAI,4DAA4D;AAAA;AAIzG,UAAM,CAAE,gBAAgB,UAAW,MAAM,IAAI;AAE7C,QAAI,CAAC,QAAQ;AACX,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO;AAAA,WACA,OAAP;AACA,UAAM,IAAI,MAAM,wCAAwC;AAAA;AAAA;AAI5D,sCACE,eACA,QACiB;AACjB,QAAM,OAAO,gBAAgB,eAAe;AAC5C,QAAM,OAAO,WAAW;AAExB,QAAM,oBAAoB,2BAA2B,QAAQ;AAC7D,QAAM,UAAUC,oCAAwB;AAExC,MAAI;AACF,UAAM,MAAM,MAAMD,0BAAM,MAAM;AAE9B,QAAI,CAAC,IAAI,IAAI;AACX,YAAM,IAAI,MACR,uBAAuB,IAAI,UAAU,IAAI,4DAA4D;AAAA;AAIzG,UAAM,SAAS,MAAM,IAAI;AACzB,UAAM,CAAE,QAAU,WAAU,IAAI,KAC9B,CAAC,WAA0B,OAAO,YAAY;AAGhD,QAAI,CAAC,MAAM;AACT,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO;AAAA,WACA,OAAP;AACA,UAAM,IAAI,MAAM,wCAAwC;AAAA;AAAA;AAI5D,qCACE,eACA,QACiB;AACjB,QAAM,OAAO,eAAe,eAAe;AAC3C,QAAM,OAAO,WAAW;AAExB,QAAM,oBAAoB,0BAA0B,QAAQ;AAC5D,QAAM,UAAUE,mCAAuB;AAEvC,MAAI;AACF,UAAM,cAAc,MAAMF,0BAAM,MAAM;AACtC,QAAI,CAAC,YAAY,IAAI;AACnB,YAAM,IAAI,MACR,uBAAuB,YAAY,UAAU,YAAY,4DAA4D;AAAA;AAGzH,UAAM,YAAY,MAAM,YAAY;AAEpC,UAAM,aAAa,MAAMA,0BAAM,UAAU,KAAK;AAC9C,QAAI,CAAC,WAAW,IAAI;AAClB,YAAM,IAAI,MACR,uBAAuB,WAAW,UAAU,WAAW,4DAA4D,UAAU,WAAW;AAAA;AAG5I,UAAM,WAAW,MAAM,WAAW;AAClC,UAAM,OAAO,SAAS;AAEtB,QAAI,CAAC,MAAM;AACT,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO;AAAA,WACA,OAAP;AACA,UAAM,IAAI,MAAM,8CAA8C;AAAA;AAAA;MAIrD,mBAAmB,OAC9B,eACA,WACoB;AACpB,QAAM,OAAO,eAAe;AAE5B,MAAI;AACF,YAAQ;AAAA,WACD;AACH,eAAO,MAAM,uBAAuB,eAAe;AAAA,WAChD;AACH,eAAO,MAAM,uBAAuB,eAAe;AAAA,WAChD;AACH,eAAO,MAAM,sBAAsB,eAAe;AAAA;AAGlD,cAAM,IAAI,MAAM;AAAA;AAAA,WAEb,OAAP;AACA,UAAM;AAAA;AAAA;;MCpLG,2BAA2B,CACtC,gBACA,WAC6B;AArC/B;AAsCE,QAAM,aAAa,aAAO,SAAS,gBAAhB,mBAA8B;AACjD,MAAI,CAAC,YAAY;AACf,UAAM,IAAIG,kBACR,8CAA8C,OAAO,SAAS;AAAA;AAIlE,QAAM,CAAE,MAAM,UAAWC,oCAAuB;AAChD,SAAO;AAAA,IACL;AAAA,IACA;AAAA;AAAA;MAIS,uBAAuB,CAClC,WAC6B;AAC7B,QAAM,CAAE,MAAM,UAAW,yBACvB,6BACA;AAGF,UAAQ;AAAA,SACD;AAAA,SACA;AAAA,SACA;AAAA,SACA;AACH,aAAO,CAAE,MAAM;AAAA,SACZ;AACH,UAAIV,yBAAK,WAAW,SAAS;AAC3B,eAAO,CAAE,MAAM;AAAA;AAEjB,aAAO,yBACL,oCACA;AAAA;AAGF,YAAM,IAAI,MAAM,gCAAgC;AAAA;AAAA;MAIzC,6BAA6B,OACxC,eACA,WACoB;AACpB,QAAM,oBAAoBC,gCAAY;AAEtC,oBAAkB,aAAa;AAE/B,MAAI,CAAC,kBAAkB,KAAK;AAC1B,sBAAkB,MAAM,MAAM,iBAC5B,kBAAkB,SAAS,UAC3B;AAAA;AAIJ,SAAOD,yBAAK,KAEVL,uBAAG,aAAagB,uBAAG,WACnB,kBACA,kBAAkB,UAClB,kBAAkB,OAClB,kBAAkB,MAClB,kBAAkB;AAAA;MAIT,wBAAwB,OACnC,SACA,QACA,WACoB;AACpB,QAAM,oBAAoBV,gCAAY;AACtC,QAAM,oBAAoB,MAAM,2BAA2B,SAAS;AACpE,QAAM,QAAQ,MAAM,mBAAmB,SAAS;AAGhD,MAAI,MAAMW,kBAAI,SAAS,CAAE;AAIzB,MAAI,OAAO;AACT,UAAM,OAAO,eAAe;AAC5B,YAAQ;AAAA,WACD;AACH,cAAMA,kBAAI,SAAS;AAAA,UACjB,UAAU;AAAA,UACV,UAAU;AAAA,UACV;AAAA;AAEF,0BAAkB,QAAQ,kBAAkB;AAC5C;AAAA,WACG;AACH,cAAMA,kBAAI,SAAS;AAAA,UACjB,UAAU;AAAA,UACV,UAAU;AAAA,UACV;AAAA;AAEF,0BAAkB,QAAQ,iBAAiB;AAC3C,0BAAkB,aAAa;AAC/B;AAAA,WACG;AACH,cAAMA,kBAAI,SAAS;AAAA,UACjB,UAAU;AAAA,UACV,UAAU;AAAA,UACV;AAAA;AAEF;AAAA;AAEA,0BAAkB,QAAQ,IAAI;AAAA;AAAA;AAKpC,MAAIjB,uBAAG,WAAW,oBAAoB;AACpC,QAAI;AACF,YAAM,oBAAoB,MAAM,IAAI,cAAc;AAAA,QAChD,KAAK;AAAA;AAGP,YAAM,IAAI,MAAM,CAAE,KAAK,mBAAmB,QAAQ;AAClD,YAAM,IAAI,MAAM;AAAA,QACd,KAAK;AAAA,QACL,QAAQ,UAAU;AAAA,QAClB,MAAM,qBAAqB;AAAA,QAC3B,QAAQ,CAAE,MAAM,sBAAsB,OAAO;AAAA,QAC7C,WAAW;AAAA,UACT,MAAM;AAAA,UACN,OAAO;AAAA;AAAA;AAGX,aAAO;AAAA,aACA,GAAP;AACA,aAAO,KACL,gBAAgB,EAAE,kCAAkC;AAEtD,6BAAG,WAAW;AAAA;AAAA;AAIlB,QAAM,wBAAwB,kBAAkB,SAAS;AAEzD,yBAAG,UAAU,mBAAmB,CAAE,WAAW;AAC7C,QAAM,IAAI,MAAM,CAAE,KAAK,uBAAuB,KAAK;AAEnD,SAAO;AAAA;MAGI,yBAAyB,OACpC,oBACA,WACoB;AACpB,QAAM,MAAMiB,kBAAI,SAAS,CAAE;AAC3B,QAAM,MAAM,MAAM,IAAI,WAAW,CAAE,KAAK,oBAAoB,KAAK;AACjE,QAAM,SAAS,MAAM,IAAI,WAAW,CAAE,KAAK,oBAAoB;AAE/D,SAAO,OAAO,OAAO,UAAU;AAAA;MAGpB,4BAA4B,OACvC,QACA,QACA,SAC8B;AAzMhC;AA0ME,QAAM,CAAE,UAAW,yBACjB,6BACA;AAGF,qCAAM,WAAN,mBAAc,MAAM,sBAAsB;AAE1C,QAAM,mBAAmB,MAAM,OAAO,SAAS,QAAQ,CAAE,MAAM,6BAAM;AACrE,QAAM,cAAc,MAAM,iBAAiB;AAE3C,qCAAM,WAAN,mBAAc,MAAM,iCAAiC;AAErD,SAAO;AAAA,IACL;AAAA,IACA,MAAM,iBAAiB;AAAA;AAAA;;wBC1L4B;AAAA,EACrD,YACmB,QACA,QACA,QACjB;AAHiB;AACA;AACA;AAEjB,SAAK,SAAS;AACd,SAAK,SAAS;AACd,SAAK,SAAS;AAAA;AAAA,QAGF,8BACZ,QACA,SAC2B;AAC3B,UAAM,CAAE,MAAM,UAAW,yBACvB,oCACA;AAGF,SAAK,OAAO,MACV,qEAAqE;AAEvE,YAAQ;AAAA,WACD,OAAO;AACV,cAAM,WAAW,MAAM,KAAK,OAAO,SAAS,QAAQ;AAAA,UAClD,MAAM,mCAAS;AAAA;AAEjB,cAAM,cAAc,MAAM,SAAS;AACnC,eAAO;AAAA,UACL;AAAA,UACA,MAAM,SAAS;AAAA;AAAA;AAAA,WAGd;AAAA,WACA;AAAA,WACA,aAAa;AAChB,cAAM,oBAAoBX,gCAAY;AACtC,cAAM,eAAe,MAAM,sBACzB,QACA,KAAK,QACL,KAAK;AAIP,cAAM,OAAO,MAAM,uBAAuB,cAAc,KAAK;AAC7D,YAAI,oCAAS,UAAS,KAAK,YAAY;AACrC,gBAAM,IAAIY;AAAA;AAEZ,eAAO;AAAA,UACL,aAAab,yBAAK,QAChBA,yBAAK,KAAK,cAAc,kBAAkB;AAAA,UAE5C,MAAM,KAAK;AAAA;AAAA;AAAA,WAGV;AACH,eAAO;AAAA,UACL,aAAaA,yBAAK,QAAQ;AAAA,UAE1B,MAAM;AAAA;AAAA;AAGR,cAAM,IAAIS,kBAAW,mCAAmC;AAAA;AAAA;AAAA,QAIxD,QAAQ,QAA2C;AACvD,SAAK,OAAO,KACV;AAKF,UAAM,CAAE,UAAW,yBACjB,6BACA;AAIF,UAAM,WAAW,MAAM,KAAK,8BAA8B;AAE1D,WAAO;AAAA,MACL,aAAaT,yBAAK,QAAQ,SAAS,aAAa;AAAA,MAChD,MAAM,SAAS;AAAA;AAAA;AAAA;;wBCtFkC;AAAA,EAIrD,YAAY,QAAgB,QAAgB;AAC1C,SAAK,SAAS;AACd,SAAK,SAAS;AAAA;AAAA,QAGV,QACJ,QACA,SAC2B;AAC3B,SAAK,OAAO,KACV,2DAA2D,OAAO,SAAS;AAK7E,UAAM,CAAE,UAAW,yBACjB,6BACA;AAGF,QAAI;AAEF,YAAM,WAAW,MAAM,sBACrB,QACA,KAAK,QACL,KAAK;AAGP,YAAM,OAAO,MAAM,uBAAuB,UAAU,KAAK;AACzD,UAAI,oCAAS,UAAS,KAAK,YAAY;AACrC,cAAM,IAAIa;AAAA;AAGZ,YAAM,oBAAoBZ,gCAAY;AACtC,aAAO;AAAA,QACL,aAAaD,yBAAK,KAAK,UAAU,kBAAkB;AAAA,QACnD,MAAM,KAAK;AAAA;AAAA,aAEN,OAAP;AACA,UAAI,iBAAiBa,yBAAkB;AACrC,aAAK,OAAO,MAAM,2BAA2B,mCAAS;AAAA,aACjD;AACL,aAAK,OAAO,MAAM,mCAAmC,MAAM;AAAA;AAE7D,YAAM;AAAA;AAAA;AAAA;;kBCrDqC;AAAA,EAI/C,YAAY,QAAmB,QAAgB;AAC7C,SAAK,SAAS;AACd,SAAK,SAAS;AAAA;AAAA,QAGV,QACJ,QACA,SAC2B;AAC3B,QAAI;AACF,aAAO,MAAM,0BAA0B,KAAK,QAAQ,QAAQ;AAAA,QAC1D,MAAM,mCAAS;AAAA,QACf,QAAQ,KAAK;AAAA;AAAA,aAER,OAAP;AAEA,UAAI,iBAAiBA,yBAAkB;AACrC,aAAK,OAAO,MAAM,2BAA2B,mCAAS;AAAA,aACjD;AACL,aAAK,OAAO,MACV,2CAA2C,MAAM;AAAA;AAIrD,YAAM;AAAA;AAAA;AAAA;;gBCrBsC;AAAA,EAA3C,cA9BP;AA+BU,uBAAc,IAAI;AAAA;AAAA,eAEb,WACX,QACA,CAAE,QAAQ,SACgB;AAC1B,UAAM,YAAY,IAAI;AAEtB,UAAM,cAAc,IAAI,YAAY,QAAQ;AAC5C,cAAU,SAAS,OAAO;AAM1B,UAAM,oBAAoB,IAAI,kBAAkB,QAAQ,QAAQ;AAChE,cAAU,SAAS,OAAO;AAG1B,UAAM,oBAAoB,IAAI,kBAAkB,QAAQ;AACxD,cAAU,SAAS,UAAU;AAC7B,cAAU,SAAS,UAAU;AAC7B,cAAU,SAAS,aAAa;AAEhC,WAAO;AAAA;AAAA,EAGT,SAAS,UAA0B,UAAwB;AACzD,SAAK,YAAY,IAAI,UAAU;AAAA;AAAA,EAGjC,IAAI,QAA8B;AAChC,UAAM,CAAE,QAAS,yBACf,6BACA;AAEF,UAAM,WAAW,KAAK,YAAY,IAAI;AAEtC,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,MAAM,qCAAqC;AAAA;AAGvD,WAAO;AAAA;AAAA;;ACnDX,MAAM,6BAA6B,CAAC,QAAwB;AAC1D,QAAM,qBAAqB;AAI3B,MAAI,IAAI,MAAM,iBAAiB;AAC7B,WAAO;AAAA;AAGT,SAAOC,yBAAK,YAAY,QAAQ;AAAA;MAYrB,6BAA6B,CACxC,kBACwB;AACxB,SAAO;AAAA,IACL,gBAAgB,2BAA2B;AAAA;AAAA;MA4BlC,yBAAyB,OACpC,gBACsB;AAEtB,QAAM,WAAW,MAAMC,qCAAiB,aAAa,MAAM,WAAS;AAClE,UAAM,IAAI,MAAM,sCAAsC,MAAM;AAAA;AAE9D,SAAO;AAAA;;AC/CT,MAAM,iBAAiB,CAAC,WAAsC;AAC5D,SAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,QAAI;AACF,YAAM,SAAgB;AACtB,aAAO,GAAG,QAAQ,WAAS,OAAO,KAAK;AACvC,aAAO,GAAG,SAAS;AACnB,aAAO,GAAG,OAAO,MAAM,QAAQ,OAAO,OAAO;AAAA,aACtC,GAAP;AACA,YAAM,IAAI,MAAM,qCAAqC,EAAE;AAAA;AAAA;AAAA;mBAKV;AAAA,EAiFjD,YACmB,eACA,YACA,QACjB;AAHiB;AACA;AACA;AAEjB,SAAK,gBAAgB;AACrB,SAAK,aAAa;AAClB,SAAK,SAAS;AAAA;AAAA,SAvFT,WAAW,QAAgB,QAA+B;AAC/D,QAAI,aAAa;AACjB,QAAI;AACF,mBAAa,OAAO,UAAU;AAAA,aACvB,OAAP;AACA,YAAM,IAAI,MACR;AAAA;AAYJ,UAAM,oBAAoB,OAAO,kBAC/B;AAEF,UAAM,cAAc,aAAa,iBAAiB;AAIlD,UAAM,SAAS,OAAO,kBAAkB;AAIxC,UAAM,WAAW,OAAO,kBACtB;AAKF,UAAM,mBAAmB,OAAO,mBAC9B;AAGF,UAAM,gBAAgB,IAAIC,wBAAI,GAAG;AAAA,MAC/B;AAAA,SACI,UAAU,CAAE;AAAA,SACZ,YAAY,CAAE;AAAA,SACd,oBAAoB,CAAE;AAAA;AAG5B,WAAO,IAAI,aAAa,eAAe,YAAY;AAAA;AAAA,SAGtC,iBACb,QAC8C;AAC9C,QAAI,CAAC,QAAQ;AACX,aAAO;AAAA;AAGT,UAAM,cAAc,OAAO,kBAAkB;AAC7C,UAAM,kBAAkB,OAAO,kBAAkB;AACjD,QAAI;AACJ,QAAI,eAAe,iBAAiB;AAClC,4BAAsB,IAAIC,gBAAY;AAAA,QACpC;AAAA,QACA;AAAA;AAAA;AAIJ,UAAM,UAAU,OAAO,kBAAkB;AACzC,QAAI,SAAS;AACX,aAAO,IAAID,wBAAI,8BAA8B;AAAA,QAC3C,mBAAmB;AAAA,QACnB,QAAQ;AAAA,UACN,iBAAiB;AAAA,UACjB,SAAS;AAAA;AAAA;AAAA;AAKf,WAAO;AAAA;AAAA,QAiBH,eAA2C;AAC/C,QAAI;AACF,YAAM,KAAK,cACR,WAAW,CAAE,QAAQ,KAAK,aAC1B;AAEH,WAAK,OAAO,KACV,+CAA+C,KAAK;AAGtD,aAAO,CAAE,aAAa;AAAA,aACf,OAAP;AACA,WAAK,OAAO,MACV,uDAAuD,KAAK;AAK9D,WAAK,OAAO,MAAM,2BAA2B;AAC7C,aAAO;AAAA,QACL,aAAa;AAAA;AAAA;AAAA;AAAA,QASb,QAAQ,CAAE,QAAQ,YAA4C;AAClE,QAAI;AAGF,YAAM,mBAAmB,MAAM,uBAAuB;AAEtD,YAAM,UAAUE,kCAAc;AAC9B,YAAM,iBAAyD;AAC/D,iBAAW,YAAY,kBAAkB;AAIvC,cAAM,mBAAmBlB,yBAAK,SAAS,WAAW;AAKlD,cAAM,wBAAwB,iBAC3B,MAAMA,yBAAK,KACX,KAAKA,yBAAK,MAAM;AAGnB,cAAM,gBAAgB,GAAG,OAAO,SAAS,aAAa,OAAO,QAAQ,OAAO,SAAS;AACrF,cAAM,cAAc,GAAG,iBAAiB;AAGxC,cAAM,aAAa,QAAQ,MAAM;AAC/B,gBAAM,aAAaL,uBAAG,iBAAiB;AAEvC,gBAAM,SAAS;AAAA,YACb,QAAQ,KAAK;AAAA,YACb,KAAK;AAAA,YACL,MAAM;AAAA;AAGR,iBAAO,KAAK,cAAc,OAAO,QAAQ;AAAA;AAE3C,uBAAe,KAAK;AAAA;AAEtB,YAAM,QAAQ,IAAI;AAClB,WAAK,OAAO,KACV,4DAA4D,OAAO,SAAS,gCAAgC,iBAAiB;AAE/H;AAAA,aACO,GAAP;AACA,YAAM,eAAe,uCAAuC;AAC5D,WAAK,OAAO,MAAM;AAClB,YAAM,IAAI,MAAM;AAAA;AAAA;AAAA,QAId,sBACJ,YAC2B;AAC3B,QAAI;AACF,aAAO,MAAM,IAAI,QAA0B,OAAO,SAAS,WAAW;AACpE,cAAM,gBAAgB,GAAG,WAAW,aAAa,WAAW,QAAQ,WAAW;AAE/E,cAAM,SAAS,KAAK,cACjB,UAAU;AAAA,UACT,QAAQ,KAAK;AAAA,UACb,KAAK,GAAG;AAAA,WAET;AAEH,YAAI;AACF,gBAAM,uBAAuB,MAAM,eAAe;AAClD,cAAI,CAAC,sBAAsB;AACzB,kBAAM,IAAI,MACR,8CAA8C;AAAA;AAIlD,gBAAM,mBAAmBwB,0BAAM,MAC7B,qBAAqB,SAAS;AAGhC,kBAAQ;AAAA,iBACD,KAAP;AACA,eAAK,OAAO,MAAM,IAAI;AACtB,iBAAO,IAAI,MAAM,IAAI;AAAA;AAAA;AAAA,aAGlB,GAAP;AACA,YAAM,IAAI,MAAM,mCAAmC,EAAE;AAAA;AAAA;AAAA,EAOzD,aAA8B;AAC5B,WAAO,OAAO,KAAK,QAAQ;AAGzB,YAAM,WAAW,UAAU,IAAI,KAAK,QAAQ,OAAO;AAGnD,YAAM,gBAAgBnB,yBAAK,QAAQ;AACnC,YAAM,kBAAkB,2BAA2B;AAEnD,YAAM,SAAS,KAAK,cACjB,UAAU,CAAE,QAAQ,KAAK,YAAY,KAAK,WAC1C;AACH,UAAI;AAEF,mBAAW,CAAC,WAAW,gBAAgB,OAAO,QAC5C,kBACC;AACD,cAAI,UAAU,WAAW;AAAA;AAG3B,YAAI,KAAK,MAAM,eAAe;AAAA,eACvB,KAAP;AACA,aAAK,OAAO,KAAK,IAAI;AACrB,YAAI,OAAO,KAAK,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA,QASzB,qBAAqB,QAAkC;AAC3D,QAAI;AACF,YAAM,gBAAgB,GAAG,OAAO,SAAS,aAAa,OAAO,QAAQ,OAAO,SAAS;AACrF,YAAM,KAAK,cACR,WAAW;AAAA,QACV,QAAQ,KAAK;AAAA,QACb,KAAK,GAAG;AAAA,SAET;AACH,aAAO,QAAQ,QAAQ;AAAA,aAChB,GAAP;AACA,aAAO,QAAQ,QAAQ;AAAA;AAAA;AAAA;;AC/Q7B,MAAM,oBAAoB;8BAEoC;AAAA,EA+C5D,YACmB,eACA,eACA,QACjB;AAHiB;AACA;AACA;AAEjB,SAAK,gBAAgB;AACrB,SAAK,gBAAgB;AACrB,SAAK,SAAS;AAAA;AAAA,SArDT,WAAW,QAAgB,QAA+B;AAC/D,QAAI,gBAAgB;AACpB,QAAI;AACF,sBAAgB,OAAO,UACrB;AAAA,aAEK,OAAP;AACA,YAAM,IAAI,MACR;AAAA;AAKJ,QAAI,cAAc;AAClB,QAAI;AACF,oBAAc,OAAO,UACnB;AAAA,aAEK,OAAP;AACA,YAAM,IAAI,MACR;AAAA;AAOJ,UAAM,aAAa,OAAO,kBACxB;AAGF,QAAI;AACJ,QAAI,YAAY;AACd,mBAAa,IAAIoB,uCAA2B,aAAa;AAAA,WACpD;AACL,mBAAa,IAAIC;AAAA;AAGnB,UAAM,gBAAgB,IAAIC,8BACxB,WAAW,qCACX;AAGF,WAAO,IAAI,wBAAwB,eAAe,eAAe;AAAA;AAAA,QAa7D,eAA2C;AAC/C,QAAI;AACF,YAAM,WAAW,MAAM,KAAK,cACzB,mBAAmB,KAAK,eACxB;AAEH,UAAI,SAAS,UAAU,WAAW,KAAK;AACrC,eAAO;AAAA,UACL,aAAa;AAAA;AAAA;AAIjB,UAAI,SAAS,UAAU,UAAU,KAAK;AACpC,aAAK,OAAO,MACV,oCAAoC,SAAS,UAAU,QAAQ,wBAAwB,SAAS,UAAU;AAAA;AAAA,aAGvG,GAAP;AACA,WAAK,OAAO,MAAM,2CAA2C,EAAE;AAAA;AAGjE,SAAK,OAAO,MACV,sEAAsE,KAAK;AAM7E,WAAO,CAAE,aAAa;AAAA;AAAA,QAOlB,QAAQ,CAAE,QAAQ,YAA4C;AAClE,QAAI;AAGF,YAAM,mBAAmB,MAAM,uBAAuB;AAKtD,YAAM,UAAUC,kCAAe;AAE/B,YAAM,WAAW,iBAAiB,IAAI,oBAAkB;AAItD,cAAM,mBAAmBvB,yBAAK,UAC5BA,yBAAK,SAAS,WAAW;AAM3B,cAAM,wBAAwB,iBAC3B,MAAMA,yBAAK,KACX,KAAKA,yBAAK,MAAM;AAGnB,cAAM,gBAAgB,GAAG,OAAO,SAAS,aAAa,OAAO,QAAQ,OAAO,SAAS;AACrF,cAAM,cAAc,GAAG,iBAAiB;AACxC,eAAO,QAAQ,YAAY;AACzB,gBAAM,WAAW,MAAM,KAAK,cACzB,mBAAmB,KAAK,eACxB,mBAAmB,aACnB,WAAW;AAEd,cAAI,SAAS,UAAU,UAAU,KAAK;AACpC,mBAAO;AAAA,iBACF;AAAA,cACH,OAAO,IAAI,MACT,qBAAqB,mCAAmC,SAAS,UAAU;AAAA;AAAA;AAIjF,iBAAO;AAAA,eACF;AAAA,YACH,OAAO;AAAA;AAAA;AAAA;AAKb,YAAM,YAAY,MAAM,QAAQ,IAAI;AAEpC,YAAM,SAAS,UAAU,OAAO,OAAK,EAAE;AACvC,UAAI,OAAO,WAAW,GAAG;AACvB,aAAK,OAAO,KACV,6BAA6B,UAAU,uCAAuC,OAAO,SAAS,gCAAgC,iBAAiB;AAAA,aAE5I;AACL,cAAM,IAAI,MACR,OACG,IAAI,OAAE;AA9LnB;AA8LsB,yBAAE,UAAF,mBAAS;AAAA,WAClB,OAAO,SACP,KAAK;AAAA;AAAA,aAGL,GAAP;AACA,YAAM,eAAe,mDAAmD;AACxE,WAAK,OAAO,MAAM;AAClB,YAAM,IAAI,MAAM;AAAA;AAAA;AAAA,EAIZ,SAAS,eAAuB,UAAmC;AACzE,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,YAAM,mBAA+B;AACrC,WAAK,cACF,mBAAmB,eACnB,mBAAmB,UACnB,WACA,KAAK,SAAO;AACX,cAAM,OAAO,IAAI;AACjB,YAAI,CAAC,MAAM;AACT,iBAAO,IAAI,MAAM;AACjB;AAAA;AAEF,aACG,GAAG,SAAS,QACZ,GAAG,QAAQ,WAAS;AACnB,2BAAiB,KAAK;AAAA,WAEvB,GAAG,OAAO,MAAM;AACf,kBAAQ,OAAO,OAAO;AAAA;AAAA,SAG3B,MAAM;AAAA;AAAA;AAAA,QAIP,sBACJ,YAC2B;AAC3B,UAAM,gBAAgB,GAAG,WAAW,aAAa,WAAW,QAAQ,WAAW;AAC/E,QAAI;AACF,YAAM,uBAAuB,MAAM,KAAK,SACtC,KAAK,eACL,GAAG;AAEL,UAAI,CAAC,sBAAsB;AACzB,cAAM,IAAI,MACR,8CAA8C;AAAA;AAGlD,YAAM,mBAAmBmB,0BAAM,MAC7B,qBAAqB,SAAS;AAEhC,aAAO;AAAA,aACA,GAAP;AACA,YAAM,IAAI,MAAM,mCAAmC,EAAE;AAAA;AAAA;AAAA,EAOzD,aAA8B;AAC5B,WAAO,CAAC,KAAK,QAAQ;AAGnB,YAAM,WAAW,UAAU,IAAI,KAAK,QAAQ,OAAO;AAEnD,YAAM,gBAAgBK,yBAAa,QAAQ;AAC3C,YAAM,kBAAkB,2BAA2B;AAEnD,UAAI;AACF,aAAK,SAAS,KAAK,eAAe,UAAU,KAAK,iBAAe;AAE9D,qBAAW,CAAC,WAAW,gBAAgB,OAAO,QAC5C,kBACC;AACD,gBAAI,UAAU,WAAW;AAAA;AAE3B,cAAI,KAAK;AAAA;AAAA,eAEJ,GAAP;AACA,aAAK,OAAO,MAAM,EAAE;AACpB,YAAI,OAAO,KAAK,KAAK,EAAE;AAAA;AAAA;AAAA;AAAA,EAS7B,qBAAqB,QAAkC;AACrD,UAAM,gBAAgB,GAAG,OAAO,SAAS,aAAa,OAAO,QAAQ,OAAO,SAAS;AACrF,WAAO,KAAK,cACT,mBAAmB,KAAK,eACxB,mBAAmB,GAAG,4BACtB;AAAA;AAAA;;uBC9PgD;AAAA,EAqCrD,YACmB,eACA,YACA,QACjB;AAHiB;AACA;AACA;AAEjB,SAAK,gBAAgB;AACrB,SAAK,aAAa;AAClB,SAAK,SAAS;AAAA;AAAA,SA3CT,WAAW,QAAgB,QAA+B;AAC/D,QAAI,aAAa;AACjB,QAAI;AACF,mBAAa,OAAO,UAAU;AAAA,aACvB,OAAP;AACA,YAAM,IAAI,MACR;AAAA;AAOJ,UAAM,cAAc,OAAO,kBACzB;AAEF,QAAI,kBAAkB;AACtB,QAAI,aAAa;AACf,UAAI;AACF,0BAAkB,KAAK,MAAM;AAAA,eACtB,KAAP;AACA,cAAM,IAAI,MACR;AAAA;AAAA;AAKN,UAAM,gBAAgB,IAAIC,gBAAQ;AAAA,SAC5B,eAAe;AAAA,QACjB,aAAa;AAAA;AAAA;AAIjB,WAAO,IAAI,iBAAiB,eAAe,YAAY;AAAA;AAAA,QAiBnD,eAA2C;AAC/C,QAAI;AACF,YAAM,KAAK,cAAc,OAAO,KAAK,YAAY;AACjD,WAAK,OAAO,KACV,4CAA4C,KAAK;AAGnD,aAAO;AAAA,QACL,aAAa;AAAA;AAAA,aAER,KAAP;AACA,WAAK,OAAO,MACV,oDAAoD,KAAK;AAK3D,WAAK,OAAO,MAAM,4BAA4B,IAAI;AAElD,aAAO,CAAE,aAAa;AAAA;AAAA;AAAA,QAQpB,QAAQ,CAAE,QAAQ,YAA4C;AAClE,QAAI;AAGF,YAAM,mBAAmB,MAAM,uBAAuB;AAEtD,YAAM,UAAUP,kCAAc;AAC9B,YAAM,iBAAiD;AACvD,uBAAiB,QAAQ,oBAAkB;AAIzC,cAAM,mBAAmBlB,yBAAK,SAAS,WAAW;AAKlD,cAAM,wBAAwB,iBAC3B,MAAMA,yBAAK,KACX,KAAKA,yBAAK,MAAM;AAGnB,cAAM,gBAAgB,GAAG,OAAO,SAAS,aAAa,OAAO,QAAQ,OAAO,SAAS;AACrF,cAAM,cAAc,GAAG,iBAAiB;AAGxC,cAAM,aAAa,QAAQ,MACzB,KAAK,cAAc,OAAO,KAAK,YAAY,OAAO,gBAAgB;AAAA,UAChE;AAAA;AAGJ,uBAAe,KAAK;AAAA;AAGtB,YAAM,QAAQ,IAAI;AAElB,WAAK,OAAO,KACV,4DAA4D,OAAO,SAAS,gCAAgC,iBAAiB;AAAA,aAExH,GAAP;AACA,YAAM,eAAe,qDAAqD;AAC1E,WAAK,OAAO,MAAM;AAClB,YAAM,IAAI,MAAM;AAAA;AAAA;AAAA,EAIpB,sBAAsB,YAAmD;AACvE,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,YAAM,gBAAgB,GAAG,WAAW,aAAa,WAAW,QAAQ,WAAW;AAE/E,YAAM,mBAA+B;AACrC,WAAK,cACF,OAAO,KAAK,YACZ,KAAK,GAAG,wCACR,mBACA,GAAG,SAAS,SAAO;AAClB,aAAK,OAAO,MAAM,IAAI;AACtB,eAAO;AAAA,SAER,GAAG,QAAQ,WAAS;AACnB,yBAAiB,KAAK;AAAA,SAEvB,GAAG,OAAO,MAAM;AACf,cAAM,uBAAuB,OAAO,OAAO,kBAAkB,SAC3D;AAEF,gBAAQmB,0BAAM,MAAM;AAAA;AAAA;AAAA;AAAA,EAQ5B,aAA8B;AAC5B,WAAO,CAAC,KAAK,QAAQ;AAGnB,YAAM,WAAW,UAAU,IAAI,KAAK,QAAQ,OAAO;AAGnD,YAAM,gBAAgBnB,yBAAK,QAAQ;AACnC,YAAM,kBAAkB,2BAA2B;AAGnD,WAAK,cACF,OAAO,KAAK,YACZ,KAAK,UACL,mBACA,GAAG,QAAQ,MAAM;AAChB,YAAI,UAAU,KAAK;AAAA,SAEpB,GAAG,SAAS,SAAO;AAClB,aAAK,OAAO,KAAK,IAAI;AAErB,YAAI,CAAC,IAAI,aAAa;AACpB,cAAI,OAAO,KAAK,KAAK,IAAI;AAAA,eACpB;AACL,cAAI;AAAA;AAAA,SAGP,KAAK;AAAA;AAAA;AAAA,QAQN,qBAAqB,QAAkC;AAC3D,WAAO,IAAI,QAAQ,aAAW;AAC5B,YAAM,gBAAgB,GAAG,OAAO,SAAS,aAAa,OAAO,QAAQ,OAAO,SAAS;AACrF,WAAK,cACF,OAAO,KAAK,YACZ,KAAK,GAAG,4BACR,SACA,KAAK,CAAC,aAAiC;AACtC,gBAAQ,SAAS;AAAA,SAElB,MAAM,MAAM;AACX,gBAAQ;AAAA;AAAA;AAAA;AAAA;;ACpMlB,IAAI,gBAAgB;AACpB,IAAI;AACF,kBAAgB0B,iCACd,sCACA;AAAA,SAEK,KAAP;AAIA,kBAAgBf,uBAAG;AAAA;mBAO8B;AAAA,EAIjD,YAEmB,QACA,QACA,WACjB;AAHiB;AACA;AACA;AAEjB,SAAK,SAAS;AACd,SAAK,SAAS;AACd,SAAK,YAAY;AAAA;AAAA,QAGb,eAA2C;AAC/C,WAAO;AAAA,MACL,aAAa;AAAA;AAAA;AAAA,EAIjB,QAAQ,CAAE,QAAQ,YAAuD;AA3E3E;AA4EI,UAAM,kBAAkB,aAAO,SAAS,cAAhB,YAA6B;AAErD,UAAM,aAAaX,yBAAK,KACtB,eACA,iBACA,OAAO,MACP,OAAO,SAAS;AAGlB,QAAI,CAACL,uBAAG,WAAW,aAAa;AAC9B,WAAK,OAAO,KAAK,kBAAkB;AACnC,6BAAG,UAAU,YAAY,CAAE,WAAW;AAAA;AAGxC,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,6BAAG,KAAK,WAAW,YAAY,SAAO;AACpC,YAAI,KAAK;AACP,eAAK,OAAO,MACV,4BAA4B,gBAAgB;AAE9C,iBAAO;AAAA;AAET,aAAK,OAAO,KAAK,4BAA4B;AAC7C,aAAK,UACF,WAAW,YACX,KAAK,oBAAkB;AACtB,kBAAQ;AAAA,YACN,WAAW,GAAG,8BAA8B,OAAO,SAAS;AAAA;AAAA,WAG/D,MAAM,YAAU;AACf,iBAAO;AAAA;AAAA;AAAA;AAAA;AAAA,QAMX,sBACJ,YAC2B;AAC3B,UAAM,eAAeK,yBAAK,KACxB,eACA,WAAW,WACX,WAAW,MACX,WAAW,MACX;AAGF,QAAI;AACF,aAAO,MAAML,uBAAG,SAAS;AAAA,aAClB,KAAP;AACA,WAAK,OAAO,MACV,4CAA4C,wBAAwB;AAEtE,YAAM,IAAI,MAAM,IAAI;AAAA;AAAA;AAAA,EAIxB,aAA8B;AAC5B,WAAOgC,4BAAQ,OAAO,eAAe;AAAA,MAEnC,YAAY,CAAC,KAAK,aAAa;AAC7B,cAAM,gBAAgB3B,yBAAK,QAAQ;AACnC,cAAM,UAAU,2BAA2B;AAC3C,mBAAW,CAAC,QAAQ,UAAU,OAAO,QAAQ,UAAU;AACrD,cAAI,UAAU,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA,QAMxB,qBAAqB,QAAkC;AAnJ/D;AAoJI,UAAM,YAAY,aAAO,SAAS,cAAhB,YAA6B;AAE/C,UAAM,gBAAgBA,yBAAK,KACzB,eACA,WACA,OAAO,MACP,OAAO,SAAS,MAChB;AAIF,QAAI;AACF,YAAML,uBAAG,OAAO,eAAeA,uBAAG,UAAU;AAC5C,aAAO;AAAA,aACA,KAAP;AACA,aAAO;AAAA;AAAA;AAAA;;AClIb,MAAMiC,mBAAiB,CAAC,WAAsC;AAC5D,SAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,QAAI;AACF,YAAM,SAAgB;AACtB,aAAO,GAAG,QAAQ,WAAS,OAAO,KAAK;AACvC,aAAO,GAAG,SAAS;AACnB,aAAO,GAAG,OAAO,MAAM,QAAQ,OAAO,OAAO;AAAA,aACtC,GAAP;AACA,YAAM,IAAI,MAAM,qCAAqC,EAAE;AAAA;AAAA;AAAA;4BAKD;AAAA,EAkC1D,YACmB,eACA,eACA,QACjB;AAHiB;AACA;AACA;AAEjB,SAAK,gBAAgB;AACrB,SAAK,gBAAgB;AACrB,SAAK,SAAS;AAAA;AAAA,SAxCT,WAAW,QAAgB,QAA+B;AAC/D,QAAI,gBAAgB;AACpB,QAAI;AACF,sBAAgB,OAAO,UACrB;AAAA,aAEK,OAAP;AACA,YAAM,IAAI,MACR;AAAA;AAKJ,UAAM,uBAAuB,OAAO,UAClC;AAGF,UAAM,gBAAgBC,iBAAQ,aAAa;AAAA,MACzC,UAAU;AAAA,MACV,UAAU,qBAAqB,UAAU;AAAA,MACzC,UAAU,qBAAqB,UAAU;AAAA,MACzC,SAAS,qBAAqB,UAAU;AAAA,MACxC,qBACE,qBAAqB,kBAAkB,0BAA0B;AAAA,MACnE,UAAU,qBAAqB,kBAAkB,eAAe;AAAA,MAChE,YACE,qBAAqB,kBAAkB,iBAAiB;AAAA,MAC1D,QAAQ,qBAAqB,UAAU;AAAA;AAGzC,WAAO,IAAI,sBAAsB,eAAe,eAAe;AAAA;AAAA,EAiBjE,eAA2C;AACzC,WAAO,IAAI,QAAQ,aAAW;AAC5B,WAAK,cAAc,aAAa,KAAK,eAAe,CAAC,KAAK,cAAc;AACtE,YAAI,WAAW;AACb,eAAK,OAAO,KACV,2DAA2D,KAAK;AAElE,kBAAQ;AAAA,YACN,aAAa;AAAA;AAAA,eAEV;AACL,eAAK,OAAO,MACV,mEAAmE,KAAK;AAM1E,eAAK,OAAO,MAAM,kCAAkC,IAAI;AACxD,kBAAQ;AAAA,YACN,aAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAWjB,QAAQ,CAAE,QAAQ,YAA4C;AAClE,QAAI;AAGF,YAAM,mBAAmB,MAAM,uBAAuB;AACtD,YAAM,UAAUX,kCAAc;AAC9B,YAAM,iBAA0C;AAChD,iBAAW,YAAY,kBAAkB;AAIvC,cAAM,mBAAmBlB,yBAAK,SAAS,WAAW;AAKlD,cAAM,wBAAwB,iBAC3B,MAAMA,yBAAK,KACX,KAAKA,yBAAK,MAAM;AAGnB,cAAM,gBAAgB,GAAG,OAAO,SAAS,aAAa,OAAO,QAAQ,OAAO,SAAS;AACrF,cAAM,cAAc,GAAG,iBAAiB;AAExC,cAAM,SAAS;AAAA,UACb,WAAW,KAAK;AAAA,UAChB,QAAQ;AAAA;AAIV,cAAM,aAAa,QACjB,MACE,IAAI,QAAQ,CAAC,KAAK,QAAQ;AACxB,gBAAM,aAAaL,uBAAG,iBAAiB,UAAU;AAEjD,gBAAM,cAAc,KAAK,cAAc,OAAO;AAE9C,sBAAY,GAAG,SAAS;AAExB,sBAAY,GAAG,WAAW;AAE1B,qBAAW,KAAK;AAAA;AAGtB,uBAAe,KAAK;AAAA;AAEtB,YAAM,QAAQ,IAAI;AAClB,WAAK,OAAO,KACV,4DAA4D,OAAO,SAAS,gCAAgC,iBAAiB;AAE/H;AAAA,aACO,GAAP;AACA,YAAM,eAAe,gDAAgD;AACrE,WAAK,OAAO,MAAM;AAClB,YAAM,IAAI,MAAM;AAAA;AAAA;AAAA,QAId,sBACJ,YAC2B;AAC3B,QAAI;AACF,aAAO,MAAM,IAAI,QAA0B,OAAO,SAAS,WAAW;AACpE,cAAM,gBAAgB,GAAG,WAAW,aAAa,WAAW,QAAQ,WAAW;AAE/E,cAAM,SAAS,KAAK,cAAc,SAAS;AAAA,UACzC,WAAW,KAAK;AAAA,UAChB,QAAQ,GAAG;AAAA;AAGb,YAAI;AACF,gBAAM,uBAAuB,MAAMiC,iBAAe;AAClD,cAAI,CAAC,sBAAsB;AACzB,kBAAM,IAAI,MACR,8CAA8C;AAAA;AAIlD,gBAAM,mBAAmBT,0BAAM,MAC7B,qBAAqB,SAAS;AAGhC,kBAAQ;AAAA,iBACD,KAAP;AACA,eAAK,OAAO,MAAM,IAAI;AACtB,iBAAO,IAAI,MAAM,IAAI;AAAA;AAAA;AAAA,aAGlB,GAAP;AACA,YAAM,IAAI,MAAM,mCAAmC,EAAE;AAAA;AAAA;AAAA,EAOzD,aAA8B;AAC5B,WAAO,OAAO,KAAK,QAAQ;AAGzB,YAAM,WAAW,UAAU,IAAI,KAAK,QAAQ,OAAO;AAGnD,YAAM,gBAAgBnB,yBAAK,QAAQ;AACnC,YAAM,kBAAkB,2BAA2B;AAEnD,YAAM,SAAS,KAAK,cAAc,SAAS;AAAA,QACzC,WAAW,KAAK;AAAA,QAChB,QAAQ;AAAA;AAGV,UAAI;AAEF,mBAAW,CAAC,WAAW,gBAAgB,OAAO,QAC5C,kBACC;AACD,cAAI,UAAU,WAAW;AAAA;AAG3B,YAAI,KAAK,MAAM4B,iBAAe;AAAA,eACvB,KAAP;AACA,aAAK,OAAO,KAAK,IAAI;AACrB,YAAI,OAAO,KAAK,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA,QASzB,qBAAqB,QAAkC;AAC3D,QAAI;AACF,YAAM,gBAAgB,GAAG,OAAO,SAAS,aAAa,OAAO,QAAQ,OAAO,SAAS;AAErF,aAAO,IAAI,QAAQ,SAAO;AACxB,aAAK,cAAc,QACjB,KAAK,eACL,GAAG,4BACH,CAAC,KAAK,SAAS;AACb,cAAI,CAAC,OAAO,MAAM;AAChB,gBAAI;AAAA,iBACC;AACL,gBAAI;AACJ,iBAAK,OAAO,KAAK,IAAI;AAAA;AAAA;AAAA;AAAA,aAKtB,GAAP;AACA,aAAO,QAAQ,QAAQ;AAAA;AAAA;AAAA;;gBChPN;AAAA,eACR,WACX,QACA,CAAE,QAAQ,YACc;AAvC5B;AAwCI,UAAM,gBAAiB,aAAO,kBAC5B,+BADqB,YAElB;AAEL,YAAQ;AAAA,WACD;AACH,eAAO,KAAK;AACZ,eAAO,iBAAiB,WAAW,QAAQ;AAAA,WACxC;AACH,eAAO,KAAK;AACZ,eAAO,aAAa,WAAW,QAAQ;AAAA,WACpC;AACH,eAAO,KACL;AAEF,eAAO,wBAAwB,WAAW,QAAQ;AAAA,WAC/C;AACH,eAAO,KACL;AAEF,eAAO,sBAAsB,WAAW,QAAQ;AAAA,WAC7C;AACH,eAAO,KAAK;AACZ,eAAO,IAAI,aAAa,QAAQ,QAAQ;AAAA;AAExC,eAAO,KAAK;AACZ,eAAO,IAAI,aAAa,QAAQ,QAAQ;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;"}