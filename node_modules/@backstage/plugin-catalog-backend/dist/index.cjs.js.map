{"version":3,"file":"index.cjs.js","sources":["../src/service/request/basicEntityFilter.ts","../src/service/request/common.ts","../src/service/request/parseEntityFilterParams.ts","../src/service/request/parseEntityPaginationParams.ts","../src/service/request/parseEntityTransformParams.ts","../src/util/timing.ts","../src/catalog/DatabaseEntitiesCatalog.ts","../src/database/types.ts","../src/catalog/DatabaseLocationsCatalog.ts","../src/database/search.ts","../src/database/CommonDatabase.ts","../src/database/DatabaseManager.ts","../src/util/runPeriodically.ts","../src/ingestion/HigherOrderOperations.ts","../src/ingestion/processors/results.ts","../src/ingestion/LocationReaders.ts","../src/ingestion/processors/AnnotateLocationEntityProcessor.ts","../src/ingestion/processors/AnnotateScmSlugEntityProcessor.ts","../src/ingestion/processors/awsOrganization/config.ts","../src/ingestion/processors/AwsOrganizationCloudAccountProcessor.ts","../src/ingestion/processors/bitbucket/client.ts","../src/ingestion/processors/bitbucket/BitbucketRepositoryParser.ts","../src/ingestion/processors/BitbucketDiscoveryProcessor.ts","../src/ingestion/processors/BuiltinKindsEntityProcessor.ts","../src/ingestion/processors/codeowners/resolve.ts","../src/ingestion/processors/codeowners/scm.ts","../src/ingestion/processors/codeowners/read.ts","../src/ingestion/processors/CodeOwnersProcessor.ts","../src/ingestion/processors/util/parse.ts","../src/ingestion/processors/FileReaderProcessor.ts","../src/ingestion/processors/github/github.ts","../src/ingestion/processors/GithubDiscoveryProcessor.ts","../src/ingestion/processors/util/org.ts","../src/ingestion/processors/GithubOrgReaderProcessor.ts","../src/ingestion/processors/ldap/util.ts","../src/ingestion/processors/ldap/vendors.ts","../src/ingestion/processors/ldap/client.ts","../src/ingestion/processors/ldap/config.ts","../src/ingestion/processors/ldap/constants.ts","../src/ingestion/processors/ldap/read.ts","../src/ingestion/processors/LdapOrgReaderProcessor.ts","../src/ingestion/processors/LocationEntityProcessor.ts","../src/ingestion/processors/microsoftGraph/client.ts","../src/ingestion/processors/microsoftGraph/config.ts","../src/ingestion/processors/microsoftGraph/constants.ts","../src/ingestion/processors/microsoftGraph/read.ts","../src/ingestion/processors/MicrosoftGraphOrgReaderProcessor.ts","../src/ingestion/processors/PlaceholderProcessor.ts","../src/ingestion/processors/StaticLocationProcessor.ts","../src/ingestion/processors/UrlReaderProcessor.ts","../src/search/DefaultCatalogCollator.ts","../src/ingestion/CatalogRules.ts","../src/ingestion/LocationAnalyzer.ts","../src/service/CatalogBuilder.ts","../src/service/util.ts","../src/service/router.ts","../src/next/util.ts","../src/next/ConfigLocationEntityProvider.ts","../src/next/database/DefaultProcessingDatabase.ts","../src/next/DefaultCatalogProcessingEngine.ts","../src/next/DefaultCatalogProcessingOrchestrator.ts","../src/next/DefaultLocationService.ts","../src/next/DefaultLocationStore.ts","../src/next/NextEntitiesCatalog.ts","../src/next/search.ts","../src/next/Stitcher.ts","../src/next/NextCatalogBuilder.ts","../src/next/NextRouter.ts"],"sourcesContent":["/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { EntitiesSearchFilter, EntityFilter } from '../../database';\n\n/**\n * Forms a full EntityFilter based on a single key-value(s) object.\n */\nexport function basicEntityFilter(\n  items: Record<string, string | string[]>,\n): EntityFilter {\n  const filtersByKey: Record<string, EntitiesSearchFilter> = {};\n\n  for (const [key, value] of Object.entries(items)) {\n    const values = [value].flat();\n\n    const f =\n      key in filtersByKey\n        ? filtersByKey[key]\n        : (filtersByKey[key] = { key, matchValueIn: [] });\n\n    f.matchValueIn!.push(...values);\n  }\n\n  return { anyOf: [{ allOf: Object.values(filtersByKey) }] };\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError } from '@backstage/errors';\n\n/**\n * Takes a single unknown parameter and makes sure that it's a string that can\n * be parsed as an integer.\n */\nexport function parseIntegerParam(\n  param: unknown,\n  ctx: string,\n): number | undefined {\n  if (param === undefined) {\n    return undefined;\n  }\n\n  if (typeof param !== 'string') {\n    throw new InputError(`Invalid ${ctx}, not an integer on string form`);\n  }\n\n  const parsed = parseInt(param, 10);\n  if (!Number.isInteger(parsed) || String(parsed) !== param) {\n    throw new InputError(`Invalid ${ctx}, not an integer`);\n  }\n\n  return parsed;\n}\n\n/**\n * Takes a single unknown parameter and makes sure that it's a string.\n */\nexport function parseStringParam(\n  param: unknown,\n  ctx: string,\n): string | undefined {\n  if (param === undefined) {\n    return undefined;\n  }\n\n  if (typeof param !== 'string') {\n    throw new InputError(`Invalid ${ctx}, not a string`);\n  }\n\n  return param;\n}\n\n/**\n * Takes a single unknown parameter and makes sure that it's a single string or\n * an array of strings, and returns as an array.\n */\nexport function parseStringsParam(\n  param: unknown,\n  ctx: string,\n): string[] | undefined {\n  if (param === undefined) {\n    return undefined;\n  }\n\n  const array = [param].flat();\n  if (array.some(p => typeof p !== 'string')) {\n    throw new InputError(`Invalid ${ctx}, not a string`);\n  }\n\n  return array as string[];\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError } from '@backstage/errors';\nimport { EntitiesSearchFilter, EntityFilter } from '../../database';\nimport { parseStringsParam } from './common';\n\n/**\n * Parses the filtering part of a query, like\n * /entities?filter=metadata.namespace=default,kind=Component\n */\nexport function parseEntityFilterParams(\n  params: Record<string, unknown>,\n): EntityFilter | undefined {\n  // Each filter string is on the form a=b,c=d\n  const filterStrings = parseStringsParam(params.filter, 'filter');\n  if (!filterStrings) {\n    return undefined;\n  }\n\n  // Outer array: \"any of the inner ones\"\n  // Inner arrays: \"all of these must match\"\n  const filters = filterStrings.map(parseEntityFilterString).filter(Boolean);\n  if (!filters.length) {\n    return undefined;\n  }\n\n  return { anyOf: filters.map(f => ({ allOf: f! })) };\n}\n\n/**\n * Parses a single filter string as seen in a filter query, for example\n * metadata.namespace=default,kind=Component\n */\nexport function parseEntityFilterString(\n  filterString: string,\n): EntitiesSearchFilter[] | undefined {\n  const statements = filterString\n    .split(',')\n    .map(s => s.trim())\n    .filter(Boolean);\n\n  if (!statements.length) {\n    return undefined;\n  }\n\n  const filtersByKey: Record<string, EntitiesSearchFilter> = {};\n\n  for (const statement of statements) {\n    const equalsIndex = statement.indexOf('=');\n    if (equalsIndex < 1) {\n      throw new InputError(\n        `Invalid filter, '${statement}' is not a valid statement (expected a string on the form a=b)`,\n      );\n    }\n\n    const key = statement.substr(0, equalsIndex).trim();\n    const value = statement.substr(equalsIndex + 1).trim();\n    if (!key || !value) {\n      throw new InputError(\n        `Invalid filter, '${statement}' is not a valid statement (expected a string on the form a=b)`,\n      );\n    }\n\n    const f =\n      key in filtersByKey\n        ? filtersByKey[key]\n        : (filtersByKey[key] = { key, matchValueIn: [] });\n    f.matchValueIn!.push(value);\n  }\n\n  return Object.values(filtersByKey);\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError } from '@backstage/errors';\nimport { EntityPagination } from '../../database';\nimport { parseIntegerParam, parseStringParam } from './common';\n\n/**\n * Parses the pagination related parameters out of a query, e.g.\n * /entities?offset=100&limit=10\n */\nexport function parseEntityPaginationParams(\n  params: Record<string, unknown>,\n): EntityPagination | undefined {\n  const offset = parseIntegerParam(params.offset, 'offset');\n  const limit = parseIntegerParam(params.limit, 'limit');\n  const after = parseStringParam(params.after, 'after');\n\n  if (offset === undefined && limit === undefined && after === undefined) {\n    return undefined;\n  }\n\n  if (offset !== undefined && offset < 0) {\n    throw new InputError(`Invalid offset, must be zero or greater`);\n  }\n  if (limit !== undefined && limit <= 0) {\n    throw new InputError(`Invalid limit, must be greater than zero`);\n  }\n  if (after !== undefined && !after) {\n    throw new InputError(`Invalid after, must not be empty`);\n  }\n\n  return {\n    ...(offset !== undefined ? { offset } : {}),\n    ...(limit !== undefined ? { limit } : {}),\n    ...(after !== undefined ? { after } : {}),\n  };\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity } from '@backstage/catalog-model';\nimport { InputError } from '@backstage/errors';\nimport lodash from 'lodash';\nimport { RecursivePartial } from '../../util';\nimport { parseStringsParam } from './common';\n\nexport function parseEntityTransformParams(\n  params: Record<string, unknown>,\n): ((entity: Entity) => Entity) | undefined {\n  const fieldsStrings = parseStringsParam(params.fields, 'fields');\n  if (!fieldsStrings) {\n    return undefined;\n  }\n\n  const fields = fieldsStrings\n    .map(s => s.split(','))\n    .flat()\n    .map(s => s.trim())\n    .filter(Boolean);\n\n  if (!fields.length) {\n    return undefined;\n  }\n\n  if (fields.some(f => f.includes('['))) {\n    throw new InputError('invalid fields, array type fields are not supported');\n  }\n\n  return input => {\n    const output: RecursivePartial<Entity> = {};\n\n    for (const field of fields) {\n      const value = lodash.get(input, field);\n      if (value !== undefined) {\n        lodash.set(output, field, value);\n      }\n    }\n\n    return output as Entity;\n  };\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Returns a string with the elapsed time since the start of an operation,\n * with some human friendly precision, e.g. \"133ms\" or \"14.5s\".\n *\n * @param startTimestamp The timestamp (from process.hrtime()) at the start ot\n *                       the operation\n */\nexport function durationText(startTimestamp: [number, number]): string {\n  const delta = process.hrtime(startTimestamp);\n  const seconds = delta[0] + delta[1] / 1e9;\n  if (seconds > 1) {\n    return `${seconds.toFixed(1)}s`;\n  }\n  return `${(seconds * 1000).toFixed(0)}ms`;\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  entityHasChanges,\n  generateUpdatedEntity,\n  getEntityName,\n  LOCATION_ANNOTATION,\n  serializeEntityRef,\n} from '@backstage/catalog-model';\nimport { ConflictError } from '@backstage/errors';\nimport { chunk, groupBy } from 'lodash';\nimport limiterFactory from 'p-limit';\nimport { Logger } from 'winston';\nimport type { Database, DbEntityResponse, Transaction } from '../database';\nimport { DbEntitiesRequest } from '../database/types';\nimport { basicEntityFilter } from '../service/request';\nimport { durationText } from '../util/timing';\nimport type {\n  EntitiesCatalog,\n  EntitiesRequest,\n  EntitiesResponse,\n  EntityUpsertRequest,\n  EntityUpsertResponse,\n} from './types';\n\ntype BatchContext = {\n  kind: string;\n  namespace: string;\n  locationId?: string;\n};\n\n// Some locations return tens or hundreds of thousands of entities. To make\n// those payloads more manageable, we break work apart in batches of this\n// many entities and write them to storage per batch.\nconst BATCH_SIZE = 100;\n\n// When writing large batches, there's an increasing chance of contention in\n// the form of conflicts where we compete with other writes. Each batch gets\n// this many attempts at being written before giving up.\nconst BATCH_ATTEMPTS = 3;\n\n// The number of batches that may be ongoing at the same time.\nconst BATCH_CONCURRENCY = 3;\n\nexport class DatabaseEntitiesCatalog implements EntitiesCatalog {\n  constructor(\n    private readonly database: Database,\n    private readonly logger: Logger,\n  ) {}\n\n  async entities(request?: EntitiesRequest): Promise<EntitiesResponse> {\n    const dbRequest: DbEntitiesRequest = {\n      filter: request?.filter,\n      pagination: request?.pagination,\n    };\n\n    const dbResponse = await this.database.transaction(tx =>\n      this.database.entities(tx, dbRequest),\n    );\n\n    const entities = dbResponse.entities.map(e =>\n      request?.fields ? request.fields(e.entity) : e.entity,\n    );\n\n    return {\n      entities,\n      pageInfo: dbResponse.pageInfo,\n    };\n  }\n\n  async removeEntityByUid(uid: string): Promise<void> {\n    await this.database.transaction(async tx => {\n      await this.database.removeEntityByUid(tx, uid);\n    });\n  }\n\n  async batchAddOrUpdateEntities(\n    requests: EntityUpsertRequest[],\n    options?: {\n      locationId?: string;\n      dryRun?: boolean;\n      outputEntities?: boolean;\n    },\n  ): Promise<EntityUpsertResponse[]> {\n    // Group the requests by unique kind+namespace combinations. The reason for\n    // this is that the change detection and merging logic requires finding\n    // pre-existing versions of the entities in the database. Those queries are\n    // easier and faster to make if every batch revolves around a single kind-\n    // namespace pair.\n    const requestsByKindAndNamespace = groupBy(requests, ({ entity }) => {\n      const name = getEntityName(entity);\n      return `${name.kind}:${name.namespace}`.toLowerCase();\n    });\n\n    // Go through the requests in reasonable batch sizes. Sometimes, sources\n    // produce tens of thousands of entities, and those are too large batch\n    // sizes to reasonably send to the database.\n    const batches = Object.values(requestsByKindAndNamespace)\n      .map(request => chunk(request, BATCH_SIZE))\n      .flat();\n\n    // Bound the number of concurrent batches. We want a bit of concurrency for\n    // performance reasons, but not so much that we starve the connection pool\n    // or start thrashing.\n    const limiter = limiterFactory(BATCH_CONCURRENCY);\n    const tasks = batches.map(batch =>\n      limiter(async () => {\n        // Retry the batch write a few times to deal with contention\n        for (let attempt = 1; ; ++attempt) {\n          try {\n            return this.batchAddOrUpdateEntitiesSingleBatch(batch, options);\n          } catch (e) {\n            if (e instanceof ConflictError && attempt < BATCH_ATTEMPTS) {\n              this.logger.warn(\n                `Failed to write batch at attempt ${attempt}/${BATCH_ATTEMPTS}, ${e}`,\n              );\n            } else {\n              throw e;\n            }\n          }\n        }\n      }),\n    );\n\n    const responses = await Promise.all(tasks);\n    return responses.flat();\n  }\n\n  // Defines the actual logic of running a single batch. All of these share a\n  // common kind and namespace.\n  private async batchAddOrUpdateEntitiesSingleBatch(\n    batch: EntityUpsertRequest[],\n    options?: {\n      locationId?: string;\n      dryRun?: boolean;\n      outputEntities?: boolean;\n    },\n  ) {\n    const { kind, namespace } = getEntityName(batch[0].entity);\n    const context = {\n      kind,\n      namespace,\n      locationId: options?.locationId,\n    };\n\n    this.logger.debug(\n      `Considering batch ${serializeEntityRef(\n        batch[0].entity,\n      )}-${serializeEntityRef(batch[batch.length - 1].entity)} (${\n        batch.length\n      } entries)`,\n    );\n\n    return this.database.transaction(async tx => {\n      const { toAdd, toUpdate, toIgnore } = await this.analyzeBatch(\n        batch,\n        context,\n        tx,\n      );\n\n      let responses = new Array<EntityUpsertResponse>();\n      if (toAdd.length) {\n        const items = await this.batchAdd(toAdd, context, tx);\n        responses.push(...items);\n      }\n      if (toUpdate.length) {\n        const items = await this.batchUpdate(toUpdate, context, tx);\n        responses.push(...items);\n      }\n      for (const { entity, relations } of toIgnore) {\n        // TODO(Rugvip): We currently always update relations, but we\n        // likely want to figure out a way to avoid that\n        const entityId = entity.metadata.uid;\n        if (entityId) {\n          await this.database.setRelations(tx, entityId, relations);\n          responses.push({ entityId });\n        }\n      }\n\n      if (options?.outputEntities && responses.length > 0) {\n        const writtenEntities = await this.database.entities(tx, {\n          filter: basicEntityFilter({\n            'metadata.uid': responses.map(e => e.entityId),\n          }),\n        });\n        responses = writtenEntities.entities.map(e => ({\n          entityId: e.entity.metadata.uid!,\n          entity: e.entity,\n        }));\n      }\n\n      // If this is only a dry run, cancel the database transaction even if it\n      // was successful.\n      if (options?.dryRun) {\n        await tx.rollback();\n        this.logger.debug(`Performed successful dry run of adding entities`);\n      }\n\n      return responses;\n    });\n  }\n\n  // Given a batch of entities that were just read from a location, take them\n  // into consideration by comparing against the existing catalog entities and\n  // produce the list of entities to be added, and the list of entities to be\n  // updated\n  private async analyzeBatch(\n    requests: EntityUpsertRequest[],\n    { kind, namespace }: BatchContext,\n    tx: Transaction,\n  ): Promise<{\n    toAdd: EntityUpsertRequest[];\n    toUpdate: EntityUpsertRequest[];\n    toIgnore: EntityUpsertRequest[];\n  }> {\n    const markTimestamp = process.hrtime();\n\n    // Here we make use of the fact that all of the entities share kind and\n    // namespace within a batch\n    const names = requests.map(({ entity }) => entity.metadata.name);\n    const oldEntitiesResponse = await this.database.entities(tx, {\n      filter: basicEntityFilter({\n        kind: kind,\n        'metadata.namespace': namespace,\n        'metadata.name': names,\n      }),\n    });\n\n    const oldEntitiesByName = new Map(\n      oldEntitiesResponse.entities.map(e => [e.entity.metadata.name, e.entity]),\n    );\n\n    const toAdd: EntityUpsertRequest[] = [];\n    const toUpdate: EntityUpsertRequest[] = [];\n    const toIgnore: EntityUpsertRequest[] = [];\n\n    for (const request of requests) {\n      const newEntity = request.entity;\n      const oldEntity = oldEntitiesByName.get(newEntity.metadata.name);\n      const newLocation = newEntity.metadata.annotations?.[LOCATION_ANNOTATION];\n      const oldLocation =\n        oldEntity?.metadata.annotations?.[LOCATION_ANNOTATION];\n      if (!oldEntity) {\n        toAdd.push(request);\n      } else if (oldLocation !== newLocation) {\n        this.logger.warn(\n          `Rejecting write of entity ${serializeEntityRef(\n            newEntity,\n          )} from ${newLocation} because entity existed from ${oldLocation}`,\n        );\n        toIgnore.push(request);\n      } else if (entityHasChanges(oldEntity, newEntity)) {\n        // TODO(freben): This currently uses addOrUpdateEntity under the hood,\n        // but should probably calculate the end result entity right here\n        // instead and call a dedicated batch update database method\n        toUpdate.push(request);\n      } else {\n        // Use the existing entity to ensure that we're able to read it back by uid if needed\n        toIgnore.push({ ...request, entity: oldEntity });\n      }\n    }\n\n    this.logger.debug(\n      `Found ${toAdd.length} entities to add, ${\n        toUpdate.length\n      } entities to update in ${durationText(markTimestamp)}`,\n    );\n\n    return { toAdd, toUpdate, toIgnore };\n  }\n\n  // Efficiently adds the given entities to storage, under the assumption that\n  // they do not conflict with any existing entities\n  private async batchAdd(\n    requests: EntityUpsertRequest[],\n    { locationId }: BatchContext,\n    tx: Transaction,\n  ): Promise<EntityUpsertResponse[]> {\n    const markTimestamp = process.hrtime();\n\n    const res = await this.database.addEntities(\n      tx,\n      requests.map(({ entity, relations }) => ({\n        locationId,\n        entity,\n        relations,\n      })),\n    );\n\n    const responses = res.map(({ entity }) => ({\n      entityId: entity.metadata.uid!,\n    }));\n\n    this.logger.debug(\n      `Added ${requests.length} entities in ${durationText(markTimestamp)}`,\n    );\n\n    return responses;\n  }\n\n  // Efficiently updates the given entities into storage, under the assumption\n  // that there already exist entities with the same names\n  private async batchUpdate(\n    requests: EntityUpsertRequest[],\n    { locationId }: BatchContext,\n    tx: Transaction,\n  ): Promise<EntityUpsertResponse[]> {\n    const markTimestamp = process.hrtime();\n    const responses: EntityUpsertResponse[] = [];\n\n    // TODO(freben): Still not batched\n    for (const request of requests) {\n      const res = await this.addOrUpdateEntity(tx, request, locationId);\n      const entityId = res.metadata.uid!;\n      responses.push({ entityId });\n    }\n\n    this.logger.debug(\n      `Updated ${requests.length} entities in ${durationText(markTimestamp)}`,\n    );\n\n    return responses;\n  }\n\n  // TODO(freben): Incorporate this into batchUpdate which is the only caller\n  private async addOrUpdateEntity(\n    tx: Transaction,\n    { entity, relations }: EntityUpsertRequest,\n    locationId?: string,\n  ): Promise<Entity> {\n    // Find a matching (by uid, or by compound name, depending on the given\n    // entity) existing entity, to know whether to update or add\n    const existing = entity.metadata.uid\n      ? await this.database.entityByUid(tx, entity.metadata.uid)\n      : await this.database.entityByName(tx, getEntityName(entity));\n\n    // If it's an update, run the algorithm for annotation merging, updating\n    // etag/generation, etc.\n    let response: DbEntityResponse;\n    if (existing) {\n      const updated = generateUpdatedEntity(existing.entity, entity);\n      response = await this.database.updateEntity(\n        tx,\n        { locationId, entity: updated, relations },\n        existing.entity.metadata.etag,\n        existing.entity.metadata.generation,\n      );\n    } else {\n      const added = await this.database.addEntities(tx, [\n        { locationId, entity, relations },\n      ]);\n      response = added[0];\n    }\n\n    return response.entity;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport type {\n  Entity,\n  EntityName,\n  EntityRelationSpec,\n  Location,\n} from '@backstage/catalog-model';\n\nexport type DbEntitiesRow = {\n  id: string;\n  location_id: string | null;\n  etag: string;\n  generation: number;\n  full_name: string;\n  data: string;\n};\n\nexport type DbEntityRequest = {\n  locationId?: string;\n  entity: Entity;\n  relations: EntityRelationSpec[];\n};\n\nexport type DbEntitiesRequest = {\n  filter?: EntityFilter;\n  pagination?: EntityPagination;\n};\n\nexport type DbEntitiesResponse = {\n  entities: DbEntityResponse[];\n  pageInfo: DbPageInfo;\n};\n\nexport type DbPageInfo =\n  | {\n      hasNextPage: false;\n    }\n  | {\n      hasNextPage: true;\n      endCursor: string;\n    };\n\nexport type DbEntityResponse = {\n  locationId?: string;\n  entity: Entity;\n};\n\nexport type DbEntitiesRelationsRow = {\n  originating_entity_id: string;\n  source_full_name: string;\n  type: string;\n  target_full_name: string;\n};\n\nexport type DbEntitiesSearchRow = {\n  entity_id: string;\n  key: string;\n  value: string | null;\n};\n\nexport type DbLocationsRow = {\n  id: string;\n  type: string;\n  target: string;\n};\n\nexport type DbLocationsRowWithStatus = DbLocationsRow & {\n  status: string | null;\n  timestamp: string | null;\n  message: string | null;\n};\n\nexport enum DatabaseLocationUpdateLogStatus {\n  FAIL = 'fail',\n  SUCCESS = 'success',\n}\n\nexport type DatabaseLocationUpdateLogEvent = {\n  id: string;\n  status: DatabaseLocationUpdateLogStatus;\n  location_id: string;\n  entity_name: string;\n  created_at?: string;\n  message?: string;\n};\n\n/**\n * Matches rows in the entities_search table.\n */\nexport type EntitiesSearchFilter = {\n  /**\n   * The key to match on.\n   *\n   * Matches are always case insensitive.\n   */\n  key: string;\n\n  /**\n   * Match on plain equality of values.\n   *\n   * If undefined, this factor is not taken into account. Otherwise, match on\n   * values that are equal to any of the given array items. Matches are always\n   * case insensitive.\n   */\n  matchValueIn?: string[];\n};\n\n/**\n * A filter expression for entities.\n *\n * Any (at least one) of the outer sets must match, within which all of the\n * individual filters must match.\n */\nexport type EntityFilter = {\n  anyOf: { allOf: EntitiesSearchFilter[] }[];\n};\n\n/**\n * A pagination rule for entities.\n */\nexport type EntityPagination = {\n  limit?: number;\n  offset?: number;\n  after?: string;\n};\n\n/**\n * An abstraction for transactions of the underlying database technology.\n */\nexport type Transaction = {\n  rollback(): Promise<unknown>;\n};\n\n/**\n * An abstraction on top of the underlying database, wrapping the basic CRUD\n * needs.\n */\nexport type Database = {\n  /**\n   * Runs a transaction.\n   *\n   * The callback is expected to make calls back into this class. When it\n   * completes, the transaction is closed.\n   *\n   * @param fn The callback that implements the transaction\n   */\n  transaction<T>(fn: (tx: Transaction) => Promise<T>): Promise<T>;\n\n  /**\n   * Adds a set of new entities to the catalog.\n   *\n   * @param tx An ongoing transaction\n   * @param request The entities being added\n   */\n  addEntities(\n    tx: Transaction,\n    request: DbEntityRequest[],\n  ): Promise<DbEntityResponse[]>;\n\n  /**\n   * Updates an existing entity in the catalog.\n   *\n   * The given entity must contain an uid to identify an already stored entity\n   * in the catalog. If it is missing or if no matching entity is found, the\n   * operation fails.\n   *\n   * If matchingEtag or matchingGeneration are given, they are taken into\n   * account. Attempts to update a matching entity, but where the etag and/or\n   * generation are not equal to the passed values, will fail.\n   *\n   * @param tx An ongoing transaction\n   * @param request The entity being updated\n   * @param matchingEtag If specified, reject with ConflictError if not\n   *                     matching the entry in the database\n   * @param matchingGeneration If specified, reject with ConflictError if not\n   *                           matching the entry in the database\n   * @returns The updated entity\n   */\n  updateEntity(\n    tx: Transaction,\n    request: DbEntityRequest,\n    matchingEtag?: string,\n    matchingGeneration?: number,\n  ): Promise<DbEntityResponse>;\n\n  entities(\n    tx: Transaction,\n    request?: DbEntitiesRequest,\n  ): Promise<DbEntitiesResponse>;\n\n  entityByName(\n    tx: Transaction,\n    name: EntityName,\n  ): Promise<DbEntityResponse | undefined>;\n\n  entityByUid(\n    tx: Transaction,\n    uid: string,\n  ): Promise<DbEntityResponse | undefined>;\n\n  removeEntityByUid(tx: Transaction, uid: string): Promise<void>;\n\n  /**\n   * Remove current relations for the entity and replace them with the new\n   * relations array.\n   *\n   * @param tx An ongoing transaction\n   * @param entityUid The entity uid\n   * @param relations The relationships to be set\n   */\n  setRelations(\n    tx: Transaction,\n    entityUid: string,\n    relations: EntityRelationSpec[],\n  ): Promise<void>;\n\n  addLocation(tx: Transaction, location: Location): Promise<DbLocationsRow>;\n\n  removeLocation(tx: Transaction, id: string): Promise<void>;\n\n  location(id: string): Promise<DbLocationsRowWithStatus>;\n\n  locations(): Promise<DbLocationsRowWithStatus[]>;\n\n  locationHistory(id: string): Promise<DatabaseLocationUpdateLogEvent[]>;\n\n  addLocationUpdateLogEvent(\n    locationId: string,\n    status: DatabaseLocationUpdateLogStatus,\n    entityName?: string | string[],\n    message?: string,\n  ): Promise<void>;\n};\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Location } from '@backstage/catalog-model';\nimport type { Database } from '../database';\nimport {\n  DatabaseLocationUpdateLogEvent,\n  DatabaseLocationUpdateLogStatus,\n} from '../database/types';\nimport { LocationResponse, LocationsCatalog } from './types';\n\nexport class DatabaseLocationsCatalog implements LocationsCatalog {\n  constructor(private readonly database: Database) {}\n\n  async addLocation(location: Location): Promise<Location> {\n    return await this.database.transaction(\n      async tx => await this.database.addLocation(tx, location),\n    );\n  }\n\n  async removeLocation(id: string): Promise<void> {\n    await this.database.transaction(tx => this.database.removeLocation(tx, id));\n  }\n\n  async locations(): Promise<LocationResponse[]> {\n    const items = await this.database.locations();\n    return items.map(({ message, status, timestamp, ...data }) => ({\n      currentStatus: {\n        message,\n        status,\n        timestamp,\n      },\n      data,\n    }));\n  }\n\n  async locationHistory(id: string): Promise<DatabaseLocationUpdateLogEvent[]> {\n    return this.database.locationHistory(id);\n  }\n\n  async location(id: string): Promise<LocationResponse> {\n    const {\n      message,\n      status,\n      timestamp,\n      ...data\n    } = await this.database.location(id);\n    return {\n      currentStatus: {\n        message,\n        status,\n        timestamp,\n      },\n      data,\n    };\n  }\n\n  async logUpdateSuccess(\n    locationId: string,\n    entityName?: string | string[],\n  ): Promise<void> {\n    await this.database.addLocationUpdateLogEvent(\n      locationId,\n      DatabaseLocationUpdateLogStatus.SUCCESS,\n      entityName,\n    );\n  }\n\n  async logUpdateFailure(\n    locationId: string,\n    error?: Error,\n    entityName?: string,\n  ): Promise<void> {\n    await this.database.addLocationUpdateLogEvent(\n      locationId,\n      DatabaseLocationUpdateLogStatus.FAIL,\n      entityName,\n      error?.message,\n    );\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity, ENTITY_DEFAULT_NAMESPACE } from '@backstage/catalog-model';\nimport type { DbEntitiesSearchRow } from './types';\n\n// These are excluded in the generic loop, either because they do not make sense\n// to index, or because they are special-case always inserted whether they are\n// null or not\nconst SPECIAL_KEYS = [\n  'metadata.name',\n  'metadata.namespace',\n  'metadata.uid',\n  'metadata.etag',\n  'metadata.generation',\n];\n\n// The maximum length allowed for search values. These columns are indexed, and\n// database engines do not like to index on massive values. For example,\n// postgres will balk after 8191 byte line sizes.\nconst MAX_KEY_LENGTH = 200;\nconst MAX_VALUE_LENGTH = 200;\n\ntype Kv = {\n  key: string;\n  value: unknown;\n};\n\n// Helper for traversing through a nested structure and outputting a list of\n// path->value entries of the leaves.\n//\n// For example, this yaml structure\n//\n// a: 1\n// b:\n//   c: null\n//   e: [f, g]\n// h:\n//  - i: 1\n//    j: k\n//  - i: 2\n//    j: l\n//\n// will result in\n//\n// \"a\", 1\n// \"b.c\", null\n// \"b.e\": \"f\"\n// \"b.e.f\": true\n// \"b.e\": \"g\"\n// \"b.e.g\": true\n// \"h.i\": 1\n// \"h.j\": \"k\"\n// \"h.i\": 2\n// \"h.j\": \"l\"\nexport function traverse(root: unknown): Kv[] {\n  const output: Kv[] = [];\n\n  function visit(path: string, current: unknown) {\n    if (SPECIAL_KEYS.includes(path)) {\n      return;\n    }\n\n    // empty or scalar\n    if (\n      current === undefined ||\n      current === null ||\n      ['string', 'number', 'boolean'].includes(typeof current)\n    ) {\n      output.push({ key: path, value: current });\n      return;\n    }\n\n    // unknown\n    if (typeof current !== 'object') {\n      return;\n    }\n\n    // array\n    if (Array.isArray(current)) {\n      for (const item of current) {\n        // NOTE(freben): The reason that these are output in two different ways,\n        // is to support use cases where you want to express that MORE than one\n        // tag is present in a list. Since the EntityFilters structure is a\n        // record, you can't have several entries of the same key. Therefore\n        // you will have to match on\n        //\n        // { \"a.b\": [\"true\"], \"a.c\": [\"true\"] }\n        //\n        // rather than\n        //\n        // { \"a\": [\"b\", \"c\"] }\n        //\n        // because the latter means EITHER b or c has to be present.\n        visit(path, item);\n        if (typeof item === 'string') {\n          output.push({ key: `${path}.${item}`, value: true });\n        }\n      }\n      return;\n    }\n\n    // object\n    for (const [key, value] of Object.entries(current!)) {\n      visit(path ? `${path}.${key}` : key, value);\n    }\n  }\n\n  visit('', root);\n\n  return output;\n}\n\n// Translates a number of raw data rows to search table rows\nexport function mapToRows(\n  input: Kv[],\n  entityId: string,\n): DbEntitiesSearchRow[] {\n  const result: DbEntitiesSearchRow[] = [];\n\n  for (const { key: rawKey, value: rawValue } of input) {\n    const key = rawKey.toLowerCase();\n    if (rawValue === undefined || rawValue === null) {\n      result.push({ entity_id: entityId, key, value: null });\n    } else {\n      const value = String(rawValue).toLowerCase();\n      if (key.length <= MAX_KEY_LENGTH && value.length <= MAX_VALUE_LENGTH) {\n        result.push({ entity_id: entityId, key, value });\n      }\n    }\n  }\n\n  return result;\n}\n\n/**\n * Generates all of the search rows that are relevant for this entity.\n *\n * @param entityId The uid of the entity\n * @param entity The entity\n * @returns A list of entity search rows\n */\nexport function buildEntitySearch(\n  entityId: string,\n  entity: Entity,\n): DbEntitiesSearchRow[] {\n  // Visit the entire structure recursively\n  const raw = traverse(entity);\n\n  // Start with some special keys that are always present because you want to\n  // be able to easily search for null specifically\n  raw.push({ key: 'metadata.name', value: entity.metadata.name });\n  raw.push({ key: 'metadata.namespace', value: entity.metadata.namespace });\n  raw.push({ key: 'metadata.uid', value: entity.metadata.uid });\n\n  // Namespace not specified has the default value \"default\", so we want to\n  // match on that as well\n  if (!entity.metadata.namespace) {\n    raw.push({ key: 'metadata.namespace', value: ENTITY_DEFAULT_NAMESPACE });\n  }\n\n  return mapToRows(raw, entityId);\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ConflictError, InputError, NotFoundError } from '@backstage/errors';\nimport {\n  Entity,\n  EntityName,\n  EntityRelationSpec,\n  ENTITY_DEFAULT_NAMESPACE,\n  ENTITY_META_GENERATED_FIELDS,\n  generateEntityEtag,\n  generateEntityUid,\n  Location,\n  parseEntityName,\n} from '@backstage/catalog-model';\nimport { Knex } from 'knex';\nimport lodash from 'lodash';\nimport type { Logger } from 'winston';\nimport { buildEntitySearch } from './search';\nimport {\n  Database,\n  DatabaseLocationUpdateLogEvent,\n  DatabaseLocationUpdateLogStatus,\n  DbEntitiesRelationsRow,\n  DbEntitiesRequest,\n  DbEntitiesResponse,\n  DbEntitiesRow,\n  DbEntitiesSearchRow,\n  DbEntityRequest,\n  DbEntityResponse,\n  DbLocationsRow,\n  DbLocationsRowWithStatus,\n  DbPageInfo,\n  EntityPagination,\n  Transaction,\n} from './types';\n\n// The number of items that are sent per batch to the database layer, when\n// doing .batchInsert calls to knex. This needs to be low enough to not cause\n// errors in the underlying engine due to exceeding query limits, but large\n// enough to get the speed benefits.\nconst BATCH_SIZE = 50;\n\n/**\n * The core database implementation.\n */\nexport class CommonDatabase implements Database {\n  constructor(\n    private readonly database: Knex,\n    private readonly logger: Logger,\n  ) {}\n\n  async transaction<T>(fn: (tx: Transaction) => Promise<T>): Promise<T> {\n    try {\n      let result: T | undefined = undefined;\n\n      await this.database.transaction(\n        async tx => {\n          // We can't return here, as knex swallows the return type in case the transaction is rolled back:\n          // https://github.com/knex/knex/blob/e37aeaa31c8ef9c1b07d2e4d3ec6607e557d800d/lib/transaction.js#L136\n          result = await fn(tx);\n        },\n        {\n          // If we explicitly trigger a rollback, don't fail.\n          doNotRejectOnRollback: true,\n        },\n      );\n\n      return result!;\n    } catch (e) {\n      this.logger.debug(`Error during transaction, ${e}`);\n\n      if (\n        /SQLITE_CONSTRAINT: UNIQUE/.test(e.message) ||\n        /unique constraint/.test(e.message)\n      ) {\n        throw new ConflictError(`Rejected due to a conflicting entity`, e);\n      }\n\n      throw e;\n    }\n  }\n\n  async addEntities(\n    txOpaque: Transaction,\n    request: DbEntityRequest[],\n  ): Promise<DbEntityResponse[]> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const result: DbEntityResponse[] = [];\n    const entityRows: DbEntitiesRow[] = [];\n    const relationRows: DbEntitiesRelationsRow[] = [];\n    const searchRows: DbEntitiesSearchRow[] = [];\n\n    for (const { entity, relations, locationId } of request) {\n      if (entity.metadata.uid !== undefined) {\n        throw new InputError('May not specify uid for new entities');\n      } else if (entity.metadata.etag !== undefined) {\n        throw new InputError('May not specify etag for new entities');\n      } else if (entity.metadata.generation !== undefined) {\n        throw new InputError('May not specify generation for new entities');\n      } else if (entity.relations !== undefined) {\n        throw new InputError('May not specify relations for new entities');\n      }\n\n      const uid = generateEntityUid();\n      const etag = generateEntityEtag();\n      const generation = 1;\n      const newEntity = {\n        ...entity,\n        metadata: {\n          ...entity.metadata,\n          uid,\n          etag,\n          generation,\n        },\n      };\n\n      result.push({ entity: newEntity, locationId });\n      entityRows.push(this.toEntityRow(locationId, newEntity));\n      relationRows.push(...this.toRelationRows(uid, relations));\n      searchRows.push(...buildEntitySearch(uid, newEntity));\n    }\n\n    await tx.batchInsert('entities', entityRows, BATCH_SIZE);\n    await tx.batchInsert('entities_relations', relationRows, BATCH_SIZE);\n    await tx.batchInsert('entities_search', searchRows, BATCH_SIZE);\n\n    return result;\n  }\n\n  async updateEntity(\n    txOpaque: Transaction,\n    request: DbEntityRequest,\n    matchingEtag?: string,\n    matchingGeneration?: number,\n  ): Promise<DbEntityResponse> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const { uid } = request.entity.metadata;\n    if (!uid) {\n      throw new InputError('Must specify uid when updating entities');\n    }\n\n    // Find existing entity\n    const oldRows = await tx<DbEntitiesRow>('entities')\n      .where({ id: uid })\n      .select();\n    if (oldRows.length !== 1) {\n      throw new NotFoundError('No matching entity found');\n    }\n    const etag = oldRows[0].etag;\n    const generation = Number(oldRows[0].generation);\n\n    // Validate the old entity. The Number cast is here because sqlite reads it\n    // as a string, no matter what the table actually says.\n    if (matchingEtag && matchingEtag !== etag) {\n      throw new ConflictError(\n        `Etag mismatch, expected=\"${matchingEtag}\" found=\"${etag}\"`,\n      );\n    }\n    if (matchingGeneration && matchingGeneration !== generation) {\n      throw new ConflictError(\n        `Generation mismatch, expected=\"${matchingGeneration}\" found=\"${generation}\"`,\n      );\n    }\n\n    // Store the updated entity; select on the old etag to ensure that we do\n    // not lose to another writer\n    const newRow = this.toEntityRow(request.locationId, request.entity);\n    const updatedRows = await tx<DbEntitiesRow>('entities')\n      .where({ id: uid, etag })\n      .update(newRow);\n    if (updatedRows !== 1) {\n      throw new ConflictError(`Failed to update entity`);\n    }\n\n    const relationRows = this.toRelationRows(uid, request.relations);\n    await tx<DbEntitiesRelationsRow>('entities_relations')\n      .where({ originating_entity_id: uid })\n      .del();\n    await tx.batchInsert('entities_relations', relationRows, BATCH_SIZE);\n\n    try {\n      const entries = buildEntitySearch(uid, request.entity);\n      await tx<DbEntitiesSearchRow>('entities_search')\n        .where({ entity_id: uid })\n        .del();\n      await tx.batchInsert('entities_search', entries, BATCH_SIZE);\n    } catch {\n      // ignore intentionally - if this happens, the entity was deleted before\n      // we got around to writing the entries\n    }\n\n    return request;\n  }\n\n  async entities(\n    txOpaque: Transaction,\n    request?: DbEntitiesRequest,\n  ): Promise<DbEntitiesResponse> {\n    const tx = txOpaque as Knex.Transaction;\n\n    let entitiesQuery = tx<DbEntitiesRow>('entities');\n\n    for (const singleFilter of request?.filter?.anyOf ?? []) {\n      entitiesQuery = entitiesQuery.orWhere(function singleFilterFn() {\n        for (const { key, matchValueIn } of singleFilter.allOf) {\n          // NOTE(freben): This used to be a set of OUTER JOIN, which may seem to\n          // make a lot of sense. However, it had abysmal performance on sqlite\n          // when datasets grew large, so we're using IN instead.\n          const matchQuery = tx<DbEntitiesSearchRow>('entities_search')\n            .select('entity_id')\n            .where(function keyFilter() {\n              this.andWhere({ key: key.toLowerCase() });\n              if (matchValueIn) {\n                if (matchValueIn.length === 1) {\n                  this.andWhere({ value: matchValueIn[0].toLowerCase() });\n                } else if (matchValueIn.length > 1) {\n                  this.andWhere(\n                    'value',\n                    'in',\n                    matchValueIn.map(v => v.toLowerCase()),\n                  );\n                }\n              }\n            });\n          this.andWhere('id', 'in', matchQuery);\n        }\n      });\n    }\n\n    entitiesQuery = entitiesQuery\n      .select('entities.*')\n      .orderBy('full_name', 'asc');\n\n    const { limit, offset } = parsePagination(request?.pagination);\n    if (limit !== undefined) {\n      entitiesQuery = entitiesQuery.limit(limit + 1);\n    }\n    if (offset !== undefined) {\n      entitiesQuery = entitiesQuery.offset(offset);\n    }\n\n    let rows = await entitiesQuery;\n\n    let pageInfo: DbPageInfo;\n    if (limit === undefined || rows.length <= limit) {\n      pageInfo = { hasNextPage: false };\n    } else {\n      rows = rows.slice(0, -1);\n      pageInfo = {\n        hasNextPage: true,\n        endCursor: stringifyPagination({\n          limit,\n          offset: (offset ?? 0) + limit,\n        }),\n      };\n    }\n\n    return {\n      entities: await this.toEntityResponses(tx, rows),\n      pageInfo,\n    };\n  }\n\n  async entityByName(\n    txOpaque: Transaction,\n    name: EntityName,\n  ): Promise<DbEntityResponse | undefined> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const rows = await tx<DbEntitiesRow>('entities')\n      .where({\n        full_name: `${name.kind}:${name.namespace}/${name.name}`.toLowerCase(),\n      })\n      .select();\n\n    if (rows.length !== 1) {\n      return undefined;\n    }\n\n    return this.toEntityResponses(tx, rows).then(r => r[0]);\n  }\n\n  async entityByUid(\n    txOpaque: Transaction,\n    uid: string,\n  ): Promise<DbEntityResponse | undefined> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const rows = await tx<DbEntitiesRow>('entities')\n      .where({ id: uid })\n      .select();\n\n    if (rows.length !== 1) {\n      return undefined;\n    }\n\n    return this.toEntityResponses(tx, rows).then(r => r[0]);\n  }\n\n  async removeEntityByUid(txOpaque: Transaction, uid: string): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const result = await tx<DbEntitiesRow>('entities').where({ id: uid }).del();\n    if (!result) {\n      throw new NotFoundError(`Found no entity with ID ${uid}`);\n    }\n  }\n\n  async setRelations(\n    txOpaque: Transaction,\n    originatingEntityId: string,\n    relations: EntityRelationSpec[],\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n    const relationRows = this.toRelationRows(originatingEntityId, relations);\n\n    await tx<DbEntitiesRelationsRow>('entities_relations')\n      .where({ originating_entity_id: originatingEntityId })\n      .del();\n    await tx.batchInsert('entities_relations', relationRows, BATCH_SIZE);\n  }\n\n  async addLocation(\n    txOpaque: Transaction,\n    location: Location,\n  ): Promise<DbLocationsRow> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const row: DbLocationsRow = {\n      id: location.id,\n      type: location.type,\n      target: location.target,\n    };\n    await tx<DbLocationsRow>('locations').insert(row);\n    return row;\n  }\n\n  async removeLocation(txOpaque: Transaction, id: string): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const locations = await tx<DbLocationsRow>('locations')\n      .where({ id })\n      .select();\n    if (!locations.length) {\n      throw new NotFoundError(`Found no location with ID ${id}`);\n    }\n\n    if (locations[0].type === 'bootstrap') {\n      throw new ConflictError('You may not delete the bootstrap location.');\n    }\n\n    await tx<DbEntitiesRow>('entities')\n      .where({ location_id: id })\n      .update({ location_id: null });\n    await tx<DbLocationsRow>('locations').where({ id }).del();\n  }\n\n  async location(id: string): Promise<DbLocationsRowWithStatus> {\n    const items = await this.database<DbLocationsRowWithStatus>('locations')\n      .where('locations.id', id)\n      .leftOuterJoin(\n        'location_update_log_latest',\n        'locations.id',\n        'location_update_log_latest.location_id',\n      )\n      .select('locations.*', {\n        status: 'location_update_log_latest.status',\n        timestamp: 'location_update_log_latest.created_at',\n        message: 'location_update_log_latest.message',\n      });\n\n    if (!items.length) {\n      throw new NotFoundError(`Found no location with ID ${id}`);\n    }\n    return items[0];\n  }\n\n  async locations(): Promise<DbLocationsRowWithStatus[]> {\n    const locations = await this.database('locations')\n      .leftOuterJoin(\n        'location_update_log_latest',\n        'locations.id',\n        'location_update_log_latest.location_id',\n      )\n      .select('locations.*', {\n        status: 'location_update_log_latest.status',\n        timestamp: 'location_update_log_latest.created_at',\n        message: 'location_update_log_latest.message',\n      });\n\n    return locations;\n  }\n\n  async locationHistory(id: string): Promise<DatabaseLocationUpdateLogEvent[]> {\n    const result = await this.database<DatabaseLocationUpdateLogEvent>(\n      'location_update_log',\n    )\n      .where('location_id', id)\n      .orderBy('created_at', 'desc')\n      .limit(10)\n      .select();\n\n    return result;\n  }\n\n  async addLocationUpdateLogEvent(\n    locationId: string,\n    status: DatabaseLocationUpdateLogStatus,\n    entityName?: string | string[],\n    message?: string,\n  ): Promise<void> {\n    // Remove log entries older than a day\n    const cutoff = new Date();\n    cutoff.setDate(cutoff.getDate() - 1);\n    await this.database<DatabaseLocationUpdateLogEvent>('location_update_log')\n      .where('created_at', '<', cutoff.toISOString())\n      .del();\n\n    const items: Partial<DatabaseLocationUpdateLogEvent>[] = [entityName]\n      .flat()\n      .map(n => ({\n        status,\n        location_id: locationId,\n        entity_name: n,\n        message,\n      }));\n\n    for (const chunk of lodash.chunk(items, BATCH_SIZE)) {\n      await this.database<DatabaseLocationUpdateLogEvent>(\n        'location_update_log',\n      ).insert(chunk);\n    }\n  }\n\n  private toEntityRow(\n    locationId: string | undefined,\n    entity: Entity,\n  ): DbEntitiesRow {\n    const lowerKind = entity.kind.toLowerCase();\n    const lowerNamespace = (\n      entity.metadata.namespace || ENTITY_DEFAULT_NAMESPACE\n    ).toLowerCase();\n    const lowerName = entity.metadata.name.toLowerCase();\n\n    const data = {\n      ...entity,\n      metadata: lodash.omit(entity.metadata, ...ENTITY_META_GENERATED_FIELDS),\n    };\n\n    return {\n      id: entity.metadata.uid!,\n      location_id: locationId || null,\n      etag: entity.metadata.etag!,\n      generation: entity.metadata.generation!,\n      full_name: `${lowerKind}:${lowerNamespace}/${lowerName}`,\n      data: JSON.stringify(data),\n    };\n  }\n\n  private toRelationRows(\n    originatingEntityId: string,\n    relations: EntityRelationSpec[],\n  ): DbEntitiesRelationsRow[] {\n    const serializeName = (e: EntityName) =>\n      `${e.kind}:${e.namespace}/${e.name}`.toLowerCase();\n\n    const rows = relations.map(({ source, target, type }) => ({\n      originating_entity_id: originatingEntityId,\n      source_full_name: serializeName(source),\n      target_full_name: serializeName(target),\n      type,\n    }));\n\n    return deduplicateRelations(rows);\n  }\n\n  private async toEntityResponses(\n    tx: Knex.Transaction,\n    rows: DbEntitiesRow[],\n  ): Promise<DbEntityResponse[]> {\n    // TODO(Rugvip): This is here because it's simple for now, but we likely\n    //               need to refactor this to be more efficient or introduce pagination.\n    const relations = await this.getRelationsPerFullName(\n      tx,\n      rows.map(r => r.full_name),\n    );\n\n    const result = new Array<DbEntityResponse>();\n    for (const row of rows) {\n      const entity = JSON.parse(row.data) as Entity;\n      entity.metadata.uid = row.id;\n      entity.metadata.etag = row.etag;\n      entity.metadata.generation = Number(row.generation); // cast due to sqlite\n\n      entity.relations = (relations[row.full_name] ?? []).map(r => ({\n        target: parseEntityName(r.target_full_name),\n        type: r.type,\n      }));\n\n      result.push({\n        locationId: row.location_id || undefined,\n        entity,\n      });\n    }\n\n    return result;\n  }\n\n  // Returns a mapping from e.g. component:default/foo to the relations whose\n  // source_full_name matches that.\n  private async getRelationsPerFullName(\n    tx: Knex.Transaction,\n    sourceFullNames: string[],\n  ): Promise<Record<string, DbEntitiesRelationsRow[]>> {\n    const batches = lodash.chunk(lodash.uniq(sourceFullNames), 500);\n\n    const relations = new Array<DbEntitiesRelationsRow>();\n    for (const batch of batches) {\n      relations.push(\n        ...(await tx<DbEntitiesRelationsRow>('entities_relations')\n          .whereIn('source_full_name', batch)\n          .orderBy(['type', 'target_full_name'])\n          .select()),\n      );\n    }\n\n    return lodash.groupBy(\n      deduplicateRelations(relations),\n      r => r.source_full_name,\n    );\n  }\n}\n\nfunction parsePagination(\n  input?: EntityPagination,\n): { limit?: number; offset?: number } {\n  if (!input) {\n    return {};\n  }\n\n  let { limit, offset } = input;\n\n  if (input.after !== undefined) {\n    let cursor;\n    try {\n      const json = Buffer.from(input.after, 'base64').toString('utf8');\n      cursor = JSON.parse(json);\n    } catch {\n      throw new InputError('Malformed after cursor, could not be parsed');\n    }\n    if (cursor.limit !== undefined) {\n      if (!Number.isInteger(cursor.limit)) {\n        throw new InputError('Malformed after cursor, limit was not an number');\n      }\n      limit = cursor.limit;\n    }\n    if (cursor.offset !== undefined) {\n      if (!Number.isInteger(cursor.offset)) {\n        throw new InputError('Malformed after cursor, offset was not a number');\n      }\n      offset = cursor.offset;\n    }\n  }\n\n  return { limit, offset };\n}\n\nfunction stringifyPagination(input: { limit: number; offset: number }) {\n  const json = JSON.stringify({ limit: input.limit, offset: input.offset });\n  const base64 = Buffer.from(json, 'utf8').toString('base64');\n  return base64;\n}\n\nfunction deduplicateRelations(\n  rows: DbEntitiesRelationsRow[],\n): DbEntitiesRelationsRow[] {\n  return lodash.uniqBy(\n    rows,\n    r => `${r.source_full_name}:${r.target_full_name}:${r.type}`,\n  );\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { getVoidLogger, resolvePackagePath } from '@backstage/backend-common';\nimport knexFactory, { Knex } from 'knex';\nimport { v4 as uuidv4 } from 'uuid';\nimport { Logger } from 'winston';\nimport { CommonDatabase } from './CommonDatabase';\nimport { Database } from './types';\n\nconst migrationsDir = resolvePackagePath(\n  '@backstage/plugin-catalog-backend',\n  'migrations',\n);\n\nexport type CreateDatabaseOptions = {\n  logger: Logger;\n};\n\nconst defaultOptions: CreateDatabaseOptions = {\n  logger: getVoidLogger(),\n};\n\nexport class DatabaseManager {\n  public static async createDatabase(\n    knex: Knex,\n    options: Partial<CreateDatabaseOptions> = {},\n  ): Promise<Database> {\n    await knex.migrate.latest({\n      directory: migrationsDir,\n    });\n    const { logger } = { ...defaultOptions, ...options };\n    return new CommonDatabase(knex, logger);\n  }\n\n  public static async createInMemoryDatabase(): Promise<Database> {\n    const knex = await this.createInMemoryDatabaseConnection();\n    return await this.createDatabase(knex);\n  }\n\n  public static async createInMemoryDatabaseConnection(): Promise<Knex> {\n    const knex = knexFactory({\n      client: 'sqlite3',\n      connection: ':memory:',\n      useNullAsDefault: true,\n    });\n\n    knex.client.pool.on('createSuccess', (_eventId: any, resource: any) => {\n      resource.run('PRAGMA foreign_keys = ON', () => {});\n    });\n\n    return knex;\n  }\n\n  public static async createTestDatabase(): Promise<Database> {\n    const knex = await this.createTestDatabaseConnection();\n    return await this.createDatabase(knex);\n  }\n\n  public static async createTestDatabaseConnection(): Promise<Knex> {\n    const config: Knex.Config<any> = {\n      /*\n      client: 'pg',\n      connection: {\n        host: 'localhost',\n        user: 'postgres',\n        password: 'postgres',\n      },\n      */\n      client: 'sqlite3',\n      connection: ':memory:',\n      useNullAsDefault: true,\n    };\n\n    let knex = knexFactory(config);\n    if (typeof config.connection !== 'string') {\n      const tempDbName = `d${uuidv4().replace(/-/g, '')}`;\n      await knex.raw(`CREATE DATABASE ${tempDbName};`);\n      knex = knexFactory({\n        ...config,\n        connection: {\n          ...config.connection,\n          database: tempDbName,\n        },\n      });\n    }\n\n    knex.client.pool.on('createSuccess', (_eventId: any, resource: any) => {\n      resource.run('PRAGMA foreign_keys = ON', () => {});\n    });\n\n    return knex;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Runs a function repeatedly, with a fixed wait between invocations.\n *\n * Supports async functions, and silently ignores exceptions and rejections.\n *\n * @param fn The function to run. May return a Promise.\n * @param delayMs The delay between a completed function invocation and the\n *                next.\n * @returns A function that, when called, stops the invocation loop.\n */\nexport function runPeriodically(fn: () => any, delayMs: number): () => void {\n  let cancel: () => void;\n  let cancelled = false;\n  const cancellationPromise = new Promise<void>(resolve => {\n    cancel = () => {\n      resolve();\n      cancelled = true;\n    };\n  });\n\n  const startRefresh = async () => {\n    while (!cancelled) {\n      try {\n        await fn();\n      } catch {\n        // ignore intentionally\n      }\n\n      await Promise.race([\n        new Promise(resolve => setTimeout(resolve, delayMs)),\n        cancellationPromise,\n      ]);\n    }\n  };\n  startRefresh();\n\n  return cancel!;\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Location,\n  LocationSpec,\n  stringifyLocationReference,\n} from '@backstage/catalog-model';\nimport { v4 as uuidv4 } from 'uuid';\nimport { Logger } from 'winston';\nimport { EntitiesCatalog, LocationsCatalog } from '../catalog';\nimport { durationText } from '../util';\nimport {\n  AddLocationResult,\n  HigherOrderOperation,\n  LocationReader,\n} from './types';\n\n/**\n * Placeholder for operations that span several catalogs and/or stretches out\n * in time.\n *\n * TODO(freben): Find a better home for these, possibly refactoring to use the\n * database more directly.\n */\nexport class HigherOrderOperations implements HigherOrderOperation {\n  constructor(\n    private readonly entitiesCatalog: EntitiesCatalog,\n    private readonly locationsCatalog: LocationsCatalog,\n    private readonly locationReader: LocationReader,\n    private readonly logger: Logger,\n  ) {}\n\n  /**\n   * Adds a single location to the catalog.\n   *\n   * The location is inspected and fetched, and all of the resulting data is\n   * validated. If everything goes well, the location and entities are stored\n   * in the catalog.\n   *\n   * If the location already existed, the old location is returned instead and\n   * the catalog is left unchanged.\n   *\n   * @param spec The location to add\n   */\n  async addLocation(\n    spec: LocationSpec,\n    options?: { dryRun?: boolean },\n  ): Promise<AddLocationResult> {\n    const dryRun = options?.dryRun || false;\n\n    // Attempt to find a previous location matching the spec\n    const previousLocations = await this.locationsCatalog.locations();\n    const previousLocation = previousLocations.find(\n      l => spec.type === l.data.type && spec.target === l.data.target,\n    );\n    const location: Location = previousLocation\n      ? previousLocation.data\n      : {\n          id: uuidv4(),\n          type: spec.type,\n          target: spec.target,\n        };\n\n    // Read the location fully, bailing on any errors\n    const readerOutput = await this.locationReader.read(spec);\n    if (!(spec.presence === 'optional') && readerOutput.errors.length) {\n      const item = readerOutput.errors[0];\n      throw item.error;\n    }\n\n    // TODO(freben): At this point, we could detect orphaned entities, by way\n    // of having a location annotation pointing to the location but not being\n    // in the entities list. But we aren't sure what to do about those yet.\n\n    // Write\n    if (!previousLocation && !dryRun) {\n      // TODO: We do not include location operations in the dryRun. We might perform\n      // this operation as a separate dry run.\n      await this.locationsCatalog.addLocation(location);\n    }\n    if (readerOutput.entities.length === 0) {\n      return { location, entities: [] };\n    }\n\n    const writtenEntities = await this.entitiesCatalog.batchAddOrUpdateEntities(\n      readerOutput.entities,\n      {\n        locationId: dryRun ? undefined : location.id,\n        dryRun,\n        outputEntities: true,\n      },\n    );\n\n    const entities = writtenEntities.map(e => e.entity!);\n\n    return { location, entities };\n  }\n\n  /**\n   * Goes through all registered locations, and performs a refresh of each one.\n   *\n   * Entities are read from their respective sources, are parsed and validated\n   * according to the entity policy, and get inserted or updated in the catalog.\n   * Entities that have disappeared from their location are left orphaned,\n   * without changes.\n   */\n  async refreshAllLocations(): Promise<void> {\n    const startTimestamp = process.hrtime();\n    const logger = this.logger.child({\n      component: 'catalog-all-locations-refresh',\n    });\n\n    logger.info('Locations Refresh: Beginning locations refresh');\n\n    const locations = await this.locationsCatalog.locations();\n    logger.info(`Locations Refresh: Visiting ${locations.length} locations`);\n\n    for (const { data: location } of locations) {\n      logger.info(\n        `Locations Refresh: Refreshing location ${stringifyLocationReference(\n          location,\n        )}`,\n      );\n      try {\n        await this.refreshSingleLocation(location, logger);\n        await this.locationsCatalog.logUpdateSuccess(location.id, undefined);\n      } catch (e) {\n        logger.warn(\n          `Locations Refresh: Failed to refresh location ${stringifyLocationReference(\n            location,\n          )}, ${e.stack}`,\n        );\n        await this.locationsCatalog.logUpdateFailure(location.id, e);\n      }\n    }\n\n    logger.info(\n      `Locations Refresh: Completed locations refresh in ${durationText(\n        startTimestamp,\n      )}`,\n    );\n  }\n\n  // Performs a full refresh of a single location\n  private async refreshSingleLocation(\n    location: Location,\n    optionalLogger?: Logger,\n  ) {\n    let startTimestamp = process.hrtime();\n    const logger = optionalLogger || this.logger;\n\n    const readerOutput = await this.locationReader.read({\n      type: location.type,\n      target: location.target,\n    });\n\n    for (const item of readerOutput.errors) {\n      logger.warn(\n        `Failed item in location ${stringifyLocationReference(\n          item.location,\n        )}, ${item.error.stack}`,\n      );\n    }\n\n    logger.info(\n      `Read ${\n        readerOutput.entities.length\n      } entities from location ${stringifyLocationReference(\n        location,\n      )} in ${durationText(startTimestamp)}`,\n    );\n\n    startTimestamp = process.hrtime();\n\n    try {\n      await this.entitiesCatalog.batchAddOrUpdateEntities(\n        readerOutput.entities,\n        { locationId: location.id },\n      );\n    } catch (e) {\n      for (const entity of readerOutput.entities) {\n        await this.locationsCatalog.logUpdateFailure(\n          location.id,\n          e,\n          entity.entity.metadata.name,\n        );\n      }\n      throw e;\n    }\n\n    logger.debug(`Posting update success markers`);\n\n    await this.locationsCatalog.logUpdateSuccess(\n      location.id,\n      readerOutput.entities.map(e => e.entity.metadata.name),\n    );\n\n    logger.info(\n      `Wrote ${\n        readerOutput.entities.length\n      } entities from location ${stringifyLocationReference(\n        location,\n      )} in ${durationText(startTimestamp)}`,\n    );\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError, NotFoundError } from '@backstage/errors';\nimport {\n  Entity,\n  EntityRelationSpec,\n  LocationSpec,\n} from '@backstage/catalog-model';\nimport { CatalogProcessorResult } from './types';\n\nexport function notFoundError(\n  atLocation: LocationSpec,\n  message: string,\n): CatalogProcessorResult {\n  return {\n    type: 'error',\n    location: atLocation,\n    error: new NotFoundError(message),\n  };\n}\n\nexport function inputError(\n  atLocation: LocationSpec,\n  message: string,\n): CatalogProcessorResult {\n  return {\n    type: 'error',\n    location: atLocation,\n    error: new InputError(message),\n  };\n}\n\nexport function generalError(\n  atLocation: LocationSpec,\n  message: string,\n): CatalogProcessorResult {\n  return { type: 'error', location: atLocation, error: new Error(message) };\n}\n\nexport function location(\n  newLocation: LocationSpec,\n  optional: boolean,\n): CatalogProcessorResult {\n  return { type: 'location', location: newLocation, optional };\n}\n\nexport function entity(\n  atLocation: LocationSpec,\n  newEntity: Entity,\n): CatalogProcessorResult {\n  return { type: 'entity', location: atLocation, entity: newEntity };\n}\n\nexport function relation(spec: EntityRelationSpec): CatalogProcessorResult {\n  return { type: 'relation', relation: spec };\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NotAllowedError } from '@backstage/errors';\nimport { UrlReader } from '@backstage/backend-common';\nimport {\n  Entity,\n  EntityPolicy,\n  EntityRelationSpec,\n  ENTITY_DEFAULT_NAMESPACE,\n  LocationSpec,\n  stringifyLocationReference,\n} from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { Logger } from 'winston';\nimport { CatalogRulesEnforcer } from './CatalogRules';\nimport * as result from './processors/results';\nimport {\n  CatalogProcessor,\n  CatalogProcessorEmit,\n  CatalogProcessorEntityResult,\n  CatalogProcessorErrorResult,\n  CatalogProcessorLocationResult,\n  CatalogProcessorParser,\n  CatalogProcessorResult,\n} from './processors/types';\nimport { LocationReader, ReadLocationResult } from './types';\n\n// The max amount of nesting depth of generated work items\nconst MAX_DEPTH = 10;\n\ntype Options = {\n  reader: UrlReader;\n  parser: CatalogProcessorParser;\n  logger: Logger;\n  config: Config;\n  processors: CatalogProcessor[];\n  rulesEnforcer: CatalogRulesEnforcer;\n  policy: EntityPolicy;\n};\n\n/**\n * Implements the reading of a location through a series of processor tasks.\n */\nexport class LocationReaders implements LocationReader {\n  private readonly options: Options;\n\n  constructor(options: Options) {\n    this.options = options;\n  }\n\n  async read(location: LocationSpec): Promise<ReadLocationResult> {\n    const { rulesEnforcer, logger } = this.options;\n\n    const output: ReadLocationResult = {\n      entities: [],\n      errors: [],\n    };\n    let items: CatalogProcessorResult[] = [result.location(location, false)];\n\n    for (let depth = 0; depth < MAX_DEPTH; ++depth) {\n      const newItems: CatalogProcessorResult[] = [];\n      const emit: CatalogProcessorEmit = i => newItems.push(i);\n\n      for (const item of items) {\n        if (item.type === 'location') {\n          await this.handleLocation(item, emit);\n        } else if (item.type === 'entity') {\n          if (rulesEnforcer.isAllowed(item.entity, item.location)) {\n            const relations = Array<EntityRelationSpec>();\n\n            const entity = await this.handleEntity(\n              item,\n              emitResult => {\n                if (emitResult.type === 'relation') {\n                  relations.push(emitResult.relation);\n                  return;\n                }\n                emit(emitResult);\n              },\n              location,\n            );\n\n            if (entity) {\n              output.entities.push({\n                entity,\n                location: item.location,\n                relations,\n              });\n            }\n          } else {\n            output.errors.push({\n              location: item.location,\n              error: new NotAllowedError(\n                `Entity of kind ${\n                  item.entity.kind\n                } is not allowed from location ${stringifyLocationReference(\n                  item.location,\n                )}`,\n              ),\n            });\n          }\n        } else if (item.type === 'error') {\n          await this.handleError(item, emit);\n          output.errors.push({\n            location: item.location,\n            error: item.error,\n          });\n        }\n      }\n\n      if (newItems.length === 0) {\n        return output;\n      }\n\n      items = newItems;\n    }\n\n    const message = `Max recursion depth ${MAX_DEPTH} reached for location ${location.type} ${location.target}`;\n    logger.warn(message);\n    output.errors.push({ location, error: new Error(message) });\n    return output;\n  }\n\n  private async handleLocation(\n    item: CatalogProcessorLocationResult,\n    emit: CatalogProcessorEmit,\n  ) {\n    const { processors, logger } = this.options;\n\n    const validatedEmit: CatalogProcessorEmit = emitResult => {\n      if (emitResult.type === 'relation') {\n        throw new Error('readLocation may not emit entity relations');\n      }\n      if (\n        emitResult.type === 'location' &&\n        emitResult.location.type === item.location.type &&\n        emitResult.location.target === item.location.target\n      ) {\n        // Ignore self-referential locations silently (this can happen for\n        // example if you use a glob target like \"**/*.yaml\" in a Location\n        // entity)\n        return;\n      }\n      emit(emitResult);\n    };\n\n    for (const processor of processors) {\n      if (processor.readLocation) {\n        try {\n          if (\n            await processor.readLocation(\n              item.location,\n              item.optional,\n              validatedEmit,\n              this.options.parser,\n            )\n          ) {\n            return;\n          }\n        } catch (e) {\n          const message = `Processor ${\n            processor.constructor.name\n          } threw an error while reading location ${stringifyLocationReference(\n            item.location,\n          )}, ${e}`;\n          emit(result.generalError(item.location, message));\n          logger.warn(message);\n        }\n      }\n    }\n\n    const message = `No processor was able to read location ${stringifyLocationReference(\n      item.location,\n    )}`;\n    emit(result.inputError(item.location, message));\n    logger.warn(message);\n  }\n\n  private async handleEntity(\n    item: CatalogProcessorEntityResult,\n    emit: CatalogProcessorEmit,\n    originLocation: LocationSpec,\n  ): Promise<Entity | undefined> {\n    const { processors, logger } = this.options;\n\n    let current = item.entity;\n\n    // Construct the name carefully, this happens before validation below\n    // so we do not want to crash here due to missing metadata or so\n    const kind = current.kind || '';\n    const namespace = !current.metadata\n      ? ''\n      : current.metadata.namespace ?? ENTITY_DEFAULT_NAMESPACE;\n    const name = !current.metadata ? '' : current.metadata.name;\n\n    for (const processor of processors) {\n      if (processor.preProcessEntity) {\n        try {\n          current = await processor.preProcessEntity(\n            current,\n            item.location,\n            emit,\n            originLocation,\n          );\n        } catch (e) {\n          const message = `Processor ${\n            processor.constructor.name\n          } threw an error while preprocessing entity ${kind}:${namespace}/${name} at ${stringifyLocationReference(\n            item.location,\n          )}, ${e}`;\n          emit(result.generalError(item.location, e.message));\n          logger.warn(message);\n          return undefined;\n        }\n      }\n    }\n\n    try {\n      const next = await this.options.policy.enforce(current);\n      if (!next) {\n        const message = `Policy unexpectedly returned no data while analyzing entity ${kind}:${namespace}/${name} at ${stringifyLocationReference(\n          item.location,\n        )}`;\n        emit(result.generalError(item.location, message));\n        logger.warn(message);\n        return undefined;\n      }\n      current = next;\n    } catch (e) {\n      const message = `Policy check failed while analyzing entity ${kind}:${namespace}/${name} at ${stringifyLocationReference(\n        item.location,\n      )}, ${e}`;\n      emit(result.inputError(item.location, e.message));\n      logger.warn(message);\n      return undefined;\n    }\n\n    let handled = false;\n    for (const processor of processors) {\n      if (processor.validateEntityKind) {\n        try {\n          handled = await processor.validateEntityKind(current);\n          if (handled) {\n            break;\n          }\n        } catch (e) {\n          const message = `Processor ${\n            processor.constructor.name\n          } threw an error while validating the entity ${kind}:${namespace}/${name} at ${stringifyLocationReference(\n            item.location,\n          )}, ${e}`;\n          emit(result.inputError(item.location, message));\n          logger.warn(message);\n          return undefined;\n        }\n      }\n    }\n    if (!handled) {\n      const message = `No processor recognized the entity ${kind}:${namespace}/${name} at ${stringifyLocationReference(\n        item.location,\n      )}`;\n      emit(result.inputError(item.location, message));\n      logger.warn(message);\n      return undefined;\n    }\n\n    for (const processor of processors) {\n      if (processor.postProcessEntity) {\n        try {\n          current = await processor.postProcessEntity(\n            current,\n            item.location,\n            emit,\n          );\n        } catch (e) {\n          const message = `Processor ${\n            processor.constructor.name\n          } threw an error while postprocessing entity ${kind}:${namespace}/${name} at ${stringifyLocationReference(\n            item.location,\n          )}, ${e}`;\n          emit(result.generalError(item.location, message));\n          logger.warn(message);\n          return undefined;\n        }\n      }\n    }\n\n    return current;\n  }\n\n  private async handleError(\n    item: CatalogProcessorErrorResult,\n    emit: CatalogProcessorEmit,\n  ) {\n    const { processors, logger } = this.options;\n\n    logger.debug(\n      `Encountered error at location ${stringifyLocationReference(\n        item.location,\n      )}, ${item.error}`,\n    );\n\n    const validatedEmit: CatalogProcessorEmit = emitResult => {\n      if (emitResult.type === 'relation') {\n        throw new Error('handleError may not emit entity relations');\n      }\n\n      emit(emitResult);\n    };\n\n    for (const processor of processors) {\n      if (processor.handleError) {\n        try {\n          await processor.handleError(item.error, item.location, validatedEmit);\n        } catch (e) {\n          const message = `Processor ${\n            processor.constructor.name\n          } threw an error while handling another error at ${stringifyLocationReference(\n            item.location,\n          )}, ${e}`;\n          emit(result.generalError(item.location, message));\n          logger.warn(message);\n        }\n      }\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  EDIT_URL_ANNOTATION,\n  Entity,\n  LocationSpec,\n  LOCATION_ANNOTATION,\n  ORIGIN_LOCATION_ANNOTATION,\n  SOURCE_LOCATION_ANNOTATION,\n  stringifyLocationReference,\n  VIEW_URL_ANNOTATION,\n} from '@backstage/catalog-model';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport { identity, merge, pickBy } from 'lodash';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\n\ntype Options = {\n  integrations: ScmIntegrationRegistry;\n};\n\nexport class AnnotateLocationEntityProcessor implements CatalogProcessor {\n  constructor(private readonly options: Options) {}\n\n  async preProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n    _: CatalogProcessorEmit,\n    originLocation: LocationSpec,\n  ): Promise<Entity> {\n    const { integrations } = this.options;\n    let viewUrl;\n    let editUrl;\n    let sourceLocation;\n\n    if (location.type === 'url') {\n      const scmIntegration = integrations.byUrl(location.target);\n\n      viewUrl = location.target;\n      editUrl = scmIntegration?.resolveEditUrl(location.target);\n\n      const sourceUrl = scmIntegration?.resolveUrl({\n        url: './',\n        base: location.target,\n      });\n\n      if (sourceUrl) {\n        sourceLocation = stringifyLocationReference({\n          type: 'url',\n          target: sourceUrl,\n        });\n      }\n    }\n\n    return merge(\n      {\n        metadata: {\n          annotations: pickBy(\n            {\n              [LOCATION_ANNOTATION]: stringifyLocationReference(location),\n              [ORIGIN_LOCATION_ANNOTATION]: stringifyLocationReference(\n                originLocation,\n              ),\n              [VIEW_URL_ANNOTATION]: viewUrl,\n              [EDIT_URL_ANNOTATION]: editUrl,\n              [SOURCE_LOCATION_ANNOTATION]: sourceLocation,\n            },\n            identity,\n          ),\n        },\n      },\n      entity,\n    );\n  }\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { Entity, LocationSpec } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport {\n  ScmIntegrationRegistry,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport parseGitUrl from 'git-url-parse';\nimport { identity, merge, pickBy } from 'lodash';\nimport { CatalogProcessor } from './types';\n\nconst GITHUB_ACTIONS_ANNOTATION = 'github.com/project-slug';\n\nexport class AnnotateScmSlugEntityProcessor implements CatalogProcessor {\n  constructor(\n    private readonly opts: { scmIntegrationRegistry: ScmIntegrationRegistry },\n  ) {}\n\n  static fromConfig(config: Config): AnnotateScmSlugEntityProcessor {\n    return new AnnotateScmSlugEntityProcessor({\n      scmIntegrationRegistry: ScmIntegrations.fromConfig(config),\n    });\n  }\n\n  async preProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n  ): Promise<Entity> {\n    if (entity.kind !== 'Component' || location.type !== 'url') {\n      return entity;\n    }\n\n    const scmIntegration = this.opts.scmIntegrationRegistry.byUrl(\n      location.target,\n    );\n\n    if (!scmIntegration || scmIntegration.type !== 'github') {\n      return entity;\n    }\n\n    const gitUrl = parseGitUrl(location.target);\n    let githubProjectSlug =\n      entity.metadata.annotations?.[GITHUB_ACTIONS_ANNOTATION];\n\n    if (!githubProjectSlug) {\n      githubProjectSlug = `${gitUrl.owner}/${gitUrl.name}`;\n    }\n\n    return merge(\n      {\n        metadata: {\n          annotations: pickBy(\n            {\n              [GITHUB_ACTIONS_ANNOTATION]: githubProjectSlug,\n            },\n            identity,\n          ),\n        },\n      },\n      entity,\n    );\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\n\n/**\n * The configuration parameters for a single AWS Organization Processor\n */\nexport type AwsOrganizationProviderConfig = {\n  /**\n   * The role to assume for the processor.\n   */\n  roleArn?: string;\n};\n\nexport function readAwsOrganizationConfig(\n  config: Config,\n): AwsOrganizationProviderConfig {\n  const providerConfig = config.getOptionalConfig('provider');\n\n  const roleArn = providerConfig?.getOptionalString('roleArn');\n  return {\n    roleArn,\n  };\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { LocationSpec, ResourceEntityV1alpha1 } from '@backstage/catalog-model';\nimport AWS, { Credentials, Organizations } from 'aws-sdk';\nimport { Account, ListAccountsResponse } from 'aws-sdk/clients/organizations';\n\nimport * as results from './results';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\nimport { Config } from '@backstage/config';\nimport { Logger } from 'winston';\nimport {\n  AwsOrganizationProviderConfig,\n  readAwsOrganizationConfig,\n} from './awsOrganization/config';\n\nconst AWS_ORGANIZATION_REGION = 'us-east-1';\nconst LOCATION_TYPE = 'aws-cloud-accounts';\n\nconst ACCOUNTID_ANNOTATION: string = 'amazonaws.com/account-id';\nconst ARN_ANNOTATION: string = 'amazonaws.com/arn';\nconst ORGANIZATION_ANNOTATION: string = 'amazonaws.com/organization-id';\n\n/**\n * A processor for ingesting AWS Accounts from AWS Organizations.\n *\n * If custom authentication is needed, it can be achieved by configuring the global AWS.credentials object.\n */\nexport class AwsOrganizationCloudAccountProcessor implements CatalogProcessor {\n  logger: Logger;\n  organizations: Organizations;\n  provider: AwsOrganizationProviderConfig;\n\n  static fromConfig(config: Config, options: { logger: Logger }) {\n    const c = config.getOptionalConfig('catalog.processors.awsOrganization');\n    return new AwsOrganizationCloudAccountProcessor({\n      ...options,\n      provider: c ? readAwsOrganizationConfig(c) : {},\n    });\n  }\n\n  private static buildCredentials(\n    config: AwsOrganizationProviderConfig,\n  ): Credentials | undefined {\n    const roleArn = config.roleArn;\n    if (!roleArn) {\n      return undefined;\n    }\n\n    return new AWS.ChainableTemporaryCredentials({\n      params: {\n        RoleSessionName: 'backstage-aws-organization-processor',\n        RoleArn: roleArn,\n      },\n    });\n  }\n\n  constructor(options: {\n    provider: AwsOrganizationProviderConfig;\n    logger: Logger;\n  }) {\n    this.provider = options.provider;\n    this.logger = options.logger;\n    const credentials = AwsOrganizationCloudAccountProcessor.buildCredentials(\n      this.provider,\n    );\n    this.organizations = new AWS.Organizations({\n      credentials,\n      region: AWS_ORGANIZATION_REGION,\n    }); // Only available in us-east-1\n  }\n\n  normalizeName(name: string): string {\n    return name\n      .trim()\n      .toLocaleLowerCase()\n      .replace(/[^a-zA-Z0-9\\-]/g, '-');\n  }\n\n  extractInformationFromArn(\n    arn: string,\n  ): { accountId: string; organizationId: string } {\n    const parts = arn.split('/');\n\n    return {\n      accountId: parts[parts.length - 1],\n      organizationId: parts[parts.length - 2],\n    };\n  }\n\n  async getAwsAccounts(): Promise<Account[]> {\n    let awsAccounts: Account[] = [];\n    let isInitialAttempt = true;\n    let nextToken = undefined;\n    while (isInitialAttempt || nextToken) {\n      isInitialAttempt = false;\n      const orgAccounts: ListAccountsResponse = await this.organizations\n        .listAccounts({ NextToken: nextToken })\n        .promise();\n      if (orgAccounts.Accounts) {\n        awsAccounts = awsAccounts.concat(orgAccounts.Accounts);\n      }\n      nextToken = orgAccounts.NextToken;\n    }\n\n    return awsAccounts;\n  }\n\n  mapAccountToComponent(account: Account): ResourceEntityV1alpha1 {\n    const { accountId, organizationId } = this.extractInformationFromArn(\n      account.Arn as string,\n    );\n    return {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'Resource',\n      metadata: {\n        annotations: {\n          [ACCOUNTID_ANNOTATION]: accountId,\n          [ARN_ANNOTATION]: account.Arn || '',\n          [ORGANIZATION_ANNOTATION]: organizationId,\n        },\n        name: this.normalizeName(account.Name || ''),\n        namespace: 'default',\n      },\n      spec: {\n        type: 'cloud-account',\n        owner: 'unknown',\n      },\n    };\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    if (location.type !== LOCATION_TYPE) {\n      return false;\n    }\n\n    (await this.getAwsAccounts())\n      .map(account => this.mapAccountToComponent(account))\n      .filter(entity => {\n        if (location.target !== '') {\n          if (entity.metadata.annotations) {\n            return (\n              entity.metadata.annotations[ORGANIZATION_ANNOTATION] ===\n              location.target\n            );\n          }\n          return false;\n        }\n        return true;\n      })\n      .forEach((entity: ResourceEntityV1alpha1) => {\n        emit(results.entity(location, entity));\n      });\n\n    return true;\n  }\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport fetch from 'cross-fetch';\n\nimport {\n  BitbucketIntegrationConfig,\n  getBitbucketRequestOptions,\n} from '@backstage/integration';\n\nexport class BitbucketClient {\n  private readonly config: BitbucketIntegrationConfig;\n\n  constructor(options: { config: BitbucketIntegrationConfig }) {\n    this.config = options.config;\n  }\n\n  async listProjects(options?: ListOptions): Promise<PagedResponse<any>> {\n    return this.pagedRequest(`${this.config.apiBaseUrl}/projects`, options);\n  }\n\n  async listRepositories(\n    projectKey: string,\n    options?: ListOptions,\n  ): Promise<PagedResponse<any>> {\n    return this.pagedRequest(\n      `${this.config.apiBaseUrl}/projects/${projectKey}/repos`,\n      options,\n    );\n  }\n\n  private async pagedRequest(\n    endpoint: string,\n    options?: ListOptions,\n  ): Promise<PagedResponse<any>> {\n    const request = new URL(endpoint);\n    for (const key in options) {\n      if (options[key]) {\n        request.searchParams.append(key, options[key]!.toString());\n      }\n    }\n\n    const response = await fetch(\n      request.toString(),\n      getBitbucketRequestOptions(this.config),\n    );\n    if (!response.ok) {\n      throw new Error(\n        `Unexpected response when fetching ${request.toString()}. Expected 200 but got ${\n          response.status\n        } - ${response.statusText}`,\n      );\n    }\n    return response.json().then(repositories => {\n      return repositories as PagedResponse<any>;\n    });\n  }\n}\n\nexport type ListOptions = {\n  [key: string]: number | undefined;\n  limit?: number | undefined;\n  start?: number | undefined;\n};\n\nexport type PagedResponse<T> = {\n  size: number;\n  limit: number;\n  start: number;\n  isLastPage: boolean;\n  values: T[];\n  nextPageStart: number;\n};\n\nexport async function* paginated(\n  request: (options: ListOptions) => Promise<PagedResponse<any>>,\n  options?: ListOptions,\n) {\n  const opts = options || { start: 0 };\n  let res;\n  do {\n    res = await request(opts);\n    opts.start = res.nextPageStart;\n    for (const item of res.values) {\n      yield item;\n    }\n  } while (!res.isLastPage);\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { CatalogProcessorResult } from '../types';\nimport { results } from '../index';\nimport { Logger } from 'winston';\nimport { BitbucketIntegration } from '@backstage/integration';\n\nexport type BitbucketRepositoryParser = (options: {\n  integration: BitbucketIntegration;\n  target: string;\n  logger: Logger;\n}) => AsyncIterable<CatalogProcessorResult>;\n\nexport const defaultRepositoryParser: BitbucketRepositoryParser = async function* defaultRepositoryParser({\n  target,\n}) {\n  yield results.location(\n    {\n      type: 'url',\n      target: target,\n    },\n    // Not all locations may actually exist, since the user defined them as a wildcard pattern.\n    // Thus, we emit them as optional and let the downstream processor find them while not outputting\n    // an error if it couldn't.\n    true,\n  );\n};\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { Logger } from 'winston';\nimport { Config } from '@backstage/config';\n\nimport {\n  ScmIntegrationRegistry,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport { LocationSpec } from '@backstage/catalog-model';\nimport {\n  BitbucketRepositoryParser,\n  BitbucketClient,\n  defaultRepositoryParser,\n  paginated,\n  BitbucketRepository,\n} from './bitbucket';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\n\nexport class BitbucketDiscoveryProcessor implements CatalogProcessor {\n  private readonly integrations: ScmIntegrationRegistry;\n  private readonly parser: BitbucketRepositoryParser;\n  private readonly logger: Logger;\n\n  static fromConfig(\n    config: Config,\n    options: { parser?: BitbucketRepositoryParser; logger: Logger },\n  ) {\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    return new BitbucketDiscoveryProcessor({\n      ...options,\n      integrations,\n    });\n  }\n\n  constructor(options: {\n    integrations: ScmIntegrationRegistry;\n    parser?: BitbucketRepositoryParser;\n    logger: Logger;\n  }) {\n    this.integrations = options.integrations;\n    this.parser = options.parser || defaultRepositoryParser;\n    this.logger = options.logger;\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    if (location.type !== 'bitbucket-discovery') {\n      return false;\n    }\n\n    const integration = this.integrations.bitbucket.byUrl(location.target);\n    if (!integration) {\n      throw new Error(\n        `There is no Bitbucket integration that matches ${location.target}. Please add a configuration entry for it under integrations.bitbucket`,\n      );\n    } else if (integration.config.host === 'bitbucket.org') {\n      throw new Error(\n        `Component discovery for Bitbucket Cloud is not yet supported`,\n      );\n    }\n\n    const client = new BitbucketClient({\n      config: integration.config,\n    });\n    const startTimestamp = Date.now();\n    this.logger.info(`Reading Bitbucket repositories from ${location.target}`);\n\n    const { catalogPath } = parseUrl(location.target);\n\n    const result = await readBitbucketOrg(client, location.target);\n\n    for (const repository of result.matches) {\n      for await (const entity of this.parser({\n        integration: integration,\n        target: `${repository.links.self[0].href}${catalogPath}`,\n        logger: this.logger,\n      })) {\n        emit(entity);\n      }\n    }\n\n    const duration = ((Date.now() - startTimestamp) / 1000).toFixed(1);\n    this.logger.debug(\n      `Read ${result.scanned} Bitbucket repositories (${result.matches.length} matching the pattern) in ${duration} seconds`,\n    );\n\n    return true;\n  }\n}\n\nexport async function readBitbucketOrg(\n  client: BitbucketClient,\n  target: string,\n): Promise<Result> {\n  const { projectSearchPath, repoSearchPath } = parseUrl(target);\n  const projects = paginated(options => client.listProjects(options));\n  const result: Result = {\n    scanned: 0,\n    matches: [],\n  };\n\n  for await (const project of projects) {\n    if (!projectSearchPath.test(project.key)) {\n      continue;\n    }\n    const repositories = paginated(options =>\n      client.listRepositories(project.key, options),\n    );\n    for await (const repository of repositories) {\n      result.scanned++;\n      if (repoSearchPath.test(repository.slug)) {\n        result.matches.push(repository);\n      }\n    }\n  }\n  return result;\n}\n\nfunction parseUrl(\n  urlString: string,\n): { projectSearchPath: RegExp; repoSearchPath: RegExp; catalogPath: string } {\n  const url = new URL(urlString);\n  const path = url.pathname.substr(1).split('/');\n\n  // /projects/backstage/repos/techdocs-*/catalog-info.yaml\n  if (path.length > 3 && path[1].length && path[3].length) {\n    return {\n      projectSearchPath: escapeRegExp(decodeURIComponent(path[1])),\n      repoSearchPath: escapeRegExp(decodeURIComponent(path[3])),\n      catalogPath: `/${decodeURIComponent(path.slice(4).join('/'))}`,\n    };\n  }\n\n  throw new Error(`Failed to parse ${urlString}`);\n}\n\nfunction escapeRegExp(str: string): RegExp {\n  return new RegExp(`^${str.replace(/\\*/g, '.*')}$`);\n}\n\ntype Result = {\n  scanned: number;\n  matches: BitbucketRepository[];\n};\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ApiEntity,\n  apiEntityV1alpha1Validator,\n  ComponentEntity,\n  componentEntityV1alpha1Validator,\n  DomainEntity,\n  domainEntityV1alpha1Validator,\n  Entity,\n  getEntityName,\n  GroupEntity,\n  groupEntityV1alpha1Validator,\n  locationEntityV1alpha1Validator,\n  LocationSpec,\n  parseEntityRef,\n  RELATION_API_CONSUMED_BY,\n  RELATION_API_PROVIDED_BY,\n  RELATION_CHILD_OF,\n  RELATION_CONSUMES_API,\n  RELATION_DEPENDENCY_OF,\n  RELATION_DEPENDS_ON,\n  RELATION_HAS_MEMBER,\n  RELATION_HAS_PART,\n  RELATION_MEMBER_OF,\n  RELATION_OWNED_BY,\n  RELATION_OWNER_OF,\n  RELATION_PARENT_OF,\n  RELATION_PART_OF,\n  RELATION_PROVIDES_API,\n  ResourceEntity,\n  resourceEntityV1alpha1Validator,\n  SystemEntity,\n  systemEntityV1alpha1Validator,\n  TemplateEntity,\n  templateEntityV1alpha1Validator,\n  templateEntityV1beta2Validator,\n  UserEntity,\n  userEntityV1alpha1Validator,\n} from '@backstage/catalog-model';\nimport * as result from './results';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\n\nexport class BuiltinKindsEntityProcessor implements CatalogProcessor {\n  private readonly validators = [\n    apiEntityV1alpha1Validator,\n    componentEntityV1alpha1Validator,\n    resourceEntityV1alpha1Validator,\n    groupEntityV1alpha1Validator,\n    locationEntityV1alpha1Validator,\n    templateEntityV1alpha1Validator,\n    templateEntityV1beta2Validator,\n    userEntityV1alpha1Validator,\n    systemEntityV1alpha1Validator,\n    domainEntityV1alpha1Validator,\n  ];\n\n  async validateEntityKind(entity: Entity): Promise<boolean> {\n    for (const validator of this.validators) {\n      const results = await validator.check(entity);\n      if (results) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  async postProcessEntity(\n    entity: Entity,\n    _location: LocationSpec,\n    emit: CatalogProcessorEmit,\n  ): Promise<Entity> {\n    const selfRef = getEntityName(entity);\n\n    /*\n     * Utilities\n     */\n\n    function doEmit(\n      targets: string | string[] | undefined,\n      context: { defaultKind?: string; defaultNamespace: string },\n      outgoingRelation: string,\n      incomingRelation: string,\n    ): void {\n      if (!targets) {\n        return;\n      }\n      for (const target of [targets].flat()) {\n        const targetRef = parseEntityRef(target, context);\n        if (targetRef.kind === undefined) {\n          throw new Error(\n            `Entity reference \"${target}\" did not specify a kind (e.g. starting with \"Component:\"), and has no default`,\n          );\n        }\n        emit(\n          result.relation({\n            source: selfRef,\n            type: outgoingRelation,\n            target: {\n              kind: targetRef.kind,\n              namespace: targetRef.namespace,\n              name: targetRef.name,\n            },\n          }),\n        );\n        emit(\n          result.relation({\n            source: {\n              kind: targetRef.kind,\n              namespace: targetRef.namespace,\n              name: targetRef.name,\n            },\n            type: incomingRelation,\n            target: selfRef,\n          }),\n        );\n      }\n    }\n\n    /*\n     * Emit relations for the Template kind\n     */\n    if (entity.kind === 'Template') {\n      const template = entity as TemplateEntity;\n      doEmit(\n        template.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n    }\n\n    /*\n     * Emit relations for the Component kind\n     */\n\n    if (entity.kind === 'Component') {\n      const component = entity as ComponentEntity;\n      doEmit(\n        component.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n      doEmit(\n        component.spec.subcomponentOf,\n        { defaultKind: 'Component', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n      doEmit(\n        component.spec.providesApis,\n        { defaultKind: 'API', defaultNamespace: selfRef.namespace },\n        RELATION_PROVIDES_API,\n        RELATION_API_PROVIDED_BY,\n      );\n      doEmit(\n        component.spec.consumesApis,\n        { defaultKind: 'API', defaultNamespace: selfRef.namespace },\n        RELATION_CONSUMES_API,\n        RELATION_API_CONSUMED_BY,\n      );\n      doEmit(\n        component.spec.dependsOn,\n        { defaultNamespace: selfRef.namespace },\n        RELATION_DEPENDS_ON,\n        RELATION_DEPENDENCY_OF,\n      );\n      doEmit(\n        component.spec.system,\n        { defaultKind: 'System', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n    }\n\n    /*\n     * Emit relations for the API kind\n     */\n\n    if (entity.kind === 'API') {\n      const api = entity as ApiEntity;\n      doEmit(\n        api.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n      doEmit(\n        api.spec.system,\n        { defaultKind: 'System', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n    }\n\n    /*\n     * Emit relations for the Resource kind\n     */\n\n    if (entity.kind === 'Resource') {\n      const resource = entity as ResourceEntity;\n      doEmit(\n        resource.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n      doEmit(\n        resource.spec.dependsOn,\n        { defaultNamespace: selfRef.namespace },\n        RELATION_DEPENDS_ON,\n        RELATION_DEPENDENCY_OF,\n      );\n      doEmit(\n        resource.spec.system,\n        { defaultKind: 'System', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n    }\n\n    /*\n     * Emit relations for the User kind\n     */\n\n    if (entity.kind === 'User') {\n      const user = entity as UserEntity;\n      doEmit(\n        user.spec.memberOf,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_MEMBER_OF,\n        RELATION_HAS_MEMBER,\n      );\n    }\n\n    /*\n     * Emit relations for the Group kind\n     */\n\n    if (entity.kind === 'Group') {\n      const group = entity as GroupEntity;\n      doEmit(\n        group.spec.parent,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_CHILD_OF,\n        RELATION_PARENT_OF,\n      );\n      doEmit(\n        group.spec.children,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_PARENT_OF,\n        RELATION_CHILD_OF,\n      );\n      doEmit(\n        group.spec.members,\n        { defaultKind: 'User', defaultNamespace: selfRef.namespace },\n        RELATION_HAS_MEMBER,\n        RELATION_MEMBER_OF,\n      );\n    }\n\n    /*\n     * Emit relations for the System kind\n     */\n\n    if (entity.kind === 'System') {\n      const system = entity as SystemEntity;\n      doEmit(\n        system.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n      doEmit(\n        system.spec.domain,\n        { defaultKind: 'Domain', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n    }\n\n    /*\n     * Emit relations for the Domain kind\n     */\n\n    if (entity.kind === 'Domain') {\n      const domain = entity as DomainEntity;\n      doEmit(\n        domain.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n    }\n\n    return entity;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as codeowners from 'codeowners-utils';\nimport { CodeOwnersEntry } from 'codeowners-utils';\nimport { filter, get, head, pipe, reverse } from 'lodash/fp';\n\nexport function resolveCodeOwner(\n  contents: string,\n  pattern = '*',\n): string | undefined {\n  const owners = codeowners.parse(contents);\n\n  return pipe(\n    filter((e: CodeOwnersEntry) => e.pattern === pattern),\n    reverse,\n    head,\n    get('owners'),\n    head,\n    normalizeCodeOwner,\n  )(owners);\n}\n\nexport function normalizeCodeOwner(owner: string) {\n  if (owner.match(/^@.*\\/.*/)) {\n    return owner.split('/')[1];\n  } else if (owner.match(/^@.*/)) {\n    return owner.substring(1);\n  } else if (owner.match(/^.*@.*\\..*$/)) {\n    return owner.split('@')[0];\n  }\n\n  return owner;\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst CODEOWNERS = 'CODEOWNERS';\n\nexport const scmCodeOwnersPaths: Record<string, string[]> = {\n  // https://mibexsoftware.atlassian.net/wiki/spaces/CODEOWNERS/pages/222822413/Usage\n  bitbucket: [CODEOWNERS, `.bitbucket/${CODEOWNERS}`],\n\n  // https://docs.gitlab.com/ee/user/project/code_owners.html#how-to-set-up-code-owners\n  gitlab: [CODEOWNERS, `.gitlab/${CODEOWNERS}`, `docs/${CODEOWNERS}`],\n\n  // https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/about-code-owners#codeowners-file-location\n  github: [CODEOWNERS, `.github/${CODEOWNERS}`, `docs/${CODEOWNERS}`],\n};\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { UrlReader } from '@backstage/backend-common';\nimport { NotFoundError } from '@backstage/errors';\nimport { ScmIntegration } from '@backstage/integration';\nimport 'core-js/features/promise'; // NOTE: This can be removed when ES2021 is implemented\nimport { resolveCodeOwner } from './resolve';\nimport { scmCodeOwnersPaths } from './scm';\n\nexport async function readCodeOwners(\n  reader: UrlReader,\n  sourceUrl: string,\n  codeownersPaths: string[],\n): Promise<string | undefined> {\n  const readOwnerLocation = async (path: string): Promise<string> => {\n    const url = `${sourceUrl}${path}`;\n    const data = await reader.read(url);\n    return data.toString();\n  };\n\n  const candidates = codeownersPaths.map(readOwnerLocation);\n\n  return Promise.any(candidates).catch((aggregateError: AggregateError) => {\n    const hardError = aggregateError.errors.find(\n      error => !(error instanceof NotFoundError),\n    );\n\n    if (hardError) {\n      throw hardError;\n    }\n\n    return undefined;\n  });\n}\n\nexport async function findCodeOwnerByTarget(\n  reader: UrlReader,\n  targetUrl: string,\n  scmIntegration: ScmIntegration,\n): Promise<string | undefined> {\n  const codeownersPaths = scmCodeOwnersPaths[scmIntegration?.type ?? ''];\n\n  const sourceUrl = scmIntegration?.resolveUrl({\n    url: '/',\n    base: targetUrl,\n  });\n\n  if (!sourceUrl || !codeownersPaths) {\n    return undefined;\n  }\n\n  const contents = await readCodeOwners(reader, sourceUrl, codeownersPaths);\n\n  if (!contents) {\n    return undefined;\n  }\n\n  const owner = resolveCodeOwner(contents);\n\n  return owner;\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { UrlReader } from '@backstage/backend-common';\nimport { Entity, LocationSpec } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { ScmIntegrations } from '@backstage/integration';\nimport { Logger } from 'winston';\nimport { findCodeOwnerByTarget } from './codeowners';\nimport { CatalogProcessor } from './types';\n\nconst ALLOWED_KINDS = ['API', 'Component', 'Domain', 'Resource', 'System'];\n\nconst ALLOWED_LOCATION_TYPES = [\n  'url',\n  'azure/api',\n  'bitbucket/api',\n  'github',\n  'github/api',\n  'gitlab',\n  'gitlab/api',\n];\n\nexport class CodeOwnersProcessor implements CatalogProcessor {\n  private readonly integrations: ScmIntegrations;\n  private readonly logger: Logger;\n  private readonly reader: UrlReader;\n\n  static fromConfig(\n    config: Config,\n    options: { logger: Logger; reader: UrlReader },\n  ) {\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    return new CodeOwnersProcessor({\n      ...options,\n      integrations,\n    });\n  }\n\n  constructor(options: {\n    integrations: ScmIntegrations;\n    logger: Logger;\n    reader: UrlReader;\n  }) {\n    this.integrations = options.integrations;\n    this.logger = options.logger;\n    this.reader = options.reader;\n  }\n\n  async preProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n  ): Promise<Entity> {\n    // Only continue if the owner is not set\n    if (\n      !entity ||\n      !ALLOWED_KINDS.includes(entity.kind) ||\n      !ALLOWED_LOCATION_TYPES.includes(location.type) ||\n      (entity.spec && entity.spec.owner)\n    ) {\n      return entity;\n    }\n\n    const scmIntegration = this.integrations.byUrl(location.target);\n    if (!scmIntegration) {\n      return entity;\n    }\n\n    const owner = await findCodeOwnerByTarget(\n      this.reader,\n      location.target,\n      scmIntegration,\n    );\n\n    if (!owner) {\n      this.logger.debug(\n        `CodeOwnerProcessor could not resolve owner for ${location.target}`,\n      );\n      return entity;\n    }\n\n    return {\n      ...entity,\n      spec: { ...entity.spec, owner },\n    };\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  LocationSpec,\n  stringifyLocationReference,\n} from '@backstage/catalog-model';\nimport lodash from 'lodash';\nimport yaml from 'yaml';\nimport * as result from '../results';\nimport { CatalogProcessorParser, CatalogProcessorResult } from '../types';\n\nexport function* parseEntityYaml(\n  data: Buffer,\n  location: LocationSpec,\n): Iterable<CatalogProcessorResult> {\n  let documents: yaml.Document.Parsed[];\n  try {\n    documents = yaml.parseAllDocuments(data.toString('utf8')).filter(d => d);\n  } catch (e) {\n    const loc = stringifyLocationReference(location);\n    const message = `Failed to parse YAML at ${loc}, ${e}`;\n    yield result.generalError(location, message);\n    return;\n  }\n\n  for (const document of documents) {\n    if (document.errors?.length) {\n      const loc = stringifyLocationReference(location);\n      const message = `YAML error at ${loc}, ${document.errors[0]}`;\n      yield result.generalError(location, message);\n    } else {\n      const json = document.toJSON();\n      if (lodash.isPlainObject(json)) {\n        yield result.entity(location, json as Entity);\n      } else if (json === null) {\n        // Ignore null values, these happen if there is an empty document in the\n        // YAML file, for example if --- is added to the end of the file.\n      } else {\n        const message = `Expected object at root, got ${typeof json}`;\n        yield result.generalError(location, message);\n      }\n    }\n  }\n}\n\nexport const defaultEntityDataParser: CatalogProcessorParser = async function* defaultEntityDataParser({\n  data,\n  location,\n}) {\n  for (const e of parseEntityYaml(data, location)) {\n    yield e;\n  }\n};\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { LocationSpec } from '@backstage/catalog-model';\nimport fs from 'fs-extra';\nimport g from 'glob';\nimport path from 'path';\nimport { promisify } from 'util';\nimport * as result from './results';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\nimport { parseEntityYaml } from './util/parse';\n\nconst glob = promisify(g);\n\nexport class FileReaderProcessor implements CatalogProcessor {\n  async readLocation(\n    location: LocationSpec,\n    optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    if (location.type !== 'file') {\n      return false;\n    }\n\n    try {\n      const fileMatches = await glob(location.target);\n\n      if (fileMatches.length > 0) {\n        for (const fileMatch of fileMatches) {\n          const data = await fs.readFile(fileMatch);\n\n          // The normalize converts to native slashes; the glob library returns\n          // forward slashes even on windows\n          for (const parseResult of parseEntityYaml(data, {\n            type: 'file',\n            target: path.normalize(fileMatch),\n          })) {\n            emit(parseResult);\n          }\n        }\n      } else if (!optional) {\n        const message = `${location.type} ${location.target} does not exist`;\n        emit(result.notFoundError(location, message));\n      }\n    } catch (e) {\n      const message = `${location.type} ${location.target} could not be read, ${e}`;\n      emit(result.generalError(location, message));\n    }\n\n    return true;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { GroupEntity, UserEntity } from '@backstage/catalog-model';\nimport { GithubCredentialType } from '@backstage/integration';\nimport { graphql } from '@octokit/graphql';\n\n// Graphql types\n\nexport type QueryResponse = {\n  organization?: Organization;\n  repositoryOwner?: Organization | User;\n};\n\nexport type Organization = {\n  membersWithRole?: Connection<User>;\n  team?: Team;\n  teams?: Connection<Team>;\n  repositories?: Connection<Repository>;\n};\n\nexport type PageInfo = {\n  hasNextPage: boolean;\n  endCursor?: string;\n};\n\nexport type User = {\n  login: string;\n  bio?: string;\n  avatarUrl?: string;\n  email?: string;\n  name?: string;\n  repositories?: Connection<Repository>;\n};\n\nexport type Team = {\n  slug: string;\n  combinedSlug: string;\n  name?: string;\n  description?: string;\n  avatarUrl?: string;\n  parentTeam?: Team;\n  members: Connection<User>;\n};\n\nexport type Repository = {\n  name: string;\n  url: string;\n  isArchived: boolean;\n};\n\nexport type Connection<T> = {\n  pageInfo: PageInfo;\n  nodes: T[];\n};\n\n/**\n * Gets all the users out of a GitHub organization.\n *\n * Note that the users will not have their memberships filled in.\n *\n * @param client An octokit graphql client\n * @param org The slug of the org to read\n */\nexport async function getOrganizationUsers(\n  client: typeof graphql,\n  org: string,\n  tokenType: GithubCredentialType,\n): Promise<{ users: UserEntity[] }> {\n  const query = `\n    query users($org: String!, $email: Boolean!, $cursor: String) {\n      organization(login: $org) {\n        membersWithRole(first: 100, after: $cursor) {\n          pageInfo { hasNextPage, endCursor }\n          nodes {\n            avatarUrl,\n            bio,\n            email @include(if: $email),\n            login,\n            name\n          }\n        }\n      }\n    }`;\n\n  // There is no user -> teams edge, so we leave the memberships empty for\n  // now and let the team iteration handle it instead\n  const mapper = (user: User) => {\n    const entity: UserEntity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'User',\n      metadata: {\n        name: user.login,\n        annotations: {\n          'github.com/user-login': user.login,\n        },\n      },\n      spec: {\n        profile: {},\n        memberOf: [],\n      },\n    };\n\n    if (user.bio) entity.metadata.description = user.bio;\n    if (user.name) entity.spec.profile!.displayName = user.name;\n    if (user.email) entity.spec.profile!.email = user.email;\n    if (user.avatarUrl) entity.spec.profile!.picture = user.avatarUrl;\n\n    return entity;\n  };\n\n  const users = await queryWithPaging(\n    client,\n    query,\n    r => r.organization?.membersWithRole,\n    mapper,\n    { org, email: tokenType === 'token' },\n  );\n\n  return { users };\n}\n\n/**\n * Gets all the teams out of a GitHub organization.\n *\n * Note that the teams will not have any relations apart from parent filled in.\n *\n * @param client An octokit graphql client\n * @param org The slug of the org to read\n */\nexport async function getOrganizationTeams(\n  client: typeof graphql,\n  org: string,\n): Promise<{\n  groups: GroupEntity[];\n  groupMemberUsers: Map<string, string[]>;\n}> {\n  const query = `\n    query teams($org: String!, $cursor: String) {\n      organization(login: $org) {\n        teams(first: 100, after: $cursor) {\n          pageInfo { hasNextPage, endCursor }\n          nodes {\n            slug\n            combinedSlug\n            name\n            description\n            avatarUrl\n            parentTeam { slug }\n            members(first: 100, membership: IMMEDIATE) {\n              pageInfo { hasNextPage }\n              nodes { login }\n            }\n          }\n        }\n      }\n    }`;\n\n  // Gets populated inside the mapper below\n  const groupMemberUsers = new Map<string, string[]>();\n\n  const mapper = async (team: Team) => {\n    const entity: GroupEntity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'Group',\n      metadata: {\n        name: team.slug,\n        annotations: {\n          'github.com/team-slug': team.combinedSlug,\n        },\n      },\n      spec: {\n        type: 'team',\n        profile: {},\n        children: [],\n      },\n    };\n\n    if (team.description) {\n      entity.metadata.description = team.description;\n    }\n    if (team.name) {\n      entity.spec.profile!.displayName = team.name;\n    }\n    if (team.avatarUrl) {\n      entity.spec.profile!.picture = team.avatarUrl;\n    }\n    if (team.parentTeam) {\n      entity.spec.parent = team.parentTeam.slug;\n    }\n\n    const memberNames: string[] = [];\n    groupMemberUsers.set(team.slug, memberNames);\n\n    if (!team.members.pageInfo.hasNextPage) {\n      // We got all the members in one go, run the fast path\n      for (const user of team.members.nodes) {\n        memberNames.push(user.login);\n      }\n    } else {\n      // There were more than a hundred immediate members - run the slow\n      // path of fetching them explicitly\n      const { members } = await getTeamMembers(client, org, team.slug);\n      for (const userLogin of members) {\n        memberNames.push(userLogin);\n      }\n    }\n\n    return entity;\n  };\n\n  const groups = await queryWithPaging(\n    client,\n    query,\n    r => r.organization?.teams,\n    mapper,\n    { org },\n  );\n\n  return { groups, groupMemberUsers };\n}\n\nexport async function getOrganizationRepositories(\n  client: typeof graphql,\n  org: string,\n): Promise<{ repositories: Repository[] }> {\n  const query = `\n    query repositories($org: String!, $cursor: String) {\n      repositoryOwner(login: $org) {\n        login\n        repositories(first: 100, after: $cursor) {\n          nodes {\n            name\n            url\n            isArchived\n          }\n          pageInfo {\n            hasNextPage\n            endCursor\n          }\n        }\n      }\n    }`;\n\n  const repositories = await queryWithPaging(\n    client,\n    query,\n    r => r.repositoryOwner?.repositories,\n    x => x,\n    { org },\n  );\n\n  return { repositories };\n}\n\n/**\n * Gets all the users out of a GitHub organization.\n *\n * Note that the users will not have their memberships filled in.\n *\n * @param client An octokit graphql client\n * @param org The slug of the org to read\n * @param teamSlug The slug of the team to read\n */\nexport async function getTeamMembers(\n  client: typeof graphql,\n  org: string,\n  teamSlug: string,\n): Promise<{ members: string[] }> {\n  const query = `\n    query members($org: String!, $teamSlug: String!, $cursor: String) {\n      organization(login: $org) {\n        team(slug: $teamSlug) {\n          members(first: 100, after: $cursor, membership: IMMEDIATE) {\n            pageInfo { hasNextPage, endCursor }\n            nodes { login }\n          }\n        }\n      }\n    }`;\n\n  const members = await queryWithPaging(\n    client,\n    query,\n    r => r.organization?.team?.members,\n    user => user.login,\n    { org, teamSlug },\n  );\n\n  return { members };\n}\n\n//\n// Helpers\n//\n\n/**\n * Assists in repeatedly executing a query with a paged response.\n *\n * Requires that the query accepts a $cursor variable.\n *\n * @param client The octokit client\n * @param query The query to execute\n * @param connection A function that, given the response, picks out the actual\n *                   Connection object that's being iterated\n * @param mapper A function that, given one of the nodes in the Connection,\n *               returns the model mapped form of it\n * @param variables The variable values that the query needs, minus the cursor\n */\nexport async function queryWithPaging<\n  GraphqlType,\n  OutputType,\n  Variables extends {},\n  Response = QueryResponse\n>(\n  client: typeof graphql,\n  query: string,\n  connection: (response: Response) => Connection<GraphqlType> | undefined,\n  mapper: (item: GraphqlType) => Promise<OutputType> | OutputType,\n  variables: Variables,\n): Promise<OutputType[]> {\n  const result: OutputType[] = [];\n\n  let cursor: string | undefined = undefined;\n  for (let j = 0; j < 1000 /* just for sanity */; ++j) {\n    const response: Response = await client(query, {\n      ...variables,\n      cursor,\n    });\n\n    const conn = connection(response);\n    if (!conn) {\n      throw new Error(`Found no match for ${JSON.stringify(variables)}`);\n    }\n\n    for (const node of conn.nodes) {\n      result.push(await mapper(node));\n    }\n\n    if (!conn.pageInfo.hasNextPage) {\n      break;\n    } else {\n      cursor = conn.pageInfo.endCursor;\n    }\n  }\n\n  return result;\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { LocationSpec } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport {\n  GithubCredentialsProvider,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport { graphql } from '@octokit/graphql';\nimport { Logger } from 'winston';\nimport { getOrganizationRepositories } from './github';\nimport * as results from './results';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\n\n/**\n * Extracts repositories out of a GitHub org.\n */\nexport class GithubDiscoveryProcessor implements CatalogProcessor {\n  private readonly integrations: ScmIntegrations;\n  private readonly logger: Logger;\n\n  static fromConfig(config: Config, options: { logger: Logger }) {\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    return new GithubDiscoveryProcessor({\n      ...options,\n      integrations,\n    });\n  }\n\n  constructor(options: { integrations: ScmIntegrations; logger: Logger }) {\n    this.integrations = options.integrations;\n    this.logger = options.logger;\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    if (location.type !== 'github-discovery') {\n      return false;\n    }\n\n    const gitHubConfig = this.integrations.github.byUrl(location.target)\n      ?.config;\n    if (!gitHubConfig) {\n      throw new Error(\n        `There is no GitHub integration that matches ${location.target}. Please add a configuration entry for it under integrations.github`,\n      );\n    }\n    const { headers } = await GithubCredentialsProvider.create(\n      gitHubConfig,\n    ).getCredentials({ url: location.target });\n    const { org, repoSearchPath, catalogPath } = parseUrl(location.target);\n\n    const client = graphql.defaults({\n      baseUrl: gitHubConfig.apiBaseUrl,\n      headers,\n    });\n\n    // Read out all of the raw data\n    const startTimestamp = Date.now();\n    this.logger.info(`Reading GitHub repositories from ${location.target}`);\n\n    const { repositories } = await getOrganizationRepositories(client, org);\n    const matching = repositories.filter(\n      r => !r.isArchived && repoSearchPath.test(r.name),\n    );\n\n    const duration = ((Date.now() - startTimestamp) / 1000).toFixed(1);\n    this.logger.debug(\n      `Read ${repositories.length} GitHub repositories (${matching.length} matching the pattern) in ${duration} seconds`,\n    );\n\n    for (const repository of matching) {\n      emit(\n        results.location(\n          {\n            type: 'url',\n            target: `${repository.url}${catalogPath}`,\n          },\n          // Not all locations may actually exist, since the user defined them as a wildcard pattern.\n          // Thus, we emit them as optional and let the downstream processor find them while not outputting\n          // an error if it couldn't.\n          true,\n        ),\n      );\n    }\n\n    return true;\n  }\n}\n\n/*\n * Helpers\n */\n\nexport function parseUrl(\n  urlString: string,\n): { org: string; repoSearchPath: RegExp; catalogPath: string } {\n  const url = new URL(urlString);\n  const path = url.pathname.substr(1).split('/');\n\n  // /backstage/techdocs-*/blob/master/catalog-info.yaml\n  if (path.length > 2 && path[0].length && path[1].length) {\n    return {\n      org: decodeURIComponent(path[0]),\n      repoSearchPath: escapeRegExp(decodeURIComponent(path[1])),\n      catalogPath: `/${decodeURIComponent(path.slice(2).join('/'))}`,\n    };\n  }\n\n  throw new Error(`Failed to parse ${urlString}`);\n}\n\nexport function escapeRegExp(str: string): RegExp {\n  return new RegExp(`^${str.replace(/\\*/g, '.*')}$`);\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { GroupEntity, UserEntity } from '@backstage/catalog-model';\n\nexport function buildOrgHierarchy(groups: GroupEntity[]) {\n  const groupsByName = new Map(groups.map(g => [g.metadata.name, g]));\n\n  //\n  // Make sure that g.parent.children contain g\n  //\n\n  for (const group of groups) {\n    const selfName = group.metadata.name;\n    const parentName = group.spec.parent;\n    if (parentName) {\n      const parent = groupsByName.get(parentName);\n      if (parent && !parent.spec.children.includes(selfName)) {\n        parent.spec.children.push(selfName);\n      }\n    }\n  }\n\n  //\n  // Make sure that g.children.parent is g\n  //\n\n  for (const group of groups) {\n    const selfName = group.metadata.name;\n    for (const childName of group.spec.children) {\n      const child = groupsByName.get(childName);\n      if (child && !child.spec.parent) {\n        child.spec.parent = selfName;\n      }\n    }\n  }\n}\n\n// Ensure that users have their transitive group memberships. Requires that\n// the groups were previously processed with buildOrgHierarchy()\nexport function buildMemberOf(groups: GroupEntity[], users: UserEntity[]) {\n  const groupsByName = new Map(groups.map(g => [g.metadata.name, g]));\n\n  users.forEach(user => {\n    const transitiveMemberOf = new Set<string>();\n\n    const todo = [\n      ...user.spec.memberOf,\n      ...groups\n        .filter(g => g.spec.members?.includes(user.metadata.name))\n        .map(g => g.metadata.name),\n    ];\n\n    for (;;) {\n      const current = todo.pop();\n      if (!current) {\n        break;\n      }\n\n      if (!transitiveMemberOf.has(current)) {\n        transitiveMemberOf.add(current);\n        const group = groupsByName.get(current);\n        if (group?.spec.parent) {\n          todo.push(group.spec.parent);\n        }\n      }\n    }\n\n    user.spec.memberOf = [...transitiveMemberOf];\n  });\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { LocationSpec } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport {\n  GithubCredentialsProvider,\n  GithubCredentialType,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport { graphql } from '@octokit/graphql';\nimport { Logger } from 'winston';\nimport { getOrganizationTeams, getOrganizationUsers } from './github';\nimport * as results from './results';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\nimport { buildOrgHierarchy } from './util/org';\n\ntype GraphQL = typeof graphql;\n\n/**\n * Extracts teams and users out of a GitHub org.\n */\nexport class GithubOrgReaderProcessor implements CatalogProcessor {\n  private readonly integrations: ScmIntegrations;\n  private readonly logger: Logger;\n\n  static fromConfig(config: Config, options: { logger: Logger }) {\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    return new GithubOrgReaderProcessor({\n      ...options,\n      integrations,\n    });\n  }\n\n  constructor(options: { integrations: ScmIntegrations; logger: Logger }) {\n    this.integrations = options.integrations;\n    this.logger = options.logger;\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    if (location.type !== 'github-org') {\n      return false;\n    }\n\n    const { client, tokenType } = await this.createClient(location.target);\n    const { org } = parseUrl(location.target);\n\n    // Read out all of the raw data\n    const startTimestamp = Date.now();\n    this.logger.info('Reading GitHub users and groups');\n\n    const { users } = await getOrganizationUsers(client, org, tokenType);\n    const { groups, groupMemberUsers } = await getOrganizationTeams(\n      client,\n      org,\n    );\n\n    const duration = ((Date.now() - startTimestamp) / 1000).toFixed(1);\n    this.logger.debug(\n      `Read ${users.length} GitHub users and ${groups.length} GitHub groups in ${duration} seconds`,\n    );\n\n    // Fill out the hierarchy\n    const usersByName = new Map(users.map(u => [u.metadata.name, u]));\n    for (const [groupName, userNames] of groupMemberUsers.entries()) {\n      for (const userName of userNames) {\n        const user = usersByName.get(userName);\n        if (user && !user.spec.memberOf.includes(groupName)) {\n          user.spec.memberOf.push(groupName);\n        }\n      }\n    }\n    buildOrgHierarchy(groups);\n\n    // Done!\n    for (const group of groups) {\n      emit(results.entity(location, group));\n    }\n    for (const user of users) {\n      emit(results.entity(location, user));\n    }\n\n    return true;\n  }\n\n  private async createClient(\n    orgUrl: string,\n  ): Promise<{ client: GraphQL; tokenType: GithubCredentialType }> {\n    const gitHubConfig = this.integrations.github.byUrl(orgUrl)?.config;\n\n    if (!gitHubConfig) {\n      throw new Error(\n        `There is no GitHub Org provider that matches ${orgUrl}. Please add a configuration for an integration.`,\n      );\n    }\n\n    const credentialsProvider = GithubCredentialsProvider.create(gitHubConfig);\n    const {\n      headers,\n      type: tokenType,\n    } = await credentialsProvider.getCredentials({\n      url: orgUrl,\n    });\n\n    const client = graphql.defaults({\n      baseUrl: gitHubConfig.apiBaseUrl,\n      headers,\n    });\n\n    return { client, tokenType };\n  }\n}\n\n/*\n * Helpers\n */\n\nexport function parseUrl(urlString: string): { org: string } {\n  const path = new URL(urlString).pathname.substr(1).split('/');\n\n  // /backstage\n  if (path.length === 1 && path[0].length) {\n    return { org: decodeURIComponent(path[0]) };\n  }\n\n  throw new Error(`Expected a URL pointing to /<org>`);\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Error as LDAPError } from 'ldapjs';\n\n/**\n * Builds a string form of an LDAP Error structure.\n *\n * @param error The error\n */\nexport function errorString(error: LDAPError) {\n  return `${error.code} ${error.name}: ${error.message}`;\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SearchEntry } from 'ldapjs';\n\n/**\n * An LDAP Vendor handles unique nuances between different vendors.\n */\nexport type LdapVendor = {\n  /**\n   * The attribute name that holds the distinguished name (DN) for an entry.\n   */\n  dnAttributeName: string;\n  /**\n   * The attribute name that holds a universal unique identifier for an entry.\n   */\n  uuidAttributeName: string;\n  /**\n   * Decode ldap entry values for a given attribute name to their string representation.\n   *\n   * @param entry The ldap entry\n   * @param name The attribute to decode\n   */\n  decodeStringAttribute: (entry: SearchEntry, name: string) => string[];\n};\n\nexport const DefaultLdapVendor: LdapVendor = {\n  dnAttributeName: 'entryDN',\n  uuidAttributeName: 'entryUUID',\n  decodeStringAttribute: (entry, name) => {\n    return decode(entry, name, value => {\n      return value.toString();\n    });\n  },\n};\n\nexport const ActiveDirectoryVendor: LdapVendor = {\n  dnAttributeName: 'distinguishedName',\n  uuidAttributeName: 'objectGUID',\n  decodeStringAttribute: (entry, name) => {\n    const decoder = (value: string | Buffer) => {\n      if (name === ActiveDirectoryVendor.uuidAttributeName) {\n        return formatGUID(value);\n      }\n      return value.toString();\n    };\n    return decode(entry, name, decoder);\n  },\n};\n\n// Decode an attribute to a consumer\nfunction decode(\n  entry: SearchEntry,\n  attributeName: string,\n  decoder: (value: string | Buffer) => string,\n): string[] {\n  const values = entry.raw[attributeName];\n  if (Array.isArray(values)) {\n    return values.map(v => {\n      return decoder(v);\n    });\n  } else if (values) {\n    return [decoder(values)];\n  }\n  return [];\n}\n\n// Formats a Microsoft Active Directory binary-encoded uuid to a readable string\n// See https://github.com/ldapjs/node-ldapjs/issues/297#issuecomment-137765214\nfunction formatGUID(objectGUID: string | Buffer): string {\n  let data: Buffer;\n  if (typeof objectGUID === 'string') {\n    data = new Buffer(objectGUID, 'binary');\n  } else {\n    data = objectGUID;\n  }\n  // GUID_FORMAT_D\n  let template = '{3}{2}{1}{0}-{5}{4}-{7}{6}-{8}{9}-{10}{11}{12}{13}{14}{15}';\n\n  // check each byte\n  for (let i = 0; i < data.length; i++) {\n    // @ts-ignore\n    let dataStr = data[i].toString(16);\n    dataStr = data[i] >= 16 ? dataStr : `0${dataStr}`;\n\n    // insert that character into the template\n    template = template.replace(`{${i}}`, dataStr);\n  }\n  return template;\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport ldap, { Client, SearchEntry, SearchOptions } from 'ldapjs';\nimport { Logger } from 'winston';\nimport { BindConfig } from './config';\nimport { errorString } from './util';\nimport {\n  ActiveDirectoryVendor,\n  DefaultLdapVendor,\n  LdapVendor,\n} from './vendors';\n\n/**\n * Basic wrapper for the ldapjs library.\n *\n * Helps out with promisifying calls, paging, binding etc.\n */\nexport class LdapClient {\n  private vendor: Promise<LdapVendor> | undefined;\n\n  static async create(\n    logger: Logger,\n    target: string,\n    bind?: BindConfig,\n  ): Promise<LdapClient> {\n    const client = ldap.createClient({ url: target });\n\n    // We want to have a catch-all error handler at the top, since the default\n    // behavior of the client is to blow up the entire process when it fails,\n    // unless an error handler is set.\n    client.on('error', (err: ldap.Error) => {\n      logger.warn(`LDAP client threw an error, ${errorString(err)}`);\n    });\n\n    if (!bind) {\n      return new LdapClient(client);\n    }\n\n    return new Promise<LdapClient>((resolve, reject) => {\n      const { dn, secret } = bind;\n      client.bind(dn, secret, err => {\n        if (err) {\n          reject(`LDAP bind failed for ${dn}, ${errorString(err)}`);\n        } else {\n          resolve(new LdapClient(client));\n        }\n      });\n    });\n  }\n\n  constructor(private readonly client: Client) {}\n\n  /**\n   * Performs an LDAP search operation.\n   *\n   * @param dn The fully qualified base DN to search within\n   * @param options The search options\n   */\n  async search(dn: string, options: SearchOptions): Promise<SearchEntry[]> {\n    try {\n      return await new Promise<SearchEntry[]>((resolve, reject) => {\n        const output: SearchEntry[] = [];\n\n        this.client.search(dn, options, (err, res) => {\n          if (err) {\n            reject(new Error(errorString(err)));\n            return;\n          }\n\n          res.on('searchReference', () => {\n            reject(new Error('Unable to handle referral'));\n          });\n\n          res.on('searchEntry', entry => {\n            output.push(entry);\n          });\n\n          res.on('error', e => {\n            reject(new Error(errorString(e)));\n          });\n\n          res.on('end', r => {\n            if (!r) {\n              reject(new Error('Null response'));\n            } else if (r.status !== 0) {\n              reject(new Error(`Got status ${r.status}: ${r.errorMessage}`));\n            } else {\n              resolve(output);\n            }\n          });\n        });\n      });\n    } catch (e) {\n      throw new Error(`LDAP search at DN \"${dn}\" failed, ${e.message}`);\n    }\n  }\n\n  /**\n   * Get the Server Vendor.\n   * Currently only detects Microsoft Active Directory Servers.\n   *\n   * @see https://ldapwiki.com/wiki/Determine%20LDAP%20Server%20Vendor\n   */\n  async getVendor(): Promise<LdapVendor> {\n    if (this.vendor) {\n      return this.vendor;\n    }\n    this.vendor = this.getRootDSE()\n      .then(root => {\n        if (root && root.raw?.forestFunctionality) {\n          return ActiveDirectoryVendor;\n        }\n        return DefaultLdapVendor;\n      })\n      .catch(err => {\n        this.vendor = undefined;\n        throw err;\n      });\n    return this.vendor;\n  }\n\n  /**\n   * Get the Root DSE.\n   *\n   * @see https://ldapwiki.com/wiki/RootDSE\n   */\n  async getRootDSE(): Promise<SearchEntry | undefined> {\n    const result = await this.search('', {\n      scope: 'base',\n      filter: '(objectclass=*)',\n    } as SearchOptions);\n    if (result && result.length === 1) {\n      return result[0];\n    }\n    return undefined;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config, JsonValue } from '@backstage/config';\nimport { SearchOptions } from 'ldapjs';\nimport mergeWith from 'lodash/mergeWith';\nimport { RecursivePartial } from '../../../util';\n\n/**\n * The configuration parameters for a single LDAP provider.\n */\nexport type LdapProviderConfig = {\n  // The prefix of the target that this matches on, e.g.\n  // \"ldaps://ds.example.net\", with no trailing slash.\n  target: string;\n  // The settings to use for the bind command. If none are specified, the bind\n  // command is not issued.\n  bind?: BindConfig;\n  // The settings that govern the reading and interpretation of users\n  users: UserConfig;\n  // The settings that govern the reading and interpretation of groups\n  groups: GroupConfig;\n};\n\n/**\n * The settings to use for the a command.\n */\nexport type BindConfig = {\n  // The DN of the user to auth as, e.g.\n  // uid=ldap-robot,ou=robots,ou=example,dc=example,dc=net\n  dn: string;\n  // The secret of the user to auth as (its password)\n  secret: string;\n};\n\n/**\n * The settings that govern the reading and interpretation of users.\n */\nexport type UserConfig = {\n  // The DN under which users are stored.\n  dn: string;\n  // The search options to use.\n  // Only the scope, filter, attributes, and paged fields are supported. The\n  // default is scope \"one\" and attributes \"*\" and \"+\".\n  options: SearchOptions;\n  // JSON paths (on a.b.c form) and hard coded values to set on those paths\n  set?: { [path: string]: JsonValue };\n  // Mappings from well known entity fields, to LDAP attribute names\n  map: {\n    // The name of the attribute that holds the relative distinguished name of\n    // each entry. Defaults to \"uid\".\n    rdn: string;\n    // The name of the attribute that shall be used for the value of the\n    // metadata.name field of the entity. Defaults to \"uid\".\n    name: string;\n    // The name of the attribute that shall be used for the value of the\n    // metadata.description field of the entity.\n    description?: string;\n    // The name of the attribute that shall be used for the value of the\n    // spec.profile.displayName field of the entity. Defaults to \"cn\".\n    displayName: string;\n    // The name of the attribute that shall be used for the value of the\n    // spec.profile.email field of the entity. Defaults to \"mail\".\n    email: string;\n    // The name of the attribute that shall be used for the value of the\n    // spec.profile.picture field of the entity.\n    picture?: string;\n    // The name of the attribute that shall be used for the values of the\n    // spec.memberOf field of the entity. Defaults to \"memberOf\".\n    memberOf: string;\n  };\n};\n\n/**\n * The settings that govern the reading and interpretation of groups.\n */\nexport type GroupConfig = {\n  // The DN under which groups are stored.\n  dn: string;\n  // The search options to use.\n  // Only the scope, filter, attributes, and paged fields are supported.\n  options: SearchOptions;\n  // JSON paths (on a.b.c form) and hard coded values to set on those paths\n  set?: { [path: string]: JsonValue };\n  // Mappings from well known entity fields, to LDAP attribute names\n  map: {\n    // The name of the attribute that holds the relative distinguished name of\n    // each entry. Defaults to \"cn\".\n    rdn: string;\n    // The name of the attribute that shall be used for the value of the\n    // metadata.name field of the entity. Defaults to \"cn\".\n    name: string;\n    // The name of the attribute that shall be used for the value of the\n    // metadata.description field of the entity. Defaults to \"description\".\n    description: string;\n    // The name of the attribute that shall be used for the value of the\n    // spec.type field of the entity. Defaults to \"groupType\".\n    type: string;\n    // The name of the attribute that shall be used for the value of the\n    // spec.profile.displayName field of the entity. Defaults to \"cn\".\n    displayName: string;\n    // The name of the attribute that shall be used for the value of the\n    // spec.profile.email field of the entity.\n    email?: string;\n    // The name of the attribute that shall be used for the value of the\n    // spec.profile.picture field of the entity.\n    picture?: string;\n    // The name of the attribute that shall be used for the values of the\n    // spec.parent field of the entity. Defaults to \"memberOf\".\n    memberOf: string;\n    // The name of the attribute that shall be used for the values of the\n    // spec.children field of the entity. Defaults to \"member\".\n    members: string;\n  };\n};\n\nconst defaultConfig = {\n  users: {\n    options: {\n      scope: 'one',\n      attributes: ['*', '+'],\n    },\n    map: {\n      rdn: 'uid',\n      name: 'uid',\n      displayName: 'cn',\n      email: 'mail',\n      memberOf: 'memberOf',\n    },\n  },\n  groups: {\n    options: {\n      scope: 'one',\n      attributes: ['*', '+'],\n    },\n    map: {\n      rdn: 'cn',\n      name: 'cn',\n      description: 'description',\n      displayName: 'cn',\n      type: 'groupType',\n      memberOf: 'memberOf',\n      members: 'member',\n    },\n  },\n};\n\n/**\n * Parses configuration.\n *\n * @param config The root of the LDAP config hierarchy\n */\nexport function readLdapConfig(config: Config): LdapProviderConfig[] {\n  function readBindConfig(\n    c: Config | undefined,\n  ): LdapProviderConfig['bind'] | undefined {\n    if (!c) {\n      return undefined;\n    }\n    return {\n      dn: c.getString('dn'),\n      secret: c.getString('secret'),\n    };\n  }\n\n  function readOptionsConfig(c: Config | undefined): SearchOptions {\n    if (!c) {\n      return {};\n    }\n\n    const paged = readOptionsPagedConfig(c);\n\n    return {\n      scope: c.getOptionalString('scope') as SearchOptions['scope'],\n      filter: formatFilter(c.getOptionalString('filter')),\n      attributes: c.getOptionalStringArray('attributes'),\n      ...(paged !== undefined ? { paged } : undefined),\n    };\n  }\n\n  function readOptionsPagedConfig(c: Config): SearchOptions['paged'] {\n    const pagedConfig = c.getOptional('paged');\n    if (pagedConfig === undefined) {\n      return undefined;\n    }\n\n    if (pagedConfig === true || pagedConfig === false) {\n      return pagedConfig;\n    }\n\n    const pageSize = c.getOptionalNumber('paged.pageSize');\n    const pagePause = c.getOptionalBoolean('paged.pagePause');\n    return {\n      ...(pageSize !== undefined ? { pageSize } : undefined),\n      ...(pagePause !== undefined ? { pagePause } : undefined),\n    };\n  }\n\n  function readSetConfig(\n    c: Config | undefined,\n  ): { [path: string]: JsonValue } | undefined {\n    if (!c) {\n      return undefined;\n    }\n    return Object.fromEntries(c.keys().map(path => [path, c.get(path)]));\n  }\n\n  function readUserMapConfig(\n    c: Config | undefined,\n  ): Partial<LdapProviderConfig['users']['map']> {\n    if (!c) {\n      return {};\n    }\n\n    return {\n      rdn: c.getOptionalString('rdn'),\n      name: c.getOptionalString('name'),\n      description: c.getOptionalString('description'),\n      displayName: c.getOptionalString('displayName'),\n      email: c.getOptionalString('email'),\n      picture: c.getOptionalString('picture'),\n      memberOf: c.getOptionalString('memberOf'),\n    };\n  }\n\n  function readGroupMapConfig(\n    c: Config | undefined,\n  ): Partial<LdapProviderConfig['groups']['map']> {\n    if (!c) {\n      return {};\n    }\n\n    return {\n      rdn: c.getOptionalString('rdn'),\n      name: c.getOptionalString('name'),\n      description: c.getOptionalString('description'),\n      type: c.getOptionalString('type'),\n      displayName: c.getOptionalString('displayName'),\n      email: c.getOptionalString('email'),\n      picture: c.getOptionalString('picture'),\n      memberOf: c.getOptionalString('memberOf'),\n      members: c.getOptionalString('members'),\n    };\n  }\n\n  function readUserConfig(\n    c: Config,\n  ): RecursivePartial<LdapProviderConfig['users']> {\n    return {\n      dn: c.getString('dn'),\n      options: readOptionsConfig(c.getOptionalConfig('options')),\n      set: readSetConfig(c.getOptionalConfig('set')),\n      map: readUserMapConfig(c.getOptionalConfig('map')),\n    };\n  }\n\n  function readGroupConfig(\n    c: Config,\n  ): RecursivePartial<LdapProviderConfig['groups']> {\n    return {\n      dn: c.getString('dn'),\n      options: readOptionsConfig(c.getOptionalConfig('options')),\n      set: readSetConfig(c.getOptionalConfig('set')),\n      map: readGroupMapConfig(c.getOptionalConfig('map')),\n    };\n  }\n\n  function formatFilter(filter?: string): string | undefined {\n    // Remove extra whitespace between blocks to support multiline filters from the configuration\n    return filter?.replace(/\\s*(\\(|\\))/g, '$1')?.trim();\n  }\n\n  const providerConfigs = config.getOptionalConfigArray('providers') ?? [];\n  return providerConfigs.map(c => {\n    const newConfig = {\n      target: c.getString('target').replace(/\\/+$/, ''),\n      bind: readBindConfig(c.getOptionalConfig('bind')),\n      users: readUserConfig(c.getConfig('users')),\n      groups: readGroupConfig(c.getConfig('groups')),\n    };\n    const merged = mergeWith({}, defaultConfig, newConfig, (_into, from) => {\n      // Replace arrays instead of merging, otherwise default behavior\n      return Array.isArray(from) ? from : undefined;\n    });\n    return merged as LdapProviderConfig;\n  });\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * The name of an entity annotation, that references the RDN of the LDAP object\n * it was ingested from.\n *\n * The RDN is the name of the leftmost attribute that identifies the item; for\n * example, for an item with the fully qualified DN\n * uid=john,ou=people,ou=spotify,dc=spotify,dc=net the generated entity would\n * have this annotation, with the value \"john\".\n */\nexport const LDAP_RDN_ANNOTATION = 'backstage.io/ldap-rdn';\n\n/**\n * The name of an entity annotation, that references the DN of the LDAP object\n * it was ingested from.\n *\n * The DN is the fully qualified name that identifies the item; for example,\n * for an item with the DN uid=john,ou=people,ou=spotify,dc=spotify,dc=net the\n * generated entity would have this annotation, with that full string as its\n * value.\n */\nexport const LDAP_DN_ANNOTATION = 'backstage.io/ldap-dn';\n\n/**\n * The name of an entity annotation, that references the UUID of the LDAP\n * object it was ingested from.\n *\n * The UUID is the globally unique ID that identifies the item; for example,\n * for an item with the UUID 76ef928a-b251-1037-9840-d78227f36a7e, the\n * generated entity would have this annotation, with that full string as its\n * value.\n */\nexport const LDAP_UUID_ANNOTATION = 'backstage.io/ldap-uuid';\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { GroupEntity, UserEntity } from '@backstage/catalog-model';\nimport { SearchEntry } from 'ldapjs';\nimport lodashSet from 'lodash/set';\nimport { buildOrgHierarchy } from '../util/org';\nimport { LdapClient } from './client';\nimport { GroupConfig, UserConfig } from './config';\nimport {\n  LDAP_DN_ANNOTATION,\n  LDAP_RDN_ANNOTATION,\n  LDAP_UUID_ANNOTATION,\n} from './constants';\nimport { LdapVendor } from './vendors';\n\n/**\n * Reads users out of an LDAP provider.\n *\n * @param client The LDAP client\n * @param config The user data configuration\n */\nexport async function readLdapUsers(\n  client: LdapClient,\n  config: UserConfig,\n): Promise<{\n  users: UserEntity[]; // With all relations empty\n  userMemberOf: Map<string, Set<string>>; // DN -> DN or UUID of groups\n}> {\n  const { dn, options, set, map } = config;\n  const vendor = await client.getVendor();\n\n  const entries = await client.search(dn, options);\n\n  const entities: UserEntity[] = [];\n  const userMemberOf: Map<string, Set<string>> = new Map();\n\n  for (const entry of entries) {\n    const entity: UserEntity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'User',\n      metadata: {\n        name: '',\n        annotations: {},\n      },\n      spec: {\n        profile: {},\n        memberOf: [],\n      },\n    };\n\n    if (set) {\n      for (const [path, value] of Object.entries(set)) {\n        lodashSet(entity, path, value);\n      }\n    }\n\n    mapStringAttr(entry, vendor, map.name, v => {\n      entity.metadata.name = v;\n    });\n    mapStringAttr(entry, vendor, map.description, v => {\n      entity.metadata.description = v;\n    });\n    mapStringAttr(entry, vendor, map.rdn, v => {\n      entity.metadata.annotations![LDAP_RDN_ANNOTATION] = v;\n    });\n    mapStringAttr(entry, vendor, vendor.uuidAttributeName, v => {\n      entity.metadata.annotations![LDAP_UUID_ANNOTATION] = v;\n    });\n    mapStringAttr(entry, vendor, vendor.dnAttributeName, v => {\n      entity.metadata.annotations![LDAP_DN_ANNOTATION] = v;\n    });\n    mapStringAttr(entry, vendor, map.displayName, v => {\n      entity.spec.profile!.displayName = v;\n    });\n    mapStringAttr(entry, vendor, map.email, v => {\n      entity.spec.profile!.email = v;\n    });\n    mapStringAttr(entry, vendor, map.picture, v => {\n      entity.spec.profile!.picture = v;\n    });\n\n    mapReferencesAttr(entry, vendor, map.memberOf, (myDn, vs) => {\n      ensureItems(userMemberOf, myDn, vs);\n    });\n\n    entities.push(entity);\n  }\n\n  return { users: entities, userMemberOf };\n}\n\n/**\n * Reads groups out of an LDAP provider.\n *\n * @param client The LDAP client\n * @param config The group data configuration\n */\nexport async function readLdapGroups(\n  client: LdapClient,\n  config: GroupConfig,\n): Promise<{\n  groups: GroupEntity[]; // With all relations empty\n  groupMemberOf: Map<string, Set<string>>; // DN -> DN or UUID of groups\n  groupMember: Map<string, Set<string>>; // DN -> DN or UUID of groups & users\n}> {\n  const { dn, options, set, map } = config;\n  const vendor = await client.getVendor();\n\n  const entries = await client.search(dn, options);\n\n  const groups: GroupEntity[] = [];\n  const groupMemberOf: Map<string, Set<string>> = new Map();\n  const groupMember: Map<string, Set<string>> = new Map();\n\n  for (const entry of entries) {\n    const entity: GroupEntity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'Group',\n      metadata: {\n        name: '',\n        annotations: {},\n      },\n      spec: {\n        type: 'unknown',\n        profile: {},\n        children: [],\n      },\n    };\n\n    if (set) {\n      for (const [path, value] of Object.entries(set)) {\n        lodashSet(entity, path, value);\n      }\n    }\n\n    mapStringAttr(entry, vendor, map.name, v => {\n      entity.metadata.name = v;\n    });\n    mapStringAttr(entry, vendor, map.description, v => {\n      entity.metadata.description = v;\n    });\n    mapStringAttr(entry, vendor, map.rdn, v => {\n      entity.metadata.annotations![LDAP_RDN_ANNOTATION] = v;\n    });\n    mapStringAttr(entry, vendor, vendor.uuidAttributeName, v => {\n      entity.metadata.annotations![LDAP_UUID_ANNOTATION] = v;\n    });\n    mapStringAttr(entry, vendor, vendor.dnAttributeName, v => {\n      entity.metadata.annotations![LDAP_DN_ANNOTATION] = v;\n    });\n    mapStringAttr(entry, vendor, map.type, v => {\n      entity.spec.type = v;\n    });\n    mapStringAttr(entry, vendor, map.displayName, v => {\n      entity.spec.profile!.displayName = v;\n    });\n    mapStringAttr(entry, vendor, map.email, v => {\n      entity.spec.profile!.email = v;\n    });\n    mapStringAttr(entry, vendor, map.picture, v => {\n      entity.spec.profile!.picture = v;\n    });\n\n    mapReferencesAttr(entry, vendor, map.memberOf, (myDn, vs) => {\n      ensureItems(groupMemberOf, myDn, vs);\n    });\n    mapReferencesAttr(entry, vendor, map.members, (myDn, vs) => {\n      ensureItems(groupMember, myDn, vs);\n    });\n\n    groups.push(entity);\n  }\n\n  return {\n    groups,\n    groupMemberOf,\n    groupMember,\n  };\n}\n\n/**\n * Reads users and groups out of an LDAP provider.\n *\n * Invokes the above \"raw\" read functions and stitches together the results\n * with all relations etc filled in.\n *\n * @param client The LDAP client\n * @param logger A logger instance\n * @param userConfig The user data configuration\n * @param groupConfig The group data configuration\n */\nexport async function readLdapOrg(\n  client: LdapClient,\n  userConfig: UserConfig,\n  groupConfig: GroupConfig,\n): Promise<{\n  users: UserEntity[];\n  groups: GroupEntity[];\n}> {\n  const { users, userMemberOf } = await readLdapUsers(client, userConfig);\n  const { groups, groupMemberOf, groupMember } = await readLdapGroups(\n    client,\n    groupConfig,\n  );\n\n  resolveRelations(groups, users, userMemberOf, groupMemberOf, groupMember);\n  users.sort((a, b) => a.metadata.name.localeCompare(b.metadata.name));\n  groups.sort((a, b) => a.metadata.name.localeCompare(b.metadata.name));\n\n  return { users, groups };\n}\n\n//\n// Helpers\n//\n\n// Maps a single-valued attribute to a consumer\nfunction mapStringAttr(\n  entry: SearchEntry,\n  vendor: LdapVendor,\n  attributeName: string | undefined,\n  setter: (value: string) => void,\n) {\n  if (attributeName) {\n    const values = vendor.decodeStringAttribute(entry, attributeName);\n    if (values && values.length === 1) {\n      setter(values[0]);\n    }\n  }\n}\n\n// Maps a multi-valued attribute of references to other objects, to a consumer\nfunction mapReferencesAttr(\n  entry: SearchEntry,\n  vendor: LdapVendor,\n  attributeName: string | undefined,\n  setter: (sourceDn: string, targets: string[]) => void,\n) {\n  if (attributeName) {\n    const values = vendor.decodeStringAttribute(entry, attributeName);\n    const dn = vendor.decodeStringAttribute(entry, vendor.dnAttributeName);\n    if (values && dn && dn.length === 1) {\n      setter(dn[0], values);\n    }\n  }\n}\n\n// Inserts a number of values in a key-values mapping\nfunction ensureItems(\n  target: Map<string, Set<string>>,\n  key: string,\n  values: string[],\n) {\n  if (key) {\n    let set = target.get(key);\n    if (!set) {\n      set = new Set();\n      target.set(key, set);\n    }\n    for (const value of values) {\n      if (value) {\n        set!.add(value);\n      }\n    }\n  }\n}\n\n/**\n * Takes groups and entities with empty relations, and fills in the various\n * relations that were returned by the readers, and forms the org hierarchy.\n *\n * @param groups Group entities with empty relations; modified in place\n * @param users User entities with empty relations; modified in place\n * @param userMemberOf For a user DN, the set of group DNs or UUIDs that the\n *                     user is a member of\n * @param groupMemberOf For a group DN, the set of group DNs or UUIDs that the\n *                      group is a member of (parents in the hierarchy)\n * @param groupMember For a group DN, the set of group DNs or UUIDs that are\n *                    members of the group (children in the hierarchy)\n */\nexport function resolveRelations(\n  groups: GroupEntity[],\n  users: UserEntity[],\n  userMemberOf: Map<string, Set<string>>,\n  groupMemberOf: Map<string, Set<string>>,\n  groupMember: Map<string, Set<string>>,\n) {\n  // Build reference lookup tables - all of the relations that are output from\n  // the above calls can be expressed as either DNs or UUIDs so we need to be\n  // able to find by both, as well as the name. Note that we expect them to not\n  // collide here - this is a reasonable assumption as long as the fields are\n  // the supported forms.\n  const userMap: Map<string, UserEntity> = new Map(); // by name, dn, uuid\n  const groupMap: Map<string, GroupEntity> = new Map(); // by name, dn, uuid\n  for (const user of users) {\n    userMap.set(user.metadata.name, user);\n    userMap.set(user.metadata.annotations![LDAP_DN_ANNOTATION], user);\n    userMap.set(user.metadata.annotations![LDAP_UUID_ANNOTATION], user);\n  }\n  for (const group of groups) {\n    groupMap.set(group.metadata.name, group);\n    groupMap.set(group.metadata.annotations![LDAP_DN_ANNOTATION], group);\n    groupMap.set(group.metadata.annotations![LDAP_UUID_ANNOTATION], group);\n  }\n\n  // This can happen e.g. if entryUUID wasn't returned by the server\n  userMap.delete('');\n  groupMap.delete('');\n  userMap.delete(undefined!);\n  groupMap.delete(undefined!);\n\n  // Fill in all of the immediate relations, now keyed on metadata.name. We\n  // keep all parents at this point, whether the target model can support more\n  // than one or not (it gets filtered farther down). And group children are\n  // only groups in here.\n  const newUserMemberOf: Map<string, Set<string>> = new Map();\n  const newGroupParents: Map<string, Set<string>> = new Map();\n  const newGroupChildren: Map<string, Set<string>> = new Map();\n\n  // Resolve and store in the intermediaries. It may seem redundant that the\n  // input data has both parent and children directions, as well as both\n  // user->group and group->user - the reason is that different LDAP schemas\n  // express relations in different directions. Some may have a user memberOf\n  // overlay, some don't, for example.\n  for (const [userN, groupsN] of userMemberOf.entries()) {\n    const user = userMap.get(userN);\n    if (user) {\n      for (const groupN of groupsN) {\n        const group = groupMap.get(groupN);\n        if (group) {\n          ensureItems(newUserMemberOf, user.metadata.name, [\n            group.metadata.name,\n          ]);\n        }\n      }\n    }\n  }\n  for (const [groupN, parentsN] of groupMemberOf.entries()) {\n    const group = groupMap.get(groupN);\n    if (group) {\n      for (const parentN of parentsN) {\n        const parentGroup = groupMap.get(parentN);\n        if (parentGroup) {\n          ensureItems(newGroupParents, group.metadata.name, [\n            parentGroup.metadata.name,\n          ]);\n          ensureItems(newGroupChildren, parentGroup.metadata.name, [\n            group.metadata.name,\n          ]);\n        }\n      }\n    }\n  }\n  for (const [groupN, membersN] of groupMember.entries()) {\n    const group = groupMap.get(groupN);\n    if (group) {\n      for (const memberN of membersN) {\n        // Group members can be both users and groups in the input model, so\n        // try both\n        const memberUser = userMap.get(memberN);\n        if (memberUser) {\n          ensureItems(newUserMemberOf, memberUser.metadata.name, [\n            group.metadata.name,\n          ]);\n        } else {\n          const memberGroup = groupMap.get(memberN);\n          if (memberGroup) {\n            ensureItems(newGroupChildren, group.metadata.name, [\n              memberGroup.metadata.name,\n            ]);\n            ensureItems(newGroupParents, memberGroup.metadata.name, [\n              group.metadata.name,\n            ]);\n          }\n        }\n      }\n    }\n  }\n\n  // Write down the relations again into the actual entities\n  for (const [userN, groupsN] of newUserMemberOf.entries()) {\n    const user = userMap.get(userN);\n    if (user) {\n      user.spec.memberOf = Array.from(groupsN).sort();\n    }\n  }\n  for (const [groupN, parentsN] of newGroupParents.entries()) {\n    if (parentsN.size === 1) {\n      const group = groupMap.get(groupN);\n      if (group) {\n        group.spec.parent = parentsN.values().next().value;\n      }\n    }\n  }\n  for (const [groupN, childrenN] of newGroupChildren.entries()) {\n    const group = groupMap.get(groupN);\n    if (group) {\n      group.spec.children = Array.from(childrenN).sort();\n    }\n  }\n\n  // Fill out the rest of the hierarchy\n  buildOrgHierarchy(groups);\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { LocationSpec } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { Logger } from 'winston';\nimport {\n  LdapClient,\n  LdapProviderConfig,\n  readLdapConfig,\n  readLdapOrg,\n} from './ldap';\nimport * as results from './results';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\n\n/**\n * Extracts teams and users out of an LDAP server.\n */\nexport class LdapOrgReaderProcessor implements CatalogProcessor {\n  private readonly providers: LdapProviderConfig[];\n  private readonly logger: Logger;\n\n  static fromConfig(config: Config, options: { logger: Logger }) {\n    const c = config.getOptionalConfig('catalog.processors.ldapOrg');\n    return new LdapOrgReaderProcessor({\n      ...options,\n      providers: c ? readLdapConfig(c) : [],\n    });\n  }\n\n  constructor(options: { providers: LdapProviderConfig[]; logger: Logger }) {\n    this.providers = options.providers;\n    this.logger = options.logger;\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    if (location.type !== 'ldap-org') {\n      return false;\n    }\n\n    const provider = this.providers.find(p => location.target === p.target);\n    if (!provider) {\n      throw new Error(\n        `There is no LDAP Org provider that matches ${location.target}. Please add a configuration entry for it under catalog.processors.ldapOrg.providers.`,\n      );\n    }\n\n    // Read out all of the raw data\n    const startTimestamp = Date.now();\n    this.logger.info('Reading LDAP users and groups');\n\n    // Be lazy and create the client each time; even though it's pretty\n    // inefficient, we usually only do this once per entire refresh loop and\n    // don't have to worry about timeouts and reconnects etc.\n    const client = await LdapClient.create(\n      this.logger,\n      provider.target,\n      provider.bind,\n    );\n    const { users, groups } = await readLdapOrg(\n      client,\n      provider.users,\n      provider.groups,\n    );\n\n    const duration = ((Date.now() - startTimestamp) / 1000).toFixed(1);\n    this.logger.debug(\n      `Read ${users.length} LDAP users and ${groups.length} LDAP groups in ${duration} seconds`,\n    );\n\n    // Done!\n    for (const group of groups) {\n      emit(results.entity(location, group));\n    }\n    for (const user of users) {\n      emit(results.entity(location, user));\n    }\n\n    return true;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity, LocationEntity, LocationSpec } from '@backstage/catalog-model';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport path from 'path';\nimport * as result from './results';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\n\nexport function toAbsoluteUrl(\n  integrations: ScmIntegrationRegistry,\n  base: LocationSpec,\n  target: string,\n): string {\n  try {\n    if (base.type === 'file') {\n      if (target.startsWith('.')) {\n        return path.join(path.dirname(base.target), target);\n      }\n      return target;\n    }\n    return integrations.resolveUrl({ url: target, base: base.target });\n  } catch (e) {\n    return target;\n  }\n}\n\ntype Options = {\n  integrations: ScmIntegrationRegistry;\n};\n\nexport class LocationEntityProcessor implements CatalogProcessor {\n  constructor(private readonly options: Options) {}\n\n  async postProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n    emit: CatalogProcessorEmit,\n  ): Promise<Entity> {\n    if (entity.kind === 'Location') {\n      const locationEntity = entity as LocationEntity;\n\n      const type = locationEntity.spec.type || location.type;\n      if (type === 'file' && location.target.endsWith(path.sep)) {\n        emit(\n          result.inputError(\n            location,\n            `LocationEntityProcessor cannot handle ${type} type location with target ${location.target} that ends with a path separator`,\n          ),\n        );\n      }\n\n      const targets = new Array<string>();\n      if (locationEntity.spec.target) {\n        targets.push(locationEntity.spec.target);\n      }\n      if (locationEntity.spec.targets) {\n        targets.push(...locationEntity.spec.targets);\n      }\n\n      for (const maybeRelativeTarget of targets) {\n        const target = toAbsoluteUrl(\n          this.options.integrations,\n          location,\n          maybeRelativeTarget,\n        );\n        emit(result.location({ type, target }, false));\n      }\n    }\n\n    return entity;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as msal from '@azure/msal-node';\nimport * as MicrosoftGraph from '@microsoft/microsoft-graph-types';\nimport fetch from 'cross-fetch';\nimport qs from 'qs';\nimport { MicrosoftGraphProviderConfig } from './config';\n\nexport type ODataQuery = {\n  filter?: string;\n  expand?: string[];\n  select?: string[];\n};\n\nexport type GroupMember =\n  | (MicrosoftGraph.Group & { '@odata.type': '#microsoft.graph.user' })\n  | (MicrosoftGraph.User & { '@odata.type': '#microsoft.graph.group' });\n\nexport class MicrosoftGraphClient {\n  static create(config: MicrosoftGraphProviderConfig): MicrosoftGraphClient {\n    const clientConfig: msal.Configuration = {\n      auth: {\n        clientId: config.clientId,\n        clientSecret: config.clientSecret,\n        authority: `${config.authority}/${config.tenantId}`,\n      },\n    };\n    const pca = new msal.ConfidentialClientApplication(clientConfig);\n    return new MicrosoftGraphClient(config.target, pca);\n  }\n\n  constructor(\n    private readonly baseUrl: string,\n    private readonly pca: msal.ConfidentialClientApplication,\n  ) {}\n\n  async *requestCollection<T>(\n    path: string,\n    query?: ODataQuery,\n  ): AsyncIterable<T> {\n    let response = await this.requestApi(path, query);\n\n    for (;;) {\n      if (response.status !== 200) {\n        await this.handleError(path, response);\n      }\n\n      const result = await response.json();\n      const elements: T[] = result.value;\n\n      yield* elements;\n\n      // Follow cursor to the next page if one is available\n      if (!result['@odata.nextLink']) {\n        return;\n      }\n\n      response = await this.requestRaw(result['@odata.nextLink']);\n    }\n  }\n\n  async requestApi(path: string, query?: ODataQuery): Promise<Response> {\n    const queryString = qs.stringify(\n      {\n        $filter: query?.filter,\n        $select: query?.select?.join(','),\n        $expand: query?.expand?.join(','),\n      },\n      {\n        addQueryPrefix: true,\n        // Microsoft Graph doesn't like an encoded query string\n        encode: false,\n      },\n    );\n\n    return await this.requestRaw(`${this.baseUrl}/${path}${queryString}`);\n  }\n\n  async requestRaw(url: string): Promise<Response> {\n    // Make sure that we always have a valid access token (might be cached)\n    const token = await this.pca.acquireTokenByClientCredential({\n      scopes: ['https://graph.microsoft.com/.default'],\n    });\n\n    if (!token) {\n      throw new Error('Error while requesting token for Microsoft Graph');\n    }\n\n    return await fetch(url, {\n      headers: {\n        Authorization: `Bearer ${token.accessToken}`,\n      },\n    });\n  }\n\n  async getUserProfile(userId: string): Promise<MicrosoftGraph.User> {\n    const response = await this.requestApi(`users/${userId}`);\n\n    if (response.status !== 200) {\n      await this.handleError('user profile', response);\n    }\n\n    return await response.json();\n  }\n\n  async getUserPhotoWithSizeLimit(\n    userId: string,\n    maxSize: number,\n  ): Promise<string | undefined> {\n    return await this.getPhotoWithSizeLimit('users', userId, maxSize);\n  }\n\n  async getUserPhoto(\n    userId: string,\n    sizeId?: string,\n  ): Promise<string | undefined> {\n    return await this.getPhoto('users', userId, sizeId);\n  }\n\n  async *getUsers(query?: ODataQuery): AsyncIterable<MicrosoftGraph.User> {\n    yield* this.requestCollection<MicrosoftGraph.User>(`users`, query);\n  }\n\n  async getGroupPhotoWithSizeLimit(\n    groupId: string,\n    maxSize: number,\n  ): Promise<string | undefined> {\n    return await this.getPhotoWithSizeLimit('groups', groupId, maxSize);\n  }\n\n  async getGroupPhoto(\n    groupId: string,\n    sizeId?: string,\n  ): Promise<string | undefined> {\n    return await this.getPhoto('groups', groupId, sizeId);\n  }\n\n  async *getGroups(query?: ODataQuery): AsyncIterable<MicrosoftGraph.Group> {\n    yield* this.requestCollection<MicrosoftGraph.Group>(`groups`, query);\n  }\n\n  async *getGroupMembers(groupId: string): AsyncIterable<GroupMember> {\n    yield* this.requestCollection<GroupMember>(`groups/${groupId}/members`);\n  }\n\n  async getOrganization(\n    tenantId: string,\n  ): Promise<MicrosoftGraph.Organization> {\n    const response = await this.requestApi(`organization/${tenantId}`);\n\n    if (response.status !== 200) {\n      await this.handleError(`organization/${tenantId}`, response);\n    }\n\n    return await response.json();\n  }\n\n  private async getPhotoWithSizeLimit(\n    entityName: string,\n    id: string,\n    maxSize: number,\n  ): Promise<string | undefined> {\n    const response = await this.requestApi(`${entityName}/${id}/photos`);\n\n    if (response.status === 404) {\n      return undefined;\n    } else if (response.status !== 200) {\n      await this.handleError(`${entityName} photos`, response);\n    }\n\n    const result = await response.json();\n    const photos = result.value as MicrosoftGraph.ProfilePhoto[];\n    let selectedPhoto: MicrosoftGraph.ProfilePhoto | undefined = undefined;\n\n    // Find the biggest picture that is smaller than the max size\n    for (const p of photos) {\n      if (\n        !selectedPhoto ||\n        (p.height! >= selectedPhoto.height! && p.height! <= maxSize)\n      ) {\n        selectedPhoto = p;\n      }\n    }\n\n    if (!selectedPhoto) {\n      return undefined;\n    }\n\n    return await this.getPhoto(entityName, id, selectedPhoto.id!);\n  }\n\n  private async getPhoto(\n    entityName: string,\n    id: string,\n    sizeId?: string,\n  ): Promise<string | undefined> {\n    const path = sizeId\n      ? `${entityName}/${id}/photos/${sizeId}/$value`\n      : `${entityName}/${id}/photo/$value`;\n    const response = await this.requestApi(path);\n\n    if (response.status === 404) {\n      return undefined;\n    } else if (response.status !== 200) {\n      await this.handleError('photo', response);\n    }\n\n    return `data:image/jpeg;base64,${Buffer.from(\n      await response.arrayBuffer(),\n    ).toString('base64')}`;\n  }\n\n  private async handleError(path: string, response: Response): Promise<void> {\n    const result = await response.json();\n    const error = result.error as MicrosoftGraph.PublicError;\n\n    throw new Error(\n      `Error while reading ${path} from Microsoft Graph: ${error.code} - ${error.message}`,\n    );\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\n\n/**\n * The configuration parameters for a single Microsoft Graph provider.\n */\nexport type MicrosoftGraphProviderConfig = {\n  /**\n   * The prefix of the target that this matches on, e.g.\n   * \"https://graph.microsoft.com/v1.0\", with no trailing slash.\n   */\n  target: string;\n  /**\n   * The auth authority used.\n   *\n   * E.g. \"https://login.microsoftonline.com\"\n   */\n  authority?: string;\n  /**\n   * The tenant whose org data we are interested in.\n   */\n  tenantId: string;\n  /**\n   * The OAuth client ID to use for authenticating requests.\n   */\n  clientId: string;\n  /**\n   * The OAuth client secret to use for authenticating requests.\n   *\n   * @visibility secret\n   */\n  clientSecret: string;\n  /**\n   * The filter to apply to extract users.\n   *\n   * E.g. \"accountEnabled eq true and userType eq 'member'\"\n   */\n  userFilter?: string;\n  /**\n   * The filter to apply to extract groups.\n   *\n   * E.g. \"securityEnabled eq false and mailEnabled eq true\"\n   */\n  groupFilter?: string;\n};\n\nexport function readMicrosoftGraphConfig(\n  config: Config,\n): MicrosoftGraphProviderConfig[] {\n  const providers: MicrosoftGraphProviderConfig[] = [];\n  const providerConfigs = config.getOptionalConfigArray('providers') ?? [];\n\n  for (const providerConfig of providerConfigs) {\n    const target = providerConfig.getString('target').replace(/\\/+$/, '');\n    const authority =\n      providerConfig.getOptionalString('authority')?.replace(/\\/+$/, '') ||\n      'https://login.microsoftonline.com';\n    const tenantId = providerConfig.getString('tenantId');\n    const clientId = providerConfig.getString('clientId');\n    const clientSecret = providerConfig.getString('clientSecret');\n    const userFilter = providerConfig.getOptionalString('userFilter');\n    const groupFilter = providerConfig.getOptionalString('groupFilter');\n\n    providers.push({\n      target,\n      authority,\n      tenantId,\n      clientId,\n      clientSecret,\n      userFilter,\n      groupFilter,\n    });\n  }\n\n  return providers;\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * The tenant id used by the Microsoft Graph API\n */\nexport const MICROSOFT_GRAPH_TENANT_ID_ANNOTATION =\n  'graph.microsoft.com/tenant-id';\n\n/**\n * The group id used by the Microsoft Graph API\n */\nexport const MICROSOFT_GRAPH_GROUP_ID_ANNOTATION =\n  'graph.microsoft.com/group-id';\n\n/**\n * The user id used by the Microsoft Graph API\n */\nexport const MICROSOFT_GRAPH_USER_ID_ANNOTATION = 'graph.microsoft.com/user-id';\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { GroupEntity, UserEntity } from '@backstage/catalog-model';\nimport limiterFactory from 'p-limit';\nimport { buildMemberOf, buildOrgHierarchy } from '../util/org';\nimport { MicrosoftGraphClient } from './client';\nimport {\n  MICROSOFT_GRAPH_GROUP_ID_ANNOTATION,\n  MICROSOFT_GRAPH_TENANT_ID_ANNOTATION,\n  MICROSOFT_GRAPH_USER_ID_ANNOTATION,\n} from './constants';\n\nexport function normalizeEntityName(name: string): string {\n  return name\n    .trim()\n    .toLocaleLowerCase()\n    .replace(/[^a-zA-Z0-9_\\-\\.]/g, '_');\n}\n\nexport async function readMicrosoftGraphUsers(\n  client: MicrosoftGraphClient,\n  options?: { userFilter?: string },\n): Promise<{\n  users: UserEntity[]; // With all relations empty\n}> {\n  const entities: UserEntity[] = [];\n  const promises: Promise<void>[] = [];\n  const limiter = limiterFactory(10);\n\n  for await (const user of client.getUsers({\n    filter: options?.userFilter,\n    select: ['id', 'displayName', 'mail'],\n  })) {\n    if (!user.id || !user.displayName || !user.mail) {\n      continue;\n    }\n\n    const name = normalizeEntityName(user.mail);\n    const entity: UserEntity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'User',\n      metadata: {\n        name,\n        annotations: {\n          [MICROSOFT_GRAPH_USER_ID_ANNOTATION]: user.id!,\n        },\n      },\n      spec: {\n        profile: {\n          displayName: user.displayName!,\n          email: user.mail!,\n\n          // TODO: Additional fields?\n          // jobTitle: user.jobTitle || undefined,\n          // officeLocation: user.officeLocation || undefined,\n          // mobilePhone: user.mobilePhone || undefined,\n        },\n        memberOf: [],\n      },\n    };\n\n    // Download the photos in parallel, otherwise it can take quite some time\n    const loadPhoto = limiter(async () => {\n      entity.spec.profile!.picture = await client.getUserPhotoWithSizeLimit(\n        user.id!,\n        // We are limiting the photo size, as users with full resolution photos\n        // can make the Backstage API slow\n        120,\n      );\n    });\n\n    promises.push(loadPhoto);\n    entities.push(entity);\n  }\n\n  // Wait for all photos to be downloaded\n  await Promise.all(promises);\n\n  return { users: entities };\n}\n\nexport async function readMicrosoftGraphOrganization(\n  client: MicrosoftGraphClient,\n  tenantId: string,\n): Promise<{\n  rootGroup: GroupEntity; // With all relations empty\n}> {\n  // For now we expect a single root organization\n  const organization = await client.getOrganization(tenantId);\n  const name = normalizeEntityName(organization.displayName!);\n  const rootGroup: GroupEntity = {\n    apiVersion: 'backstage.io/v1alpha1',\n    kind: 'Group',\n    metadata: {\n      name: name,\n      description: organization.displayName!,\n      annotations: {\n        [MICROSOFT_GRAPH_TENANT_ID_ANNOTATION]: organization.id!,\n      },\n    },\n    spec: {\n      type: 'root',\n      profile: {\n        displayName: organization.displayName!,\n      },\n      children: [],\n    },\n  };\n\n  return { rootGroup };\n}\n\nexport async function readMicrosoftGraphGroups(\n  client: MicrosoftGraphClient,\n  tenantId: string,\n  options?: { groupFilter?: string },\n): Promise<{\n  groups: GroupEntity[]; // With all relations empty\n  rootGroup: GroupEntity | undefined; // With all relations empty\n  groupMember: Map<string, Set<string>>;\n  groupMemberOf: Map<string, Set<string>>;\n}> {\n  const groups: GroupEntity[] = [];\n  const groupMember: Map<string, Set<string>> = new Map();\n  const groupMemberOf: Map<string, Set<string>> = new Map();\n  const limiter = limiterFactory(10);\n\n  const { rootGroup } = await readMicrosoftGraphOrganization(client, tenantId);\n  groupMember.set(rootGroup.metadata.name, new Set<string>());\n  groups.push(rootGroup);\n\n  const promises: Promise<void>[] = [];\n\n  for await (const group of client.getGroups({\n    filter: options?.groupFilter,\n    select: ['id', 'displayName', 'description', 'mail', 'mailNickname'],\n  })) {\n    if (!group.id || !group.displayName) {\n      continue;\n    }\n\n    const name = normalizeEntityName(group.mailNickname || group.displayName);\n    const entity: GroupEntity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'Group',\n      metadata: {\n        name: name,\n        annotations: {\n          [MICROSOFT_GRAPH_GROUP_ID_ANNOTATION]: group.id,\n        },\n      },\n      spec: {\n        type: 'team',\n        profile: {},\n        children: [],\n      },\n    };\n\n    if (group.description) {\n      entity.metadata.description = group.description;\n    }\n    if (group.displayName) {\n      entity.spec.profile!.displayName = group.displayName;\n    }\n    if (group.mail) {\n      entity.spec.profile!.email = group.mail;\n    }\n\n    // Download the members in parallel, otherwise it can take quite some time\n    const loadGroupMembers = limiter(async () => {\n      for await (const member of client.getGroupMembers(group.id!)) {\n        if (!member.id) {\n          continue;\n        }\n\n        if (member['@odata.type'] === '#microsoft.graph.user') {\n          ensureItem(groupMemberOf, member.id, group.id!);\n        }\n\n        if (member['@odata.type'] === '#microsoft.graph.group') {\n          ensureItem(groupMember, group.id!, member.id);\n        }\n      }\n    });\n\n    // TODO: Loading groups doesn't work right now as Microsoft Graph doesn't\n    // allows this yet: https://microsoftgraph.uservoice.com/forums/920506-microsoft-graph-feature-requests/suggestions/37884922-allow-application-to-set-or-update-a-group-s-photo\n    /*/ / Download the photos in parallel, otherwise it can take quite some time\n    const loadPhoto = limiter(async () => {\n      entity.spec.profile!.picture = await client.getGroupPhotoWithSizeLimit(\n        group.id!,\n        // We are limiting the photo size, as groups with full resolution photos\n        // can make the Backstage API slow\n        120,\n      );\n    });\n\n    promises.push(loadPhoto);*/\n    promises.push(loadGroupMembers);\n    groups.push(entity);\n  }\n\n  // Wait for all group members and photos to be loaded\n  await Promise.all(promises);\n\n  return {\n    groups,\n    rootGroup,\n    groupMember,\n    groupMemberOf,\n  };\n}\n\nexport function resolveRelations(\n  rootGroup: GroupEntity | undefined,\n  groups: GroupEntity[],\n  users: UserEntity[],\n  groupMember: Map<string, Set<string>>,\n  groupMemberOf: Map<string, Set<string>>,\n) {\n  // Build reference lookup tables, we reference them by the id the the graph\n  const groupMap: Map<string, GroupEntity> = new Map(); // by group-id or tenant-id\n\n  for (const group of groups) {\n    if (group.metadata.annotations![MICROSOFT_GRAPH_GROUP_ID_ANNOTATION]) {\n      groupMap.set(\n        group.metadata.annotations![MICROSOFT_GRAPH_GROUP_ID_ANNOTATION],\n        group,\n      );\n    }\n    if (group.metadata.annotations![MICROSOFT_GRAPH_TENANT_ID_ANNOTATION]) {\n      groupMap.set(\n        group.metadata.annotations![MICROSOFT_GRAPH_TENANT_ID_ANNOTATION],\n        group,\n      );\n    }\n  }\n\n  // Resolve all member relationships into the reverse direction\n  const parentGroups = new Map<string, Set<string>>();\n\n  groupMember.forEach((members, groupId) =>\n    members.forEach(m => ensureItem(parentGroups, m, groupId)),\n  );\n\n  // Make sure every group (except root) has at least one parent. If the parent is missing, add the root.\n  if (rootGroup) {\n    const tenantId = rootGroup.metadata.annotations![\n      MICROSOFT_GRAPH_TENANT_ID_ANNOTATION\n    ];\n\n    groups.forEach(group => {\n      const groupId = group.metadata.annotations![\n        MICROSOFT_GRAPH_GROUP_ID_ANNOTATION\n      ];\n\n      if (!groupId) {\n        return;\n      }\n\n      if (retrieveItems(parentGroups, groupId).size === 0) {\n        ensureItem(parentGroups, groupId, tenantId);\n        ensureItem(groupMember, tenantId, groupId);\n      }\n    });\n  }\n\n  groups.forEach(group => {\n    const id =\n      group.metadata.annotations![MICROSOFT_GRAPH_GROUP_ID_ANNOTATION] ??\n      group.metadata.annotations![MICROSOFT_GRAPH_TENANT_ID_ANNOTATION];\n\n    retrieveItems(groupMember, id).forEach(m => {\n      const childGroup = groupMap.get(m);\n      if (childGroup) {\n        group.spec.children.push(childGroup.metadata.name);\n      }\n    });\n\n    retrieveItems(parentGroups, id).forEach(p => {\n      const parentGroup = groupMap.get(p);\n      if (parentGroup) {\n        // TODO: Only having a single parent group might not match every companies model, but fine for now.\n        group.spec.parent = parentGroup.metadata.name;\n      }\n    });\n  });\n\n  // Make sure that all groups have proper parents and children\n  buildOrgHierarchy(groups);\n\n  // Set relations for all users\n  users.forEach(user => {\n    const id = user.metadata.annotations![MICROSOFT_GRAPH_USER_ID_ANNOTATION];\n\n    retrieveItems(groupMemberOf, id).forEach(p => {\n      const parentGroup = groupMap.get(p);\n      if (parentGroup) {\n        user.spec.memberOf.push(parentGroup.metadata.name);\n      }\n    });\n  });\n\n  // Make sure all transitive memberships are available\n  buildMemberOf(groups, users);\n}\n\nexport async function readMicrosoftGraphOrg(\n  client: MicrosoftGraphClient,\n  tenantId: string,\n  options?: { userFilter?: string; groupFilter?: string },\n): Promise<{ users: UserEntity[]; groups: GroupEntity[] }> {\n  const { users } = await readMicrosoftGraphUsers(client, {\n    userFilter: options?.userFilter,\n  });\n  const {\n    groups,\n    rootGroup,\n    groupMember,\n    groupMemberOf,\n  } = await readMicrosoftGraphGroups(client, tenantId, {\n    groupFilter: options?.groupFilter,\n  });\n\n  resolveRelations(rootGroup, groups, users, groupMember, groupMemberOf);\n  users.sort((a, b) => a.metadata.name.localeCompare(b.metadata.name));\n  groups.sort((a, b) => a.metadata.name.localeCompare(b.metadata.name));\n\n  return { users, groups };\n}\n\nfunction ensureItem(\n  target: Map<string, Set<string>>,\n  key: string,\n  value: string,\n) {\n  let set = target.get(key);\n  if (!set) {\n    set = new Set();\n    target.set(key, set);\n  }\n  set!.add(value);\n}\n\nfunction retrieveItems(\n  target: Map<string, Set<string>>,\n  key: string,\n): Set<string> {\n  return target.get(key) ?? new Set();\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { LocationSpec } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { Logger } from 'winston';\nimport {\n  MicrosoftGraphClient,\n  MicrosoftGraphProviderConfig,\n  readMicrosoftGraphConfig,\n  readMicrosoftGraphOrg,\n} from './microsoftGraph';\nimport * as results from './results';\nimport { CatalogProcessor, CatalogProcessorEmit } from './types';\n\n/**\n * Extracts teams and users out of an LDAP server.\n */\nexport class MicrosoftGraphOrgReaderProcessor implements CatalogProcessor {\n  private readonly providers: MicrosoftGraphProviderConfig[];\n  private readonly logger: Logger;\n\n  static fromConfig(config: Config, options: { logger: Logger }) {\n    const c = config.getOptionalConfig('catalog.processors.microsoftGraphOrg');\n    return new MicrosoftGraphOrgReaderProcessor({\n      ...options,\n      providers: c ? readMicrosoftGraphConfig(c) : [],\n    });\n  }\n\n  constructor(options: {\n    providers: MicrosoftGraphProviderConfig[];\n    logger: Logger;\n  }) {\n    this.providers = options.providers;\n    this.logger = options.logger;\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    if (location.type !== 'microsoft-graph-org') {\n      return false;\n    }\n\n    const provider = this.providers.find(p =>\n      location.target.startsWith(p.target),\n    );\n    if (!provider) {\n      throw new Error(\n        `There is no Microsoft Graph Org provider that matches ${location.target}. Please add a configuration entry for it under catalog.processors.microsoftGraphOrg.providers.`,\n      );\n    }\n\n    // Read out all of the raw data\n    const startTimestamp = Date.now();\n    this.logger.info('Reading Microsoft Graph users and groups');\n\n    // We create a client each time as we need one that matches the specific provider\n    const client = MicrosoftGraphClient.create(provider);\n    const { users, groups } = await readMicrosoftGraphOrg(\n      client,\n      provider.tenantId,\n      {\n        userFilter: provider.userFilter,\n        groupFilter: provider.groupFilter,\n      },\n    );\n\n    const duration = ((Date.now() - startTimestamp) / 1000).toFixed(1);\n    this.logger.debug(\n      `Read ${users.length} users and ${groups.length} groups from Microsoft Graph in ${duration} seconds`,\n    );\n\n    // Done!\n    for (const group of groups) {\n      emit(results.entity(location, group));\n    }\n    for (const user of users) {\n      emit(results.entity(location, user));\n    }\n\n    return true;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { UrlReader } from '@backstage/backend-common';\nimport { Entity, LocationSpec } from '@backstage/catalog-model';\nimport { JsonValue } from '@backstage/config';\nimport yaml from 'yaml';\nimport { CatalogProcessor } from './types';\n\nexport type ResolverRead = (url: string) => Promise<Buffer>;\n\nexport type ResolverParams = {\n  key: string;\n  value: JsonValue;\n  baseUrl: string;\n  read: ResolverRead;\n};\n\nexport type PlaceholderResolver = (\n  params: ResolverParams,\n) => Promise<JsonValue>;\n\ntype Options = {\n  resolvers: Record<string, PlaceholderResolver>;\n  reader: UrlReader;\n};\n\n/**\n * Traverses raw entity JSON looking for occurrences of $-prefixed placeholders\n * that it then fills in with actual data.\n */\nexport class PlaceholderProcessor implements CatalogProcessor {\n  constructor(private readonly options: Options) {}\n\n  async preProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n  ): Promise<Entity> {\n    const process = async (data: any): Promise<[any, boolean]> => {\n      if (!data || !(data instanceof Object)) {\n        // Scalars can't have placeholders\n        return [data, false];\n      }\n\n      if (Array.isArray(data)) {\n        // We're an array - process all entries recursively\n        const items = await Promise.all(data.map(item => process(item)));\n        return items.every(([, changed]) => !changed)\n          ? [data, false]\n          : [items.map(([item]) => item), true];\n      }\n\n      const keys = Object.keys(data);\n      if (!keys.some(k => k.startsWith('$'))) {\n        // We're an object but no placeholders at this level - process all\n        // entries recursively\n        const entries = await Promise.all(\n          Object.entries(data).map(([k, v]) =>\n            process(v).then(vp => [k, vp] as const),\n          ),\n        );\n        return entries.every(([, [, changed]]) => !changed)\n          ? [data, false]\n          : [Object.fromEntries(entries.map(([k, [v]]) => [k, v])), true];\n      } else if (keys.length !== 1) {\n        // This was an object that had more than one key, some of which were\n        // dollar prefixed. We only handle the case where there is exactly one\n        // such key; anything else is left alone.\n        return [data, false];\n      }\n\n      const resolverKey = keys[0].substr(1);\n      const resolverValue = data[keys[0]];\n      const resolver = this.options.resolvers[resolverKey];\n      if (!resolver || typeof resolverValue !== 'string') {\n        // If there was no such placeholder resolver or if the value was not a\n        // string, we err on the side of safety and assume that this is\n        // something that's best left alone. For example, if the input contains\n        // JSONSchema, there may be \"$ref\": \"#/definitions/node\" nodes in the\n        // document.\n        return [data, false];\n      }\n\n      return [\n        await resolver({\n          key: resolverKey,\n          value: resolverValue,\n          baseUrl: location.target,\n          read: this.options.reader.read.bind(this.options.reader),\n        }),\n        true,\n      ];\n    };\n\n    const [result] = await process(entity);\n    return result;\n  }\n}\n\n/*\n * Resolvers\n */\n\nexport async function yamlPlaceholderResolver(\n  params: ResolverParams,\n): Promise<JsonValue> {\n  const text = await readTextLocation(params);\n\n  let documents: yaml.Document.Parsed[];\n  try {\n    documents = yaml.parseAllDocuments(text).filter(d => d);\n  } catch (e) {\n    throw new Error(\n      `Placeholder \\$${params.key} failed to parse YAML data at ${params.value}, ${e}`,\n    );\n  }\n\n  if (documents.length !== 1) {\n    throw new Error(\n      `Placeholder \\$${params.key} expected to find exactly one document of data at ${params.value}, found ${documents.length}`,\n    );\n  }\n\n  const document = documents[0];\n\n  if (document.errors?.length) {\n    throw new Error(\n      `Placeholder \\$${params.key} found an error in the data at ${params.value}, ${document.errors[0]}`,\n    );\n  }\n\n  return document.toJSON();\n}\n\nexport async function jsonPlaceholderResolver(\n  params: ResolverParams,\n): Promise<JsonValue> {\n  const text = await readTextLocation(params);\n\n  try {\n    return JSON.parse(text);\n  } catch (e) {\n    throw new Error(\n      `Placeholder \\$${params.key} failed to parse JSON data at ${params.value}, ${e}`,\n    );\n  }\n}\n\nexport async function textPlaceholderResolver(\n  params: ResolverParams,\n): Promise<JsonValue> {\n  return await readTextLocation(params);\n}\n\n/*\n * Helpers\n */\n\nasync function readTextLocation(params: ResolverParams): Promise<string> {\n  const newUrl = relativeUrl(params);\n\n  try {\n    const data = await params.read(newUrl);\n    return data.toString('utf-8');\n  } catch (e) {\n    throw new Error(\n      `Placeholder \\$${params.key} could not read location ${params.value}, ${e}`,\n    );\n  }\n}\n\nfunction relativeUrl({ key, value, baseUrl }: ResolverParams): string {\n  if (typeof value !== 'string') {\n    throw new Error(\n      `Placeholder \\$${key} expected a string value parameter, in the form of an absolute URL or a relative path`,\n    );\n  }\n\n  let url: URL;\n  try {\n    // The two-value form of the URL constructor handles relative paths for us\n    url = new URL(value, baseUrl);\n  } catch {\n    try {\n      // Check whether value is a valid absolute URL on it's own, if not fail.\n      url = new URL(value);\n    } catch {\n      // The only remaining case that isn't support is a relative file path that should be\n      // resolved using a relative file location. Accessing local file paths can lead to\n      // path traversal attacks and access to any file on the host system. Implementing this\n      // would require additional security measures.\n      throw new Error(\n        `Placeholder \\$${key} could not form a URL out of ${baseUrl} and ${value}`,\n      );\n    }\n  }\n\n  return url.toString();\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { LocationSpec } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport * as result from './results';\nimport { CatalogProcessorEmit } from './types';\n\nexport class StaticLocationProcessor implements StaticLocationProcessor {\n  static fromConfig(config: Config): StaticLocationProcessor {\n    const locations: LocationSpec[] = [];\n\n    const lConfigs = config.getOptionalConfigArray('catalog.locations') ?? [];\n    for (const lConfig of lConfigs) {\n      const type = lConfig.getString('type');\n      const target = lConfig.getString('target');\n      locations.push({ type, target });\n    }\n\n    return new StaticLocationProcessor(locations);\n  }\n\n  constructor(private readonly staticLocations: LocationSpec[]) {}\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    if (location.type !== 'bootstrap') {\n      return false;\n    }\n\n    for (const staticLocation of this.staticLocations) {\n      emit(result.location(staticLocation, false));\n    }\n\n    return true;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { UrlReader } from '@backstage/backend-common';\nimport { LocationSpec } from '@backstage/catalog-model';\nimport parseGitUrl from 'git-url-parse';\nimport limiterFactory from 'p-limit';\nimport { Logger } from 'winston';\nimport * as result from './results';\nimport {\n  CatalogProcessor,\n  CatalogProcessorEmit,\n  CatalogProcessorParser,\n} from './types';\n\n// TODO(Rugvip): Added for backwards compatibility when moving to UrlReader, this\n// can be removed in a bit\nconst deprecatedTypes = [\n  'github',\n  'github/api',\n  'bitbucket/api',\n  'gitlab/api',\n  'azure/api',\n];\n\ntype Options = {\n  reader: UrlReader;\n  logger: Logger;\n};\n\nexport class UrlReaderProcessor implements CatalogProcessor {\n  constructor(private readonly options: Options) {}\n\n  async readLocation(\n    location: LocationSpec,\n    optional: boolean,\n    emit: CatalogProcessorEmit,\n    parser: CatalogProcessorParser,\n  ): Promise<boolean> {\n    if (deprecatedTypes.includes(location.type)) {\n      // TODO(Rugvip): Remove this warning a month or two into 2021, and remove support for the deprecated types.\n      this.options.logger.warn(\n        `Location '${location.target}' uses deprecated location type '${location.type}', use 'url' instead. ` +\n          'Use \"scripts/migrate-location-types.js\" in the Backstage repo to migrate existing locations.',\n      );\n    } else if (location.type !== 'url') {\n      return false;\n    }\n\n    try {\n      const output = await this.doRead(location.target);\n      for (const item of output) {\n        for await (const parseResult of parser({\n          data: item.data,\n          location: { type: location.type, target: item.url },\n        })) {\n          emit(parseResult);\n        }\n      }\n    } catch (error) {\n      const message = `Unable to read ${location.type}, ${error}`;\n\n      if (error.name === 'NotFoundError') {\n        if (!optional) {\n          emit(result.notFoundError(location, message));\n        }\n      } else {\n        emit(result.generalError(location, message));\n      }\n    }\n\n    return true;\n  }\n\n  private async doRead(\n    location: string,\n  ): Promise<{ data: Buffer; url: string }[]> {\n    // Does it contain globs? I.e. does it contain asterisks or question marks\n    // (no curly braces for now)\n    const { filepath } = parseGitUrl(location);\n    if (filepath?.match(/[*?]/)) {\n      const limiter = limiterFactory(5);\n      const response = await this.options.reader.search(location);\n      const output = response.files.map(async file => ({\n        url: file.url,\n        data: await limiter(file.content),\n      }));\n      return Promise.all(output);\n    }\n\n    // Otherwise do a plain read\n    const data = await this.options.reader.read(location);\n    return [{ url: location, data }];\n  }\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PluginEndpointDiscovery } from '@backstage/backend-common';\nimport { Entity } from '@backstage/catalog-model';\nimport { IndexableDocument, DocumentCollator } from '@backstage/search-common';\nimport fetch from 'cross-fetch';\n\nexport interface CatalogEntityDocument extends IndexableDocument {\n  componentType: string;\n  namespace: string;\n  kind: string;\n  lifecycle: string;\n  owner: string;\n}\n\nexport class DefaultCatalogCollator implements DocumentCollator {\n  protected discovery: PluginEndpointDiscovery;\n  protected locationTemplate: string;\n\n  constructor({\n    discovery,\n    locationTemplate,\n  }: {\n    discovery: PluginEndpointDiscovery;\n    locationTemplate?: string;\n  }) {\n    this.discovery = discovery;\n    this.locationTemplate =\n      locationTemplate || '/catalog/:namespace/:kind/:name';\n  }\n\n  protected applyArgsToFormat(\n    format: string,\n    args: Record<string, string>,\n  ): string {\n    let formatted = format;\n    for (const [key, value] of Object.entries(args)) {\n      formatted = formatted.replace(`:${key}`, value);\n    }\n    return formatted.toLowerCase();\n  }\n\n  async execute() {\n    const baseUrl = await this.discovery.getBaseUrl('catalog');\n    const res = await fetch(`${baseUrl}/entities`);\n    const entities: Entity[] = await res.json();\n    return entities.map(\n      (entity: Entity): CatalogEntityDocument => {\n        return {\n          title: entity.metadata.name,\n          location: this.applyArgsToFormat(this.locationTemplate, {\n            namespace: entity.metadata.namespace || 'default',\n            kind: entity.kind,\n            name: entity.metadata.name,\n          }),\n          text: entity.metadata.description || '',\n          componentType: entity.spec?.type?.toString() || 'other',\n          namespace: entity.metadata.namespace || 'default',\n          kind: entity.kind,\n          lifecycle: (entity.spec?.lifecycle as string) || '',\n          owner: (entity.spec?.owner as string) || '',\n        };\n      },\n    );\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport { LocationSpec, Entity } from '@backstage/catalog-model';\n\n/**\n * A structure for matching entities to a given rule.\n */\ntype EntityMatcher = {\n  kind: string;\n};\n\n/**\n * A structure for matching locations to a given rule.\n */\ntype LocationMatcher = {\n  target?: string;\n  type: string;\n};\n\n/**\n * Rules to apply to catalog entities\n *\n * An undefined list of matchers means match all, an empty list of matchers means match none\n */\ntype CatalogRule = {\n  allow: EntityMatcher[];\n  locations?: LocationMatcher[];\n};\n\nexport class CatalogRulesEnforcer {\n  /**\n   * Default rules used by the catalog.\n   *\n   * Denies any location from specifying user or group entities.\n   */\n  static readonly defaultRules: CatalogRule[] = [\n    {\n      allow: ['Component', 'API', 'Location'].map(kind => ({ kind })),\n    },\n  ];\n\n  /**\n   * Loads catalog rules from config.\n   *\n   * This reads `catalog.rules` and defaults to the default rules if no value is present.\n   * The value of the config should be a list of config objects, each with a single `allow`\n   * field which in turn is a list of entity kinds to allow.\n   *\n   * If there is no matching rule to allow an ingested entity, it will be rejected by the catalog.\n   *\n   * It also reads in rules from `catalog.locations`, where each location can have a list\n   * of rules for that specific location, specified in a `rules` field.\n   *\n   * For example:\n   *\n   * ```yaml\n   * catalog:\n   *   rules:\n   *   - allow: [Component, API]\n   *\n   *   locations:\n   *   - type: url\n   *     target: https://github.com/org/repo/blob/master/users.yaml\n   *     rules:\n   *       - allow: [User, Group]\n   *   - type: url\n   *     target: https://github.com/org/repo/blob/master/systems.yaml\n   *     rules:\n   *       - allow: [System]\n   * ```\n   */\n  static fromConfig(config: Config) {\n    const rules = new Array<CatalogRule>();\n\n    if (config.has('catalog.rules')) {\n      const globalRules = config.getConfigArray('catalog.rules').map(sub => ({\n        allow: sub.getStringArray('allow').map(kind => ({ kind })),\n      }));\n      rules.push(...globalRules);\n    } else {\n      rules.push(...CatalogRulesEnforcer.defaultRules);\n    }\n\n    if (config.has('catalog.locations')) {\n      const locationRules = config\n        .getConfigArray('catalog.locations')\n        .flatMap(locConf => {\n          if (!locConf.has('rules')) {\n            return [];\n          }\n          const type = locConf.getString('type');\n          const target = locConf.getString('target');\n\n          return locConf.getConfigArray('rules').map(ruleConf => ({\n            allow: ruleConf.getStringArray('allow').map(kind => ({ kind })),\n            locations: [{ type, target }],\n          }));\n        });\n\n      rules.push(...locationRules);\n    }\n\n    return new CatalogRulesEnforcer(rules);\n  }\n\n  constructor(private readonly rules: CatalogRule[]) {}\n\n  /**\n   * Checks wether a specific entity/location combination is allowed\n   * according to the configured rules.\n   */\n  isAllowed(entity: Entity, location: LocationSpec) {\n    for (const rule of this.rules) {\n      if (!this.matchLocation(location, rule.locations)) {\n        continue;\n      }\n\n      if (this.matchEntity(entity, rule.allow)) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  private matchLocation(\n    location: LocationSpec,\n    matchers?: LocationMatcher[],\n  ): boolean {\n    if (!matchers) {\n      return true;\n    }\n\n    for (const matcher of matchers) {\n      if (matcher.type !== location?.type) {\n        continue;\n      }\n      if (matcher.target && matcher.target !== location?.target) {\n        continue;\n      }\n      return true;\n    }\n\n    return false;\n  }\n\n  private matchEntity(entity: Entity, matchers?: EntityMatcher[]): boolean {\n    if (!matchers) {\n      return true;\n    }\n\n    for (const matcher of matchers) {\n      if (entity?.kind?.toLowerCase() !== matcher.kind.toLowerCase()) {\n        continue;\n      }\n\n      return true;\n    }\n\n    return false;\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger } from 'winston';\nimport parseGitUrl from 'git-url-parse';\nimport { Entity } from '@backstage/catalog-model';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport {\n  AnalyzeLocationRequest,\n  AnalyzeLocationResponse,\n  LocationAnalyzer,\n} from './types';\n\nexport class RepoLocationAnalyzer implements LocationAnalyzer {\n  private readonly logger: Logger;\n  private readonly scmIntegrations: ScmIntegrationRegistry;\n\n  constructor(logger: Logger, scmIntegrations: ScmIntegrationRegistry) {\n    this.logger = logger;\n    this.scmIntegrations = scmIntegrations;\n  }\n  async analyzeLocation(\n    request: AnalyzeLocationRequest,\n  ): Promise<AnalyzeLocationResponse> {\n    const { owner, name } = parseGitUrl(request.location.target);\n    const entity: Entity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'Component',\n      metadata: {\n        name: name,\n      },\n      spec: { type: 'other', lifecycle: 'unknown' },\n    };\n\n    const integration = this.scmIntegrations.byUrl(request.location.target);\n    let annotationPrefix;\n    switch (integration?.type) {\n      case 'azure':\n        annotationPrefix = 'dev.azure.com';\n        break;\n      case 'bitbucket':\n        annotationPrefix = 'bitbucket.org';\n        break;\n      case 'github':\n        annotationPrefix = 'github.com';\n        break;\n      case 'gitlab':\n        annotationPrefix = 'gitlab.com';\n        break;\n      default:\n        break;\n    }\n\n    if (annotationPrefix) {\n      entity.metadata.annotations = {\n        [`${annotationPrefix}/project-slug`]: `${owner}/${name}`,\n      };\n    }\n\n    this.logger.debug(`entity created for ${request.location.target}`);\n    return {\n      existingEntityFiles: [],\n      generateEntities: [{ entity, fields: [] }],\n    };\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PluginDatabaseManager, UrlReader } from '@backstage/backend-common';\nimport {\n  DefaultNamespaceEntityPolicy,\n  EntityPolicies,\n  EntityPolicy,\n  FieldFormatEntityPolicy,\n  makeValidator,\n  NoForeignRootFieldsEntityPolicy,\n  SchemaValidEntityPolicy,\n  Validators,\n} from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { ScmIntegrations } from '@backstage/integration';\nimport lodash from 'lodash';\nimport { Logger } from 'winston';\nimport {\n  DatabaseEntitiesCatalog,\n  DatabaseLocationsCatalog,\n  EntitiesCatalog,\n  LocationsCatalog,\n} from '../catalog';\nimport { DatabaseManager } from '../database';\nimport {\n  AnnotateLocationEntityProcessor,\n  BitbucketDiscoveryProcessor,\n  BuiltinKindsEntityProcessor,\n  CatalogProcessor,\n  CatalogProcessorParser,\n  CodeOwnersProcessor,\n  FileReaderProcessor,\n  GithubDiscoveryProcessor,\n  GithubOrgReaderProcessor,\n  HigherOrderOperation,\n  HigherOrderOperations,\n  LdapOrgReaderProcessor,\n  LocationEntityProcessor,\n  LocationReaders,\n  MicrosoftGraphOrgReaderProcessor,\n  PlaceholderProcessor,\n  PlaceholderResolver,\n  StaticLocationProcessor,\n  UrlReaderProcessor,\n} from '../ingestion';\nimport { CatalogRulesEnforcer } from '../ingestion/CatalogRules';\nimport { RepoLocationAnalyzer } from '../ingestion/LocationAnalyzer';\nimport {\n  jsonPlaceholderResolver,\n  textPlaceholderResolver,\n  yamlPlaceholderResolver,\n} from '../ingestion/processors/PlaceholderProcessor';\nimport { defaultEntityDataParser } from '../ingestion/processors/util/parse';\nimport { LocationAnalyzer } from '../ingestion/types';\n\nexport type CatalogEnvironment = {\n  logger: Logger;\n  database: PluginDatabaseManager;\n  config: Config;\n  reader: UrlReader;\n};\n\n/**\n * A builder that helps wire up all of the component parts of the catalog.\n *\n * The touch points where you can replace or extend behavior are as follows:\n *\n * - Entity policies can be added or replaced. These are automatically run\n *   after the processors' pre-processing steps. All policies are given the\n *   chance to inspect the entity, and all of them have to pass in order for\n *   the entity to be considered valid from an overall point of view.\n * - Placeholder resolvers can be replaced or added. These run on the raw\n *   structured data between the parsing and pre-processing steps, to replace\n *   dollar-prefixed entries with their actual values (like $file).\n * - Field format validators can be replaced. These check the format of\n *   individual core fields such as metadata.name, to ensure that they adhere\n *   to certain rules.\n * - Processors can be added or replaced. These implement the functionality of\n *   reading, parsing, validating, and processing the entity data before it is\n *   persisted in the catalog.\n */\nexport class CatalogBuilder {\n  private readonly env: CatalogEnvironment;\n  private entityPolicies: EntityPolicy[];\n  private entityPoliciesReplace: boolean;\n  private placeholderResolvers: Record<string, PlaceholderResolver>;\n  private fieldFormatValidators: Partial<Validators>;\n  private processors: CatalogProcessor[];\n  private processorsReplace: boolean;\n  private parser: CatalogProcessorParser | undefined;\n\n  constructor(env: CatalogEnvironment) {\n    this.env = env;\n    this.entityPolicies = [];\n    this.entityPoliciesReplace = false;\n    this.placeholderResolvers = {};\n    this.fieldFormatValidators = {};\n    this.processors = [];\n    this.processorsReplace = false;\n    this.parser = undefined;\n  }\n\n  /**\n   * Adds policies that are used to validate entities between the pre-\n   * processing and post-processing stages. All such policies must pass for the\n   * entity to be considered valid.\n   *\n   * If what you want to do is to replace the rules for what format is allowed\n   * in various core entity fields (such as metadata.name), you may want to use\n   * {@link CatalogBuilder#setFieldFormatValidators} instead.\n   *\n   * @param policies One or more policies\n   */\n  addEntityPolicy(...policies: EntityPolicy[]): CatalogBuilder {\n    this.entityPolicies.push(...policies);\n    return this;\n  }\n\n  /**\n   * Sets what policies to use for validation of entities between the pre-\n   * processing and post-processing stages. All such policies must pass for the\n   * entity to be considered valid.\n   *\n   * If what you want to do is to replace the rules for what format is allowed\n   * in various core entity fields (such as metadata.name), you may want to use\n   * {@link CatalogBuilder#setFieldFormatValidators} instead.\n   *\n   * This function replaces the default set of policies; use with care.\n   *\n   * @param policies One or more policies\n   */\n  replaceEntityPolicies(policies: EntityPolicy[]): CatalogBuilder {\n    this.entityPolicies = [...policies];\n    this.entityPoliciesReplace = true;\n    return this;\n  }\n\n  /**\n   * Adds, or overwrites, a handler for placeholders (e.g. $file) in entity\n   * definition files.\n   *\n   * @param key The key that identifies the placeholder, e.g. \"file\"\n   * @param resolver The resolver that gets values for this placeholder\n   */\n  setPlaceholderResolver(\n    key: string,\n    resolver: PlaceholderResolver,\n  ): CatalogBuilder {\n    this.placeholderResolvers[key] = resolver;\n    return this;\n  }\n\n  /**\n   * Sets the validator function to use for one or more special fields of an\n   * entity. This is useful if the default rules for formatting of fields are\n   * not sufficient.\n   *\n   * This function has no effect if used together with\n   * {@link CatalogBuilder#replaceEntityPolicies}.\n   *\n   * @param validators The (subset of) validators to set\n   */\n  setFieldFormatValidators(validators: Partial<Validators>): CatalogBuilder {\n    lodash.merge(this.fieldFormatValidators, validators);\n    return this;\n  }\n\n  /**\n   * Adds entity processors. These are responsible for reading, parsing, and\n   * processing entities before they are persisted in the catalog.\n   *\n   * @param processors One or more processors\n   */\n  addProcessor(...processors: CatalogProcessor[]): CatalogBuilder {\n    this.processors.push(...processors);\n    return this;\n  }\n\n  /**\n   * Sets what entity processors to use. These are responsible for reading,\n   * parsing, and processing entities before they are persisted in the catalog.\n   *\n   * This function replaces the default set of processors; use with care.\n   *\n   * @param processors One or more processors\n   */\n  replaceProcessors(processors: CatalogProcessor[]): CatalogBuilder {\n    this.processors = [...processors];\n    this.processorsReplace = true;\n    return this;\n  }\n\n  /**\n   * Sets up the catalog to use a custom parser for entity data.\n   *\n   * This is the function that gets called immediately after some raw entity\n   * specification data has been read from a remote source, and needs to be\n   * parsed and emitted as structured data.\n   *\n   * @param parser The custom parser\n   */\n  setEntityDataParser(parser: CatalogProcessorParser): CatalogBuilder {\n    this.parser = parser;\n    return this;\n  }\n\n  /**\n   * Wires up and returns all of the component parts of the catalog\n   */\n  async build(): Promise<{\n    entitiesCatalog: EntitiesCatalog;\n    locationsCatalog: LocationsCatalog;\n    higherOrderOperation: HigherOrderOperation;\n    locationAnalyzer: LocationAnalyzer;\n  }> {\n    const { config, database, logger } = this.env;\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    const policy = this.buildEntityPolicy();\n    const processors = this.buildProcessors();\n    const rulesEnforcer = CatalogRulesEnforcer.fromConfig(config);\n    const parser = this.parser || defaultEntityDataParser;\n\n    const locationReader = new LocationReaders({\n      ...this.env,\n      parser,\n      processors,\n      rulesEnforcer,\n      policy,\n    });\n\n    const db = await DatabaseManager.createDatabase(\n      await database.getClient(),\n      { logger },\n    );\n\n    const entitiesCatalog = new DatabaseEntitiesCatalog(db, this.env.logger);\n    const locationsCatalog = new DatabaseLocationsCatalog(db);\n    const higherOrderOperation = new HigherOrderOperations(\n      entitiesCatalog,\n      locationsCatalog,\n      locationReader,\n      logger,\n    );\n    const locationAnalyzer = new RepoLocationAnalyzer(logger, integrations);\n\n    return {\n      entitiesCatalog,\n      locationsCatalog,\n      higherOrderOperation,\n      locationAnalyzer,\n    };\n  }\n\n  private buildEntityPolicy(): EntityPolicy {\n    const entityPolicies: EntityPolicy[] = this.entityPoliciesReplace\n      ? [new SchemaValidEntityPolicy(), ...this.entityPolicies]\n      : [\n          new SchemaValidEntityPolicy(),\n          new DefaultNamespaceEntityPolicy(),\n          new NoForeignRootFieldsEntityPolicy(),\n          new FieldFormatEntityPolicy(\n            makeValidator(this.fieldFormatValidators),\n          ),\n          ...this.entityPolicies,\n        ];\n\n    return EntityPolicies.allOf(entityPolicies);\n  }\n\n  private buildProcessors(): CatalogProcessor[] {\n    const { config, logger, reader } = this.env;\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    this.checkDeprecatedReaderProcessors();\n\n    const placeholderResolvers: Record<string, PlaceholderResolver> = {\n      json: jsonPlaceholderResolver,\n      yaml: yamlPlaceholderResolver,\n      text: textPlaceholderResolver,\n      ...this.placeholderResolvers,\n    };\n\n    // These are always there no matter what\n    const processors: CatalogProcessor[] = [\n      StaticLocationProcessor.fromConfig(config),\n      new PlaceholderProcessor({ resolvers: placeholderResolvers, reader }),\n      new BuiltinKindsEntityProcessor(),\n    ];\n\n    // These are only added unless the user replaced them all\n    if (!this.processorsReplace) {\n      processors.push(\n        new FileReaderProcessor(),\n        BitbucketDiscoveryProcessor.fromConfig(config, { logger }),\n        GithubDiscoveryProcessor.fromConfig(config, { logger }),\n        GithubOrgReaderProcessor.fromConfig(config, { logger }),\n        LdapOrgReaderProcessor.fromConfig(config, { logger }),\n        MicrosoftGraphOrgReaderProcessor.fromConfig(config, { logger }),\n        new UrlReaderProcessor({ reader, logger }),\n        CodeOwnersProcessor.fromConfig(config, { logger, reader }),\n        new LocationEntityProcessor({ integrations }),\n        new AnnotateLocationEntityProcessor({ integrations }),\n      );\n    }\n\n    // Add the ones (if any) that the user added\n    processors.push(...this.processors);\n\n    return processors;\n  }\n\n  // TODO(Rugvip): These old processors are removed, for a while we'll be throwing\n  //               errors here to make sure people know where to move the config\n  private checkDeprecatedReaderProcessors() {\n    const pc = this.env.config.getOptionalConfig('catalog.processors');\n    if (pc?.has('github')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.github, move to using integrations.github instead`,\n      );\n    }\n    if (pc?.has('gitlabApi')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.gitlabApi, move to using integrations.gitlab instead`,\n      );\n    }\n    if (pc?.has('bitbucketApi')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.bitbucketApi, move to using integrations.bitbucket instead`,\n      );\n    }\n    if (pc?.has('azureApi')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.azureApi, move to using integrations.azure instead`,\n      );\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError, NotAllowedError } from '@backstage/errors';\nimport { Request } from 'express';\nimport lodash from 'lodash';\nimport yup from 'yup';\n\nexport async function requireRequestBody(req: Request): Promise<unknown> {\n  const contentType = req.header('content-type');\n  if (!contentType) {\n    throw new InputError('Content-Type missing');\n  } else if (!contentType.match(/^application\\/json($|;)/)) {\n    throw new InputError('Illegal Content-Type');\n  }\n\n  const body = req.body;\n  if (!body) {\n    throw new InputError('Missing request body');\n  } else if (!lodash.isPlainObject(body)) {\n    throw new InputError('Expected body to be a JSON object');\n  } else if (Object.keys(body).length === 0) {\n    // Because of how express.json() translates the empty body to {}\n    throw new InputError('Empty request body');\n  }\n\n  return body;\n}\n\nexport async function validateRequestBody<T>(\n  req: Request,\n  schema: yup.Schema<T>,\n): Promise<T> {\n  const body = await requireRequestBody(req);\n\n  try {\n    await schema.validate(body, { strict: true });\n  } catch (e) {\n    throw new InputError(`Malformed request: ${e}`);\n  }\n\n  return (body as unknown) as T;\n}\n\nexport function disallowReadonlyMode(readonly: boolean) {\n  if (readonly) {\n    throw new NotAllowedError('This operation not allowed in readonly mode');\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { errorHandler } from '@backstage/backend-common';\nimport type { Entity } from '@backstage/catalog-model';\nimport {\n  analyzeLocationSchema,\n  locationSpecSchema,\n} from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { NotFoundError } from '@backstage/errors';\nimport express from 'express';\nimport Router from 'express-promise-router';\nimport { Logger } from 'winston';\nimport yn from 'yn';\nimport { EntitiesCatalog, LocationsCatalog } from '../catalog';\nimport { HigherOrderOperation, LocationAnalyzer } from '../ingestion/types';\nimport {\n  basicEntityFilter,\n  parseEntityFilterParams,\n  parseEntityPaginationParams,\n  parseEntityTransformParams,\n} from './request';\nimport {\n  disallowReadonlyMode,\n  requireRequestBody,\n  validateRequestBody,\n} from './util';\n\nexport interface RouterOptions {\n  entitiesCatalog?: EntitiesCatalog;\n  locationsCatalog?: LocationsCatalog;\n  higherOrderOperation?: HigherOrderOperation;\n  locationAnalyzer?: LocationAnalyzer;\n  logger: Logger;\n  config: Config;\n}\n\nexport async function createRouter(\n  options: RouterOptions,\n): Promise<express.Router> {\n  const {\n    entitiesCatalog,\n    locationsCatalog,\n    higherOrderOperation,\n    locationAnalyzer,\n    config,\n    logger,\n  } = options;\n\n  const router = Router();\n  router.use(express.json());\n\n  const readonlyEnabled =\n    config.getOptionalBoolean('catalog.readonly') || false;\n  if (readonlyEnabled) {\n    logger.info('Catalog is running in readonly mode');\n  }\n\n  if (entitiesCatalog) {\n    router\n      .get('/entities', async (req, res) => {\n        const { entities, pageInfo } = await entitiesCatalog.entities({\n          filter: parseEntityFilterParams(req.query),\n          fields: parseEntityTransformParams(req.query),\n          pagination: parseEntityPaginationParams(req.query),\n        });\n\n        // Add a Link header to the next page\n        if (pageInfo.hasNextPage) {\n          const url = new URL(`http://ignored${req.url}`);\n          url.searchParams.delete('offset');\n          url.searchParams.set('after', pageInfo.endCursor);\n          res.setHeader('link', `<${url.pathname}${url.search}>; rel=\"next\"`);\n        }\n\n        // TODO(freben): encode the pageInfo in the response\n        res.json(entities);\n      })\n      .post('/entities', async (req, res) => {\n        /*\n         * NOTE: THIS METHOD IS DEPRECATED AND NOT RECOMMENDED TO USE\n         *\n         * Posting entities to this method has unclear semantics and will not\n         * properly subject them to limitations, processing, or resolution of\n         * relations.\n         *\n         * It stays around in the service for the time being, but may be\n         * removed or change semantics at any time without prior notice.\n         */\n        disallowReadonlyMode(readonlyEnabled);\n\n        const body = await requireRequestBody(req);\n        const [result] = await entitiesCatalog.batchAddOrUpdateEntities([\n          { entity: body as Entity, relations: [] },\n        ]);\n        const response = await entitiesCatalog.entities({\n          filter: basicEntityFilter({ 'metadata.uid': result.entityId }),\n        });\n        res.status(200).json(response.entities[0]);\n      })\n      .get('/entities/by-uid/:uid', async (req, res) => {\n        const { uid } = req.params;\n        const { entities } = await entitiesCatalog.entities({\n          filter: basicEntityFilter({ 'metadata.uid': uid }),\n        });\n        if (!entities.length) {\n          throw new NotFoundError(`No entity with uid ${uid}`);\n        }\n        res.status(200).json(entities[0]);\n      })\n      .delete('/entities/by-uid/:uid', async (req, res) => {\n        const { uid } = req.params;\n        await entitiesCatalog.removeEntityByUid(uid);\n        res.status(204).end();\n      })\n      .get('/entities/by-name/:kind/:namespace/:name', async (req, res) => {\n        const { kind, namespace, name } = req.params;\n        const { entities } = await entitiesCatalog.entities({\n          filter: basicEntityFilter({\n            kind: kind,\n            'metadata.namespace': namespace,\n            'metadata.name': name,\n          }),\n        });\n        if (!entities.length) {\n          throw new NotFoundError(\n            `No entity named '${name}' found, with kind '${kind}' in namespace '${namespace}'`,\n          );\n        }\n        res.status(200).json(entities[0]);\n      });\n  }\n\n  if (higherOrderOperation) {\n    router.post('/locations', async (req, res) => {\n      const input = await validateRequestBody(req, locationSpecSchema);\n      const dryRun = yn(req.query.dryRun, { default: false });\n\n      // when in dryRun addLocation is effectively a read operation so we don't\n      // need to disallow readonly\n      if (!dryRun) {\n        disallowReadonlyMode(readonlyEnabled);\n      }\n\n      const output = await higherOrderOperation.addLocation(input, { dryRun });\n      res.status(201).json(output);\n    });\n  }\n\n  if (locationsCatalog) {\n    router\n      .get('/locations', async (_req, res) => {\n        const output = await locationsCatalog.locations();\n        res.status(200).json(output);\n      })\n      .get('/locations/:id/history', async (req, res) => {\n        const { id } = req.params;\n        const output = await locationsCatalog.locationHistory(id);\n        res.status(200).json(output);\n      })\n      .get('/locations/:id', async (req, res) => {\n        const { id } = req.params;\n        const output = await locationsCatalog.location(id);\n        res.status(200).json(output);\n      })\n      .delete('/locations/:id', async (req, res) => {\n        disallowReadonlyMode(readonlyEnabled);\n\n        const { id } = req.params;\n        await locationsCatalog.removeLocation(id);\n        res.status(204).end();\n      });\n  }\n\n  if (locationAnalyzer) {\n    router.post('/analyze-location', async (req, res) => {\n      const input = await validateRequestBody(req, analyzeLocationSchema);\n      const output = await locationAnalyzer.analyzeLocation(input);\n      res.status(200).json(output);\n    });\n  }\n\n  router.use(errorHandler());\n  return router;\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  LocationSpec,\n  LocationEntityV1alpha1,\n  LOCATION_ANNOTATION,\n  ORIGIN_LOCATION_ANNOTATION,\n  stringifyEntityRef,\n  stringifyLocationReference,\n} from '@backstage/catalog-model';\nimport { createHash } from 'crypto';\n\nexport function locationSpecToMetadataName(location: LocationSpec) {\n  const hash = createHash('sha1')\n    .update(`${location.type}:${location.target}`)\n    .digest('hex');\n\n  return `generated-${hash}`;\n}\n\nexport function locationSpecToLocationEntity(\n  location: LocationSpec,\n  parentEntity?: Entity,\n): LocationEntityV1alpha1 {\n  let ownLocation: string;\n  let originLocation: string;\n  if (parentEntity) {\n    const maybeOwnLocation =\n      parentEntity.metadata.annotations?.[LOCATION_ANNOTATION];\n    if (!maybeOwnLocation) {\n      throw new Error(\n        `Parent entity '${stringifyEntityRef(\n          parentEntity,\n        )}' of location '${stringifyLocationReference(\n          location,\n        )}' does not have a location annotation`,\n      );\n    }\n    ownLocation = maybeOwnLocation;\n    const maybeOriginLocation =\n      parentEntity.metadata.annotations?.[ORIGIN_LOCATION_ANNOTATION];\n    if (!maybeOriginLocation) {\n      throw new Error(\n        `Parent entity '${stringifyEntityRef(\n          parentEntity,\n        )}' of location '${stringifyLocationReference(\n          location,\n        )}' does not have an origin location annotation`,\n      );\n    }\n    originLocation = maybeOriginLocation;\n  } else {\n    ownLocation = stringifyLocationReference(location);\n    originLocation = ownLocation;\n  }\n\n  const result: LocationEntityV1alpha1 = {\n    apiVersion: 'backstage.io/v1alpha1',\n    kind: 'Location',\n    metadata: {\n      name: locationSpecToMetadataName(location),\n      annotations: {\n        [LOCATION_ANNOTATION]: ownLocation,\n        [ORIGIN_LOCATION_ANNOTATION]: originLocation,\n      },\n    },\n    spec: {\n      type: location.type,\n      target: location.target,\n    },\n  };\n\n  return result;\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport path from 'path';\nimport { EntityProvider, EntityProviderConnection } from './types';\nimport { locationSpecToLocationEntity } from './util';\n\nexport class ConfigLocationEntityProvider implements EntityProvider {\n  private connection: EntityProviderConnection | undefined;\n\n  constructor(private readonly config: Config) {}\n\n  getProviderName(): string {\n    return 'ConfigLocationProvider';\n  }\n\n  async connect(connection: EntityProviderConnection): Promise<void> {\n    this.connection = connection;\n\n    const locationConfigs =\n      this.config.getOptionalConfigArray('catalog.locations') ?? [];\n\n    const entities = locationConfigs.map(location => {\n      const type = location.getString('type');\n      const target = location.getString('target');\n      return locationSpecToLocationEntity({\n        type,\n        target: type === 'file' ? path.resolve(target) : target,\n      });\n    });\n\n    await this.connection.applyMutation({\n      type: 'full',\n      entities,\n    });\n  }\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity, stringifyEntityRef } from '@backstage/catalog-model';\nimport { JsonObject } from '@backstage/config';\nimport { ConflictError, NotFoundError } from '@backstage/errors';\nimport { Knex } from 'knex';\nimport lodash from 'lodash';\nimport { v4 as uuid } from 'uuid';\nimport type { Logger } from 'winston';\nimport { Transaction } from '../../database';\nimport {\n  AddUnprocessedEntitiesOptions,\n  GetProcessableEntitiesResult,\n  ProcessingDatabase,\n  RefreshStateItem,\n  ReplaceUnprocessedEntitiesOptions,\n  UpdateProcessedEntityOptions,\n} from './types';\n\nexport type DbRefreshStateRow = {\n  entity_id: string;\n  entity_ref: string;\n  unprocessed_entity: string;\n  processed_entity?: string;\n  cache?: string;\n  next_update_at: string;\n  last_discovery_at: string; // remove?\n  errors?: string;\n};\n\nexport type DbRelationsRow = {\n  originating_entity_id: string;\n  source_entity_ref: string;\n  target_entity_ref: string;\n  type: string;\n};\n\nexport type DbRefreshStateReferencesRow = {\n  source_key?: string;\n  source_entity_ref?: string;\n  target_entity_ref: string;\n};\n\n// The number of items that are sent per batch to the database layer, when\n// doing .batchInsert calls to knex. This needs to be low enough to not cause\n// errors in the underlying engine due to exceeding query limits, but large\n// enough to get the speed benefits.\nconst BATCH_SIZE = 50;\n\nexport class DefaultProcessingDatabase implements ProcessingDatabase {\n  constructor(\n    private readonly database: Knex,\n    private readonly logger: Logger,\n  ) {}\n\n  async updateProcessedEntity(\n    txOpaque: Transaction,\n    options: UpdateProcessedEntityOptions,\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n    const {\n      id,\n      processedEntity,\n      state,\n      errors,\n      relations,\n      deferredEntities,\n    } = options;\n\n    const refreshResult = await tx<DbRefreshStateRow>('refresh_state')\n      .update({\n        processed_entity: JSON.stringify(processedEntity),\n        cache: JSON.stringify(state),\n        errors,\n      })\n      .where('entity_id', id);\n    if (refreshResult === 0) {\n      throw new NotFoundError(`Processing state not found for ${id}`);\n    }\n\n    // Schedule all deferred entities for future processing.\n    await this.addUnprocessedEntities(tx, {\n      entities: deferredEntities,\n      entityRef: stringifyEntityRef(processedEntity),\n    });\n\n    // Update fragments\n\n    // Delete old relations\n    await tx<DbRelationsRow>('relations')\n      .where({ originating_entity_id: id })\n      .delete();\n\n    // Batch insert new relations\n    const relationRows: DbRelationsRow[] = relations.map(\n      ({ source, target, type }) => ({\n        originating_entity_id: id,\n        source_entity_ref: stringifyEntityRef(source),\n        target_entity_ref: stringifyEntityRef(target),\n        type,\n      }),\n    );\n    await tx.batchInsert(\n      'relations',\n      this.deduplicateRelations(relationRows),\n      BATCH_SIZE,\n    );\n  }\n\n  async updateProcessedEntityErrors(\n    txOpaque: Transaction,\n    options: UpdateProcessedEntityOptions,\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n    const { id, errors } = options;\n\n    await tx<DbRefreshStateRow>('refresh_state')\n      .update({\n        errors,\n      })\n      .where('entity_id', id);\n  }\n\n  private deduplicateRelations(rows: DbRelationsRow[]): DbRelationsRow[] {\n    return lodash.uniqBy(\n      rows,\n      r => `${r.source_entity_ref}:${r.target_entity_ref}:${r.type}`,\n    );\n  }\n\n  private async createDelta(\n    tx: Knex.Transaction,\n    options: ReplaceUnprocessedEntitiesOptions,\n  ): Promise<{ toAdd: Entity[]; toRemove: string[] }> {\n    if (options.type === 'delta') {\n      return {\n        toAdd: options.added,\n        toRemove: options.removed.map(e => stringifyEntityRef(e)),\n      };\n    }\n\n    const oldRefs = await tx<DbRefreshStateReferencesRow>(\n      'refresh_state_references',\n    )\n      .where({ source_key: options.sourceKey })\n      .select('target_entity_ref')\n      .then(rows => rows.map(r => r.target_entity_ref));\n\n    const items = options.items.map(entity => ({\n      entity,\n      ref: stringifyEntityRef(entity),\n    }));\n\n    const oldRefsSet = new Set(oldRefs);\n    const newRefsSet = new Set(items.map(item => item.ref));\n    const toAdd = items.filter(item => !oldRefsSet.has(item.ref));\n    const toRemove = oldRefs.filter(ref => !newRefsSet.has(ref));\n\n    return { toAdd: toAdd.map(({ entity }) => entity), toRemove };\n  }\n\n  async replaceUnprocessedEntities(\n    txOpaque: Transaction,\n    options: ReplaceUnprocessedEntitiesOptions,\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const { toAdd, toRemove } = await this.createDelta(tx, options);\n\n    if (toRemove.length) {\n      // TODO(freben): Batch split, to not hit variable limits?\n      /*\n      WITH RECURSIVE\n        -- All the nodes that can be reached downwards from our root\n        descendants(root_id, entity_ref) AS (\n          SELECT id, target_entity_ref\n          FROM refresh_state_references\n          WHERE source_key = \"R1\" AND target_entity_ref = \"A\"\n          UNION\n          SELECT descendants.root_id, target_entity_ref\n          FROM descendants\n          JOIN refresh_state_references ON source_entity_ref = descendants.entity_ref\n        ),\n        -- All the nodes that can be reached upwards from the descendants\n        ancestors(root_id, via_entity_ref, to_entity_ref) AS (\n          SELECT CAST(NULL as INT), entity_ref, entity_ref\n          FROM descendants\n          UNION\n          SELECT\n            CASE WHEN source_key IS NOT NULL THEN id ELSE NULL END,\n            source_entity_ref,\n            ancestors.to_entity_ref\n          FROM ancestors\n          JOIN refresh_state_references ON target_entity_ref = ancestors.via_entity_ref\n        )\n      -- Start out with all of the descendants\n      SELECT descendants.entity_ref\n      FROM descendants\n      -- Expand with all ancestors that point to those, but aren't the current root\n      LEFT OUTER JOIN ancestors\n        ON ancestors.to_entity_ref = descendants.entity_ref\n        AND ancestors.root_id IS NOT NULL\n        AND ancestors.root_id != descendants.root_id\n      -- Exclude all lines that had such a foreign ancestor\n      WHERE ancestors.root_id IS NULL;\n      */\n      const removedCount = await tx<DbRefreshStateRow>('refresh_state')\n        .whereIn('entity_ref', function orphanedEntityRefs(orphans) {\n          return (\n            orphans\n              // All the nodes that can be reached downwards from our root\n              .withRecursive('descendants', function descendants(outer) {\n                return outer\n                  .select({ root_id: 'id', entity_ref: 'target_entity_ref' })\n                  .from('refresh_state_references')\n                  .where('source_key', options.sourceKey)\n                  .whereIn('target_entity_ref', toRemove)\n                  .union(function recursive(inner) {\n                    return inner\n                      .select({\n                        root_id: 'descendants.root_id',\n                        entity_ref:\n                          'refresh_state_references.target_entity_ref',\n                      })\n                      .from('descendants')\n                      .join('refresh_state_references', {\n                        'descendants.entity_ref':\n                          'refresh_state_references.source_entity_ref',\n                      });\n                  });\n              })\n              // All the nodes that can be reached upwards from the descendants\n              .withRecursive('ancestors', function ancestors(outer) {\n                return outer\n                  .select({\n                    root_id: tx.raw('CAST(NULL as INT)', []),\n                    via_entity_ref: 'entity_ref',\n                    to_entity_ref: 'entity_ref',\n                  })\n                  .from('descendants')\n                  .union(function recursive(inner) {\n                    return inner\n                      .select({\n                        root_id: tx.raw(\n                          'CASE WHEN source_key IS NOT NULL THEN id ELSE NULL END',\n                          [],\n                        ),\n                        via_entity_ref: 'source_entity_ref',\n                        to_entity_ref: 'ancestors.to_entity_ref',\n                      })\n                      .from('ancestors')\n                      .join('refresh_state_references', {\n                        target_entity_ref: 'ancestors.via_entity_ref',\n                      });\n                  });\n              })\n              // Start out with all of the descendants\n              .select('descendants.entity_ref')\n              .from('descendants')\n              // Expand with all ancestors that point to those, but aren't the current root\n              .leftOuterJoin('ancestors', function keepaliveRoots() {\n                this.on(\n                  'ancestors.to_entity_ref',\n                  '=',\n                  'descendants.entity_ref',\n                );\n                this.andOnNotNull('ancestors.root_id');\n                this.andOn('ancestors.root_id', '!=', 'descendants.root_id');\n              })\n              .whereNull('ancestors.root_id')\n          );\n        })\n        .delete();\n\n      await tx<DbRefreshStateReferencesRow>('refresh_state_references')\n        .where('source_key', '=', options.sourceKey)\n        .whereIn('target_entity_ref', toRemove)\n        .delete();\n\n      this.logger.debug(\n        `removed, ${removedCount} entities: ${JSON.stringify(toRemove)}`,\n      );\n    }\n\n    if (toAdd.length) {\n      const state: Knex.DbRecord<DbRefreshStateRow>[] = toAdd.map(entity => ({\n        entity_id: uuid(),\n        entity_ref: stringifyEntityRef(entity),\n        unprocessed_entity: JSON.stringify(entity),\n        errors: '',\n        next_update_at: tx.fn.now(),\n        last_discovery_at: tx.fn.now(),\n      }));\n\n      const stateReferences: DbRefreshStateReferencesRow[] = toAdd.map(\n        entity => ({\n          source_key: options.sourceKey,\n          target_entity_ref: stringifyEntityRef(entity),\n        }),\n      );\n      // TODO(freben): Concurrency? If we did these one by one, a .onConflict().merge would have made sense\n      await tx.batchInsert('refresh_state', state, BATCH_SIZE);\n      await tx.batchInsert(\n        'refresh_state_references',\n        stateReferences,\n        BATCH_SIZE,\n      );\n    }\n  }\n\n  async addUnprocessedEntities(\n    txOpaque: Transaction,\n    options: AddUnprocessedEntitiesOptions,\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const stateRows = options.entities.map(\n      entity =>\n        ({\n          entity_id: uuid(),\n          entity_ref: stringifyEntityRef(entity),\n          unprocessed_entity: JSON.stringify(entity),\n          errors: '',\n          next_update_at: tx.fn.now(),\n          last_discovery_at: tx.fn.now(),\n        } as Knex.DbRecord<DbRefreshStateRow>),\n    );\n    const stateReferenceRows = stateRows.map(\n      stateRow =>\n        ({\n          source_entity_ref: options.entityRef,\n          target_entity_ref: stateRow.entity_ref,\n        } as Knex.DbRecord<DbRefreshStateReferencesRow>),\n    );\n\n    // Upsert all of the unprocessed entities into the refresh_state table, by\n    // their entity ref.\n    // TODO(freben): Can this be batched somehow?\n    for (const row of stateRows) {\n      await tx<DbRefreshStateRow>('refresh_state')\n        .insert(row)\n        .onConflict('entity_ref')\n        .merge(['unprocessed_entity', 'last_discovery_at']);\n    }\n\n    // Replace all references for the originating entity before creating new ones\n    await tx<DbRefreshStateReferencesRow>('refresh_state_references')\n      .where({ source_entity_ref: options.entityRef })\n      .delete();\n    await tx.batchInsert(\n      'refresh_state_references',\n      stateReferenceRows,\n      BATCH_SIZE,\n    );\n  }\n\n  async getProcessableEntities(\n    txOpaque: Transaction,\n    request: { processBatchSize: number },\n  ): Promise<GetProcessableEntitiesResult> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const items = await tx<DbRefreshStateRow>('refresh_state')\n      .select()\n      .where('next_update_at', '<=', tx.fn.now())\n      .limit(request.processBatchSize)\n      .orderBy('next_update_at', 'asc');\n\n    await tx<DbRefreshStateRow>('refresh_state')\n      .whereIn(\n        'entity_ref',\n        items.map(i => i.entity_ref),\n      )\n      .update({\n        next_update_at:\n          tx.client.config.client === 'sqlite3'\n            ? tx.raw(`datetime('now', ?)`, [`100 seconds`])\n            : tx.raw(`now() + interval '100 seconds'`),\n      });\n\n    return {\n      items: items.map(\n        i =>\n          ({\n            id: i.entity_id,\n            entityRef: i.entity_ref,\n            unprocessedEntity: JSON.parse(i.unprocessed_entity) as Entity,\n            processedEntity: i.processed_entity\n              ? (JSON.parse(i.processed_entity) as Entity)\n              : undefined,\n            nextUpdateAt: i.next_update_at,\n            lastDiscoveryAt: i.last_discovery_at,\n            state: i.cache\n              ? JSON.parse(i.cache)\n              : new Map<string, JsonObject>(),\n            errors: i.errors,\n          } as RefreshStateItem),\n      ),\n    };\n  }\n\n  async transaction<T>(fn: (tx: Transaction) => Promise<T>): Promise<T> {\n    try {\n      let result: T | undefined = undefined;\n\n      await this.database.transaction(\n        async tx => {\n          // We can't return here, as knex swallows the return type in case the transaction is rolled back:\n          // https://github.com/knex/knex/blob/e37aeaa31c8ef9c1b07d2e4d3ec6607e557d800d/lib/transaction.js#L136\n          result = await fn(tx);\n        },\n        {\n          // If we explicitly trigger a rollback, don't fail.\n          doNotRejectOnRollback: true,\n        },\n      );\n\n      return result!;\n    } catch (e) {\n      this.logger.debug(`Error during transaction, ${e}`);\n\n      if (\n        /SQLITE_CONSTRAINT: UNIQUE/.test(e.message) ||\n        /unique constraint/.test(e.message)\n      ) {\n        throw new ConflictError(`Rejected due to a conflicting entity`, e);\n      }\n\n      throw e;\n    }\n  }\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  entityEnvelopeSchemaValidator,\n  stringifyEntityRef,\n} from '@backstage/catalog-model';\nimport { serializeError } from '@backstage/errors';\nimport { Logger } from 'winston';\nimport { ProcessingDatabase } from './database/types';\nimport { Stitcher } from './Stitcher';\nimport {\n  CatalogProcessingEngine,\n  CatalogProcessingOrchestrator,\n  EntityProvider,\n  EntityProviderConnection,\n  EntityProviderMutation,\n} from './types';\n\nclass Connection implements EntityProviderConnection {\n  readonly validateEntityEnvelope = entityEnvelopeSchemaValidator();\n\n  constructor(\n    private readonly config: {\n      processingDatabase: ProcessingDatabase;\n      id: string;\n    },\n  ) {}\n\n  async applyMutation(mutation: EntityProviderMutation): Promise<void> {\n    const db = this.config.processingDatabase;\n\n    if (mutation.type === 'full') {\n      this.check(mutation.entities);\n      await db.transaction(async tx => {\n        await db.replaceUnprocessedEntities(tx, {\n          sourceKey: this.config.id,\n          type: 'full',\n          items: mutation.entities,\n        });\n      });\n      return;\n    }\n\n    this.check(mutation.added);\n    this.check(mutation.removed);\n    await db.transaction(async tx => {\n      await db.replaceUnprocessedEntities(tx, {\n        sourceKey: this.config.id,\n        type: 'delta',\n        added: mutation.added,\n        removed: mutation.removed,\n      });\n    });\n  }\n\n  private check(entities: Entity[]) {\n    for (const entity of entities) {\n      try {\n        this.validateEntityEnvelope(entity);\n      } catch (e) {\n        throw new TypeError(`Malformed entity envelope, ${e}`);\n      }\n    }\n  }\n}\n\nexport class DefaultCatalogProcessingEngine implements CatalogProcessingEngine {\n  private running = false;\n\n  constructor(\n    private readonly logger: Logger,\n    private readonly entityProviders: EntityProvider[],\n    private readonly processingDatabase: ProcessingDatabase,\n    private readonly orchestrator: CatalogProcessingOrchestrator,\n    private readonly stitcher: Stitcher,\n  ) {}\n\n  async start() {\n    for (const provider of this.entityProviders) {\n      await provider.connect(\n        new Connection({\n          processingDatabase: this.processingDatabase,\n          id: provider.getProviderName(),\n        }),\n      );\n    }\n    this.running = true;\n    this.run();\n  }\n\n  private async run() {\n    while (this.running) {\n      try {\n        // TODO: We want to disconnect the queue popping and message processing\n        // so that if the queue popping fails we exponentially back off in order to give the DB room to sort itself out.\n        await this.process();\n      } catch (e) {\n        this.logger.warn('Processing failed with:', e);\n        // TODO: this can be a little smarter as mentioned in the above comment.\n        // But for now, if something fails, wait a brief time to pick up the next message.\n        await this.wait();\n      }\n    }\n  }\n\n  private async process() {\n    const { items } = await this.processingDatabase.transaction(async tx => {\n      return this.processingDatabase.getProcessableEntities(tx, {\n        processBatchSize: 1,\n      });\n    });\n\n    if (!items.length) {\n      // No items to process, wait and try again.\n      await this.wait();\n      return;\n    }\n\n    // TODO: replace Promise.all with something more sophisticated for parallel processing.\n    await Promise.all(\n      items.map(async item => {\n        const { id, state, unprocessedEntity, entityRef } = item;\n        const result = await this.orchestrator.process({\n          entity: unprocessedEntity,\n          state,\n        });\n\n        for (const error of result.errors) {\n          // TODO(freben): Try to extract the location out of the unprocessed\n          // entity and add as meta to the log lines\n          this.logger.warn(error.message, {\n            entity: entityRef,\n          });\n        }\n        const errorsString = JSON.stringify(\n          result.errors.map(e => serializeError(e)),\n        );\n\n        // If the result was marked as not OK, it signals that some part of the\n        // processing pipeline threw an exception. This can happen both as part of\n        // non-catastrophic things such as due to validation errors, as well as if\n        // something fatal happens inside the processing for other reasons. In any\n        // case, this means we can't trust that anything in the output is okay. So\n        // just store the errors and trigger a stich so that they become visible to\n        // the outside.\n        if (!result.ok) {\n          await this.processingDatabase.transaction(async tx => {\n            await this.processingDatabase.updateProcessedEntityErrors(tx, {\n              id,\n              errors: errorsString,\n            });\n          });\n          await this.stitcher.stitch(\n            new Set([stringifyEntityRef(unprocessedEntity)]),\n          );\n          return;\n        }\n\n        result.completedEntity.metadata.uid = id;\n        await this.processingDatabase.transaction(async tx => {\n          await this.processingDatabase.updateProcessedEntity(tx, {\n            id,\n            processedEntity: result.completedEntity,\n            state: result.state,\n            errors: errorsString,\n            relations: result.relations,\n            deferredEntities: result.deferredEntities,\n          });\n        });\n\n        const setOfThingsToStitch = new Set<string>([\n          stringifyEntityRef(result.completedEntity),\n          ...result.relations.map(relation =>\n            stringifyEntityRef(relation.source),\n          ),\n        ]);\n        await this.stitcher.stitch(setOfThingsToStitch);\n      }),\n    );\n  }\n\n  private async wait() {\n    await new Promise<void>(resolve => setTimeout(resolve, 1000));\n  }\n\n  async stop() {\n    this.running = false;\n  }\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  entityEnvelopeSchemaValidator,\n  EntityPolicy,\n  EntityRelationSpec,\n  entitySchemaValidator,\n  LocationEntity,\n  LocationSpec,\n  LOCATION_ANNOTATION,\n  ORIGIN_LOCATION_ANNOTATION,\n  parseLocationReference,\n  stringifyEntityRef,\n  stringifyLocationReference,\n} from '@backstage/catalog-model';\nimport { ConflictError, InputError } from '@backstage/errors';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport path from 'path';\nimport { Logger } from 'winston';\nimport {\n  CatalogProcessor,\n  CatalogProcessorParser,\n  CatalogProcessorResult,\n} from '../ingestion/processors';\nimport * as results from '../ingestion/processors/results';\nimport {\n  CatalogProcessingOrchestrator,\n  EntityProcessingRequest,\n  EntityProcessingResult,\n} from './types';\nimport { locationSpecToLocationEntity } from './util';\n\nconst validateEntity = entitySchemaValidator();\nconst validateEntityEnvelope = entityEnvelopeSchemaValidator();\n\nfunction isLocationEntity(entity: Entity): entity is LocationEntity {\n  return entity.kind === 'Location';\n}\n\nfunction getEntityLocationRef(entity: Entity): string {\n  const ref = entity.metadata.annotations?.[LOCATION_ANNOTATION];\n  if (!ref) {\n    const entityRef = stringifyEntityRef(entity);\n    throw new InputError(`Entity '${entityRef}' does not have a location`);\n  }\n  return ref;\n}\n\nfunction getEntityOriginLocationRef(entity: Entity): string {\n  const ref = entity.metadata.annotations?.[ORIGIN_LOCATION_ANNOTATION];\n  if (!ref) {\n    const entityRef = stringifyEntityRef(entity);\n    throw new InputError(\n      `Entity '${entityRef}' does not have an origin location`,\n    );\n  }\n  return ref;\n}\n\nfunction toAbsoluteUrl(\n  integrations: ScmIntegrationRegistry,\n  base: LocationSpec,\n  type: string,\n  target: string,\n): string {\n  if (base.type !== type) {\n    return target;\n  }\n  try {\n    if (type === 'file') {\n      if (target.startsWith('.')) {\n        return path.join(path.dirname(base.target), target);\n      }\n      return target;\n    } else if (type === 'url') {\n      return integrations.resolveUrl({ url: target, base: base.target });\n    }\n    return target;\n  } catch (e) {\n    return target;\n  }\n}\n\nexport class DefaultCatalogProcessingOrchestrator\n  implements CatalogProcessingOrchestrator {\n  constructor(\n    private readonly options: {\n      processors: CatalogProcessor[];\n      integrations: ScmIntegrationRegistry;\n      logger: Logger;\n      parser: CatalogProcessorParser;\n      policy: EntityPolicy;\n    },\n  ) {}\n\n  async process(\n    request: EntityProcessingRequest,\n  ): Promise<EntityProcessingResult> {\n    // TODO: implement dryRun/eager\n    return this.processSingleEntity(request.entity);\n  }\n\n  private async processSingleEntity(\n    unprocessedEntity: Entity,\n  ): Promise<EntityProcessingResult> {\n    const emitter = createEmitter(this.options.logger, unprocessedEntity);\n    try {\n      // This will be checked and mutated step by step below\n      let entity: Entity = unprocessedEntity;\n\n      // NOTE: At this early point, we can only rely on the envelope having to\n      // be valid; full entity + kind validation happens after the (potentially\n      // mutative) pre-steps. This means that the code below can't make a lot\n      // of assumptions about the data despite it using the Entity type.\n      try {\n        validateEntityEnvelope(entity);\n      } catch (e) {\n        throw new InputError(\n          `Entity envelope failed validation before processing`,\n          e,\n        );\n      }\n\n      const entityRef = stringifyEntityRef(entity);\n      // TODO: which one do we actually use here? source-location? - maybe probably doesn't exist yet?\n      const locationRef = getEntityLocationRef(entity);\n      const location = parseLocationReference(locationRef);\n      const originLocation = parseLocationReference(\n        getEntityOriginLocationRef(entity),\n      );\n\n      // Pre-process phase, used to populate entities with data that is required during main processing step\n      for (const processor of this.options.processors) {\n        if (processor.preProcessEntity) {\n          try {\n            entity = await processor.preProcessEntity(\n              entity,\n              location,\n              emitter.emit,\n              originLocation,\n            );\n          } catch (e) {\n            throw new InputError(\n              `Processor ${processor.constructor.name} threw an error while preprocessing`,\n              e,\n            );\n          }\n        }\n      }\n\n      // Enforce entity policies making sure that entities conform to a general schema\n      let policyEnforcedEntity: Entity | undefined;\n      try {\n        policyEnforcedEntity = await this.options.policy.enforce(entity);\n      } catch (e) {\n        throw new InputError('Policy check failed', e);\n      }\n      if (!policyEnforcedEntity) {\n        throw new Error('Policy unexpectedly returned no data');\n      }\n      entity = policyEnforcedEntity;\n\n      // Validate that the end result is a valid Entity at all\n      try {\n        validateEntity(entity);\n      } catch (e) {\n        throw new ConflictError(\n          `Entity envelope failed validation after preprocessing`,\n          e,\n        );\n      }\n\n      // Validate the given entity kind against its schema\n      let didValidate = false;\n      for (const processor of this.options.processors) {\n        if (processor.validateEntityKind) {\n          try {\n            didValidate = await processor.validateEntityKind(entity);\n            if (didValidate) {\n              break;\n            }\n          } catch (e) {\n            throw new InputError(\n              `Processor ${processor.constructor.name} threw an error while validating the entity`,\n              e,\n            );\n          }\n        }\n      }\n      if (!didValidate) {\n        throw new InputError(\n          'No processor recognized the entity as valid, possibly caused by a foreign kind or apiVersion',\n        );\n      }\n\n      // Double check that none of the previous steps tried to change something\n      // related to the entity ref, which would break downstream\n      if (stringifyEntityRef(entity) !== entityRef) {\n        throw new ConflictError(\n          'Fatal: The entity kind, namespace, or name changed during processing',\n        );\n      }\n\n      // Backwards compatible processing of location entities\n      if (isLocationEntity(entity)) {\n        const { type = location.type } = entity.spec;\n        const targets = new Array<string>();\n        if (entity.spec.target) {\n          targets.push(entity.spec.target);\n        }\n        if (entity.spec.targets) {\n          targets.push(...entity.spec.targets);\n        }\n\n        for (const maybeRelativeTarget of targets) {\n          if (type === 'file' && maybeRelativeTarget.endsWith(path.sep)) {\n            emitter.emit(\n              results.inputError(\n                location,\n                `LocationEntityProcessor cannot handle ${type} type location with target ${location.target} that ends with a path separator`,\n              ),\n            );\n            continue;\n          }\n          const target = toAbsoluteUrl(\n            this.options.integrations,\n            location,\n            type,\n            maybeRelativeTarget,\n          );\n\n          let didRead = false;\n          for (const processor of this.options.processors) {\n            if (processor.readLocation) {\n              try {\n                const read = await processor.readLocation(\n                  {\n                    type,\n                    target,\n                    presence: 'required',\n                  },\n                  false,\n                  emitter.emit,\n                  this.options.parser,\n                );\n                if (read) {\n                  didRead = true;\n                  break;\n                }\n              } catch (e) {\n                throw new InputError(\n                  `Processor ${processor.constructor.name} threw an error while reading ${type}:${target}`,\n                  e,\n                );\n              }\n            }\n          }\n          if (!didRead) {\n            throw new InputError(\n              `No processor was able to handle reading of ${type}:${target}`,\n            );\n          }\n        }\n      }\n\n      // Main processing step of the entity\n      for (const processor of this.options.processors) {\n        if (processor.postProcessEntity) {\n          try {\n            entity = await processor.postProcessEntity(\n              entity,\n              location,\n              emitter.emit,\n            );\n          } catch (e) {\n            throw new InputError(\n              `Processor ${processor.constructor.name} threw an error while postprocessing`,\n              e,\n            );\n          }\n        }\n      }\n\n      return {\n        ...emitter.results(),\n        completedEntity: entity,\n        state: new Map(),\n        ok: true,\n      };\n    } catch (error) {\n      this.options.logger.warn(error.message);\n      return {\n        ok: false,\n        errors: emitter.results().errors.concat(error),\n      };\n    }\n  }\n}\n\nfunction createEmitter(logger: Logger, parentEntity: Entity) {\n  let done = false;\n\n  const errors = new Array<Error>();\n  const relations = new Array<EntityRelationSpec>();\n  const deferredEntities = new Array<Entity>();\n\n  const emit = (i: CatalogProcessorResult) => {\n    if (done) {\n      logger.warn(\n        `Item if type ${i.type} was emitted after processing had completed at ${\n          new Error().stack\n        }`,\n      );\n      return;\n    }\n\n    if (i.type === 'entity') {\n      let entity: Entity;\n      try {\n        entity = validateEntityEnvelope(i.entity);\n      } catch (e) {\n        logger.debug(`Envelope validation failed at ${i.location}, ${e}`);\n        errors.push(e);\n        return;\n      }\n\n      // Note that at this point, we have only validated the envelope part of\n      // the entity data. Annotations are not part of that, so we have to be\n      // defensive. If the annotations were malformed (e.g. were not a valid\n      // object), we just skip over this step and let the full entity\n      // validation at the next step of processing catch that.\n      const annotations = entity.metadata.annotations || {};\n      if (typeof annotations === 'object' && !Array.isArray(annotations)) {\n        const originLocation = getEntityOriginLocationRef(parentEntity);\n        const location = stringifyLocationReference(i.location);\n        entity = {\n          ...entity,\n          metadata: {\n            ...entity.metadata,\n            annotations: {\n              ...annotations,\n              [ORIGIN_LOCATION_ANNOTATION]: originLocation,\n              [LOCATION_ANNOTATION]: location,\n            },\n          },\n        };\n      }\n\n      deferredEntities.push(entity);\n    } else if (i.type === 'location') {\n      deferredEntities.push(\n        locationSpecToLocationEntity(i.location, parentEntity),\n      );\n    } else if (i.type === 'relation') {\n      relations.push(i.relation);\n    } else if (i.type === 'error') {\n      errors.push(i.error);\n    }\n  };\n\n  return {\n    emit,\n    results() {\n      done = true;\n      return {\n        errors,\n        relations,\n        deferredEntities,\n      };\n    },\n  };\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport {\n  LocationSpec,\n  Location,\n  Entity,\n  LOCATION_ANNOTATION,\n  ORIGIN_LOCATION_ANNOTATION,\n} from '@backstage/catalog-model';\nimport {\n  LocationService,\n  LocationStore,\n  CatalogProcessingOrchestrator,\n} from './types';\nimport { locationSpecToMetadataName } from './util';\n\nexport class DefaultLocationService implements LocationService {\n  constructor(\n    private readonly store: LocationStore,\n    private readonly orchestrator: CatalogProcessingOrchestrator,\n  ) {}\n\n  async createLocation(\n    spec: LocationSpec,\n    dryRun: boolean,\n  ): Promise<{ location: Location; entities: Entity[] }> {\n    if (dryRun) {\n      return this.dryRunCreateLocation(spec);\n    }\n    const location = await this.store.createLocation(spec);\n    return { location, entities: [] };\n  }\n\n  listLocations(): Promise<Location[]> {\n    return this.store.listLocations();\n  }\n  getLocation(id: string): Promise<Location> {\n    return this.store.getLocation(id);\n  }\n  deleteLocation(id: string): Promise<void> {\n    return this.store.deleteLocation(id);\n  }\n\n  private async dryRunCreateLocation(\n    spec: LocationSpec,\n  ): Promise<{ location: Location; entities: Entity[] }> {\n    const entity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'Location',\n      metadata: {\n        name: locationSpecToMetadataName({\n          type: spec.type,\n          target: spec.target,\n        }),\n        namespace: 'default',\n        annotations: {\n          [LOCATION_ANNOTATION]: `${spec.type}:${spec.target}`,\n          [ORIGIN_LOCATION_ANNOTATION]: `${spec.type}:${spec.target}`,\n        },\n      },\n      spec: {\n        type: spec.type,\n        target: spec.target,\n      },\n    };\n    const unprocessedEntities: Entity[] = [entity];\n    const entities: Entity[] = [];\n    const state = new Map(); // ignored\n    while (unprocessedEntities.length) {\n      const currentEntity = unprocessedEntities.pop();\n      if (!currentEntity) {\n        continue;\n      }\n      const processed = await this.orchestrator.process({\n        entity: currentEntity,\n        state,\n      });\n\n      if (processed.ok) {\n        unprocessedEntities.push(...processed.deferredEntities);\n        entities.push(processed.completedEntity);\n      } else {\n        throw Error(processed.errors.map(String).join(', '));\n      }\n    }\n\n    return {\n      location: { ...spec, id: `${spec.type}:${spec.target}` },\n      entities,\n    };\n  }\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { LocationSpec, Location } from '@backstage/catalog-model';\nimport {\n  LocationStore,\n  EntityProvider,\n  EntityProviderConnection,\n} from './types';\nimport { v4 as uuid } from 'uuid';\nimport { locationSpecToLocationEntity } from './util';\nimport { ConflictError, NotFoundError } from '@backstage/errors';\nimport { Knex } from 'knex';\n\ntype DbLocationsRow = {\n  id: string;\n  type: string;\n  target: string;\n};\n\nexport class DefaultLocationStore implements LocationStore, EntityProvider {\n  private _connection: EntityProviderConnection | undefined;\n\n  constructor(private readonly db: Knex) {}\n\n  getProviderName(): string {\n    return 'DefaultLocationStore';\n  }\n\n  async createLocation(spec: LocationSpec): Promise<Location> {\n    const location = await this.db.transaction(async tx => {\n      // Attempt to find a previous location matching the spec\n      const previousLocations = await this.locations(tx);\n      // TODO: when location id's are a compilation of spec target we can remove this full\n      // lookup of locations first and just grab the by that instead.\n      const previousLocation = previousLocations.some(\n        l => spec.type === l.type && spec.target === l.target,\n      );\n      if (previousLocation) {\n        throw new ConflictError(\n          `Location ${spec.type}:${spec.target} already exists`,\n        );\n      }\n\n      const inner: DbLocationsRow = {\n        id: uuid(),\n        type: spec.type,\n        target: spec.target,\n      };\n\n      await tx<DbLocationsRow>('locations').insert(inner);\n\n      return inner;\n    });\n\n    await this.connection.applyMutation({\n      type: 'delta',\n      added: [locationSpecToLocationEntity(location)],\n      removed: [],\n    });\n\n    return location;\n  }\n\n  async listLocations(): Promise<Location[]> {\n    return await this.locations();\n  }\n\n  async getLocation(id: string): Promise<Location> {\n    const items = await this.db<DbLocationsRow>('locations')\n      .where({ id })\n      .select();\n\n    if (!items.length) {\n      throw new NotFoundError(`Found no location with ID ${id}`);\n    }\n    return items[0];\n  }\n\n  async deleteLocation(id: string): Promise<void> {\n    if (!this.connection) {\n      throw new Error('location store is not initialized');\n    }\n\n    const deleted = await this.db.transaction(async tx => {\n      const [location] = await tx<DbLocationsRow>('locations')\n        .where({ id })\n        .select();\n\n      if (!location) {\n        throw new NotFoundError(`Found no location with ID ${id}`);\n      }\n\n      await tx<DbLocationsRow>('locations').where({ id }).del();\n      return location;\n    });\n\n    await this.connection.applyMutation({\n      type: 'delta',\n      added: [],\n      removed: [locationSpecToLocationEntity(deleted)],\n    });\n  }\n\n  private get connection(): EntityProviderConnection {\n    if (!this._connection) {\n      throw new Error('location store is not initialized');\n    }\n\n    return this._connection;\n  }\n\n  async connect(connection: EntityProviderConnection): Promise<void> {\n    this._connection = connection;\n\n    const locations = await this.locations();\n\n    const entities = locations.map(location => {\n      return locationSpecToLocationEntity(location);\n    });\n\n    await this.connection.applyMutation({\n      type: 'full',\n      entities,\n    });\n  }\n\n  private async locations(dbOrTx: Knex.Transaction | Knex = this.db) {\n    const locations = await dbOrTx<DbLocationsRow>('locations').select();\n    return (\n      locations\n        // TODO(blam): We should create a mutation to remove this location for everyone\n        // eventually when it's all done and dusted\n        .filter(({ type }) => type !== 'bootstrap')\n        .map(item => ({\n          id: item.id,\n          target: item.target,\n          type: item.type,\n        }))\n    );\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Knex } from 'knex';\nimport { DbFinalEntitiesRow } from './Stitcher';\nimport { EntitiesCatalog } from '../catalog';\nimport { EntitiesRequest, EntitiesResponse } from '../catalog/types';\nimport { DbRefreshStateRow } from './database/DefaultProcessingDatabase';\nimport {\n  DbEntitiesSearchRow,\n  DbPageInfo,\n  EntityPagination,\n} from '../database/types';\nimport { InputError } from '@backstage/errors';\n\nfunction parsePagination(\n  input?: EntityPagination,\n): { limit?: number; offset?: number } {\n  if (!input) {\n    return {};\n  }\n\n  let { limit, offset } = input;\n\n  if (input.after !== undefined) {\n    let cursor;\n    try {\n      const json = Buffer.from(input.after, 'base64').toString('utf8');\n      cursor = JSON.parse(json);\n    } catch {\n      throw new InputError('Malformed after cursor, could not be parsed');\n    }\n    if (cursor.limit !== undefined) {\n      if (!Number.isInteger(cursor.limit)) {\n        throw new InputError('Malformed after cursor, limit was not an number');\n      }\n      limit = cursor.limit;\n    }\n    if (cursor.offset !== undefined) {\n      if (!Number.isInteger(cursor.offset)) {\n        throw new InputError('Malformed after cursor, offset was not a number');\n      }\n      offset = cursor.offset;\n    }\n  }\n\n  return { limit, offset };\n}\n\nfunction stringifyPagination(input: { limit: number; offset: number }) {\n  const json = JSON.stringify({ limit: input.limit, offset: input.offset });\n  const base64 = Buffer.from(json, 'utf8').toString('base64');\n  return base64;\n}\n\nexport class NextEntitiesCatalog implements EntitiesCatalog {\n  constructor(private readonly database: Knex) {}\n\n  async entities(request?: EntitiesRequest): Promise<EntitiesResponse> {\n    const db = this.database;\n\n    let entitiesQuery = db<DbFinalEntitiesRow>('final_entities');\n\n    for (const singleFilter of request?.filter?.anyOf ?? []) {\n      entitiesQuery = entitiesQuery.orWhere(function singleFilterFn() {\n        for (const { key, matchValueIn } of singleFilter.allOf) {\n          // NOTE(freben): This used to be a set of OUTER JOIN, which may seem to\n          // make a lot of sense. However, it had abysmal performance on sqlite\n          // when datasets grew large, so we're using IN instead.\n          const matchQuery = db<DbEntitiesSearchRow>('search')\n            .select('entity_id')\n            .where(function keyFilter() {\n              this.andWhere({ key: key.toLowerCase() });\n              if (matchValueIn) {\n                if (matchValueIn.length === 1) {\n                  this.andWhere({ value: matchValueIn[0].toLowerCase() });\n                } else if (matchValueIn.length > 1) {\n                  this.andWhere(\n                    'value',\n                    'in',\n                    matchValueIn.map(v => v.toLowerCase()),\n                  );\n                }\n              }\n            });\n          this.andWhere('entity_id', 'in', matchQuery);\n        }\n      });\n    }\n\n    // TODO: move final_entities to use entity_ref\n    entitiesQuery = entitiesQuery\n      .select('final_entities.*')\n      .whereNotNull('final_entities.final_entity')\n      .orderBy('entity_id', 'asc');\n\n    const { limit, offset } = parsePagination(request?.pagination);\n    if (limit !== undefined) {\n      entitiesQuery = entitiesQuery.limit(limit + 1);\n    }\n    if (offset !== undefined) {\n      entitiesQuery = entitiesQuery.offset(offset);\n    }\n\n    let rows = await entitiesQuery;\n\n    let pageInfo: DbPageInfo;\n    if (limit === undefined || rows.length <= limit) {\n      pageInfo = { hasNextPage: false };\n    } else {\n      rows = rows.slice(0, -1);\n      pageInfo = {\n        hasNextPage: true,\n        endCursor: stringifyPagination({\n          limit,\n          offset: (offset ?? 0) + limit,\n        }),\n      };\n    }\n\n    return {\n      entities: rows.map(e => JSON.parse(e.final_entity!)),\n      pageInfo,\n    };\n  }\n\n  async removeEntityByUid(uid: string): Promise<void> {\n    await this.database<DbRefreshStateRow>('refresh_state')\n      .where('entity_id', uid)\n      .delete();\n  }\n\n  async batchAddOrUpdateEntities(): Promise<never> {\n    throw new Error('Not implemented');\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  ENTITY_DEFAULT_NAMESPACE,\n  stringifyEntityRef,\n} from '@backstage/catalog-model';\n\nexport type DbSearchRow = {\n  entity_id: string;\n  key: string;\n  value: string | null;\n};\n\n// These are excluded in the generic loop, either because they do not make sense\n// to index, or because they are special-case always inserted whether they are\n// null or not\nconst SPECIAL_KEYS = [\n  'attachments',\n  'relations',\n  'status',\n  'metadata.name',\n  'metadata.namespace',\n  'metadata.uid',\n  'metadata.etag',\n  'metadata.generation',\n];\n\n// The maximum length allowed for search values. These columns are indexed, and\n// database engines do not like to index on massive values. For example,\n// postgres will balk after 8191 byte line sizes.\nconst MAX_KEY_LENGTH = 200;\nconst MAX_VALUE_LENGTH = 200;\n\ntype Kv = {\n  key: string;\n  value: unknown;\n};\n\n// Helper for traversing through a nested structure and outputting a list of\n// path->value entries of the leaves.\n//\n// For example, this yaml structure\n//\n// a: 1\n// b:\n//   c: null\n//   e: [f, g]\n// h:\n//  - i: 1\n//    j: k\n//  - i: 2\n//    j: l\n//\n// will result in\n//\n// \"a\", 1\n// \"b.c\", null\n// \"b.e\": \"f\"\n// \"b.e.f\": true\n// \"b.e\": \"g\"\n// \"b.e.g\": true\n// \"h.i\": 1\n// \"h.j\": \"k\"\n// \"h.i\": 2\n// \"h.j\": \"l\"\nexport function traverse(root: unknown): Kv[] {\n  const output: Kv[] = [];\n\n  function visit(path: string, current: unknown) {\n    if (SPECIAL_KEYS.includes(path)) {\n      return;\n    }\n\n    // empty or scalar\n    if (\n      current === undefined ||\n      current === null ||\n      ['string', 'number', 'boolean'].includes(typeof current)\n    ) {\n      output.push({ key: path, value: current });\n      return;\n    }\n\n    // unknown\n    if (typeof current !== 'object') {\n      return;\n    }\n\n    // array\n    if (Array.isArray(current)) {\n      for (const item of current) {\n        // NOTE(freben): The reason that these are output in two different ways,\n        // is to support use cases where you want to express that MORE than one\n        // tag is present in a list. Since the EntityFilters structure is a\n        // record, you can't have several entries of the same key. Therefore\n        // you will have to match on\n        //\n        // { \"a.b\": [\"true\"], \"a.c\": [\"true\"] }\n        //\n        // rather than\n        //\n        // { \"a\": [\"b\", \"c\"] }\n        //\n        // because the latter means EITHER b or c has to be present.\n        visit(path, item);\n        if (typeof item === 'string') {\n          output.push({ key: `${path}.${item}`, value: true });\n        }\n      }\n      return;\n    }\n\n    // object\n    for (const [key, value] of Object.entries(current!)) {\n      visit(path ? `${path}.${key}` : key, value);\n    }\n  }\n\n  visit('', root);\n\n  return output;\n}\n\n// Translates a number of raw data rows to search table rows\nexport function mapToRows(input: Kv[], entityId: string): DbSearchRow[] {\n  const result: DbSearchRow[] = [];\n\n  for (const { key: rawKey, value: rawValue } of input) {\n    const key = rawKey.toLocaleLowerCase('en-US');\n    if (rawValue === undefined || rawValue === null) {\n      result.push({ entity_id: entityId, key, value: null });\n    } else {\n      const value = String(rawValue).toLocaleLowerCase('en-US');\n      if (key.length <= MAX_KEY_LENGTH && value.length <= MAX_VALUE_LENGTH) {\n        result.push({ entity_id: entityId, key, value });\n      }\n    }\n  }\n\n  return result;\n}\n\n/**\n * Generates all of the search rows that are relevant for this entity.\n *\n * @param entityId The uid of the entity\n * @param entity The entity\n * @returns A list of entity search rows\n */\nexport function buildEntitySearch(\n  entityId: string,\n  entity: Entity,\n): DbSearchRow[] {\n  // Visit the base structure recursively\n  const raw = traverse(entity);\n\n  // Start with some special keys that are always present because you want to\n  // be able to easily search for null specifically\n  raw.push({ key: 'metadata.name', value: entity.metadata.name });\n  raw.push({ key: 'metadata.namespace', value: entity.metadata.namespace });\n  raw.push({ key: 'metadata.uid', value: entity.metadata.uid });\n\n  // Namespace not specified has the default value \"default\", so we want to\n  // match on that as well\n  if (!entity.metadata.namespace) {\n    raw.push({ key: 'metadata.namespace', value: ENTITY_DEFAULT_NAMESPACE });\n  }\n\n  // Visit relations\n  for (const relation of entity.relations ?? []) {\n    raw.push({\n      key: `relations.${relation.type}`,\n      value: stringifyEntityRef(relation.target),\n    });\n  }\n\n  return mapToRows(raw, entityId);\n}\n","/*\n * Copyright 2021 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ENTITY_STATUS_CATALOG_PROCESSING_TYPE } from '@backstage/catalog-client';\nimport {\n  Entity,\n  parseEntityRef,\n  UNSTABLE_EntityStatusItem,\n} from '@backstage/catalog-model';\nimport { SerializedError } from '@backstage/errors';\nimport { createHash } from 'crypto';\nimport stableStringify from 'fast-json-stable-stringify';\nimport { Knex } from 'knex';\nimport { Logger } from 'winston';\nimport { buildEntitySearch, DbSearchRow } from './search';\nimport { v4 as uuid } from 'uuid';\nimport { DbRefreshStateRow } from './database/DefaultProcessingDatabase';\n\n// The number of items that are sent per batch to the database layer, when\n// doing .batchInsert calls to knex. This needs to be low enough to not cause\n// errors in the underlying engine due to exceeding query limits, but large\n// enough to get the speed benefits.\nconst BATCH_SIZE = 50;\n\nexport type DbFinalEntitiesRow = {\n  entity_id: string;\n  hash: string;\n  stitch_ticket: string;\n  final_entity?: string;\n};\n\nfunction generateStableHash(entity: Entity) {\n  return createHash('sha1')\n    .update(stableStringify({ ...entity }))\n    .digest('hex');\n}\n\n/**\n * Performs the act of stitching - to take all of the various outputs from the\n * ingestion process, and stitching them together into the final entity JSON\n * shape.\n */\nexport class Stitcher {\n  constructor(\n    private readonly database: Knex,\n    private readonly logger: Logger,\n  ) {}\n\n  async stitch(entityRefs: Set<string>) {\n    for (const entityRef of entityRefs) {\n      try {\n        const entityResult = await this.database<DbRefreshStateRow>(\n          'refresh_state',\n        )\n          .where({ entity_ref: entityRef })\n          .limit(1)\n          .select('entity_id');\n        if (!entityResult.length) {\n          // Entity does no exist in refresh state table, no stitching required.\n          continue;\n        }\n\n        // Insert stitching ticket that will be compared before inserting the final entity.\n        const ticket = uuid();\n        await this.database<DbFinalEntitiesRow>('final_entities')\n          .insert({\n            entity_id: entityResult[0].entity_id,\n            hash: '',\n            stitch_ticket: ticket,\n          })\n          .onConflict('entity_id')\n          .merge(['stitch_ticket']);\n\n        // Selecting from refresh_state and final_entities should yield exactly\n        // one row (except in abnormal cases where the stitch was invoked for\n        // something that didn't exist at all, in which case it's zero rows).\n        // The join with the temporary incoming_references still gives one row.\n        // The only result set \"expanding\" join is the one with relations, so\n        // the output should be at least one row (if zero or one relations were\n        // found), or at most the same number of rows as relations.\n        const result: Array<{\n          entityId: string;\n          processedEntity?: string;\n          errors: string;\n          incomingReferenceCount: string | number;\n          previousHash?: string;\n          relationType?: string;\n          relationTarget?: string;\n        }> = await this.database\n          .with('incoming_references', function incomingReferences(builder) {\n            return builder\n              .from('refresh_state_references')\n              .where({ target_entity_ref: entityRef })\n              .count({ count: '*' });\n          })\n          .select({\n            entityId: 'refresh_state.entity_id',\n            processedEntity: 'refresh_state.processed_entity',\n            errors: 'refresh_state.errors',\n            incomingReferenceCount: 'incoming_references.count',\n            previousHash: 'final_entities.hash',\n            relationType: 'relations.type',\n            relationTarget: 'relations.target_entity_ref',\n          })\n          .from('refresh_state')\n          .where({ 'refresh_state.entity_ref': entityRef })\n          .crossJoin(this.database.raw('incoming_references'))\n          .leftOuterJoin('final_entities', {\n            'final_entities.entity_id': 'refresh_state.entity_id',\n          })\n          .leftOuterJoin('relations', {\n            'relations.source_entity_ref': 'refresh_state.entity_ref',\n          })\n          .orderBy('relationType', 'asc')\n          .orderBy('relationTarget', 'asc');\n\n        // If there were no rows returned, it would mean that there was no\n        // matching row even in the refresh_state. This can happen for example\n        // if we emit a relation to something that hasn't been ingested yet.\n        // It's safe to ignore this stitch attempt in that case.\n        if (!result.length) {\n          this.logger.error(\n            `Unable to stitch ${entityRef}, item does not exist in refresh state table`,\n          );\n          continue;\n        }\n\n        const {\n          entityId,\n          processedEntity,\n          errors,\n          incomingReferenceCount,\n          previousHash,\n        } = result[0];\n\n        // If there was no processed entity in place, the target hasn't been\n        // through the processing steps yet. It's safe to ignore this stitch\n        // attempt in that case, since another stitch will be triggered when\n        // that processing has finished.\n        if (!processedEntity) {\n          this.logger.debug(\n            `Unable to stitch ${entityRef}, the entity has not yet been processed`,\n          );\n          continue;\n        }\n\n        // Grab the processed entity and stitch all of the relevant data into\n        // it\n        const entity = JSON.parse(processedEntity) as Entity;\n        const isOrphan = Number(incomingReferenceCount) === 0;\n        let statusItems: UNSTABLE_EntityStatusItem[] = [];\n\n        if (isOrphan) {\n          this.logger.debug(`${entityRef} is an orphan`);\n          entity.metadata.annotations = {\n            ...entity.metadata.annotations,\n            ['backstage.io/orphan']: 'true',\n          };\n        }\n        if (errors) {\n          const parsedErrors = JSON.parse(errors) as SerializedError[];\n          if (Array.isArray(parsedErrors) && parsedErrors.length) {\n            statusItems = parsedErrors.map(e => ({\n              type: ENTITY_STATUS_CATALOG_PROCESSING_TYPE,\n              level: 'error',\n              message: `${e.name}: ${e.message}`,\n              error: e,\n            }));\n          }\n        }\n\n        // TODO: entityRef is lower case and should be uppercase in the final\n        // result\n        entity.relations = result\n          .filter(row => row.relationType /* exclude null row, if relevant */)\n          .map(row => ({\n            type: row.relationType!,\n            target: parseEntityRef(row.relationTarget!),\n          }));\n        if (statusItems.length) {\n          entity.status = {\n            ...entity.status,\n            items: [...(entity.status?.items ?? []), ...statusItems],\n          };\n        }\n\n        // If the output entity was actually not changed, just abort\n        const hash = generateStableHash(entity);\n        if (hash === previousHash) {\n          this.logger.debug(`Skipped stitching of ${entityRef}, no changes`);\n          continue;\n        }\n\n        entity.metadata.uid = entityId;\n        entity.metadata.generation = 1;\n        if (!entity.metadata.etag) {\n          // If the original data source did not have its own etag handling,\n          // use the hash as a good-quality etag\n          entity.metadata.etag = hash;\n        }\n\n        const rowsChanged = await this.database<DbFinalEntitiesRow>(\n          'final_entities',\n        )\n          .update({\n            final_entity: JSON.stringify(entity),\n            hash,\n          })\n          .where('entity_id', entityId)\n          .where('stitch_ticket', ticket)\n          .onConflict('entity_id')\n          .merge(['final_entity', 'hash']);\n\n        if (rowsChanged.length === 0) {\n          this.logger.debug(\n            `Entity ${entityRef} is already processed, skipping write.`,\n          );\n          continue;\n        }\n\n        // TODO(freben): Search will probably need a similar safeguard against\n        // race conditions like the final_entities ticket handling above.\n        // Otherwise, it can be the case that:\n        // A writes the entity ->\n        // B writes the entity ->\n        // B writes search ->\n        // A writes search\n        const searchEntries = buildEntitySearch(entityId, entity);\n        await this.database<DbSearchRow>('search')\n          .where({ entity_id: entityId })\n          .delete();\n        await this.database.batchInsert('search', searchEntries, BATCH_SIZE);\n      } catch (error) {\n        this.logger.error(`Failed to stitch ${entityRef}, ${error}`);\n      }\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  PluginDatabaseManager,\n  resolvePackagePath,\n  UrlReader,\n} from '@backstage/backend-common';\nimport {\n  DefaultNamespaceEntityPolicy,\n  EntityPolicies,\n  EntityPolicy,\n  FieldFormatEntityPolicy,\n  makeValidator,\n  NoForeignRootFieldsEntityPolicy,\n  SchemaValidEntityPolicy,\n  Validators,\n} from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { ScmIntegrations } from '@backstage/integration';\nimport lodash from 'lodash';\nimport { Logger } from 'winston';\nimport {\n  DatabaseLocationsCatalog,\n  EntitiesCatalog,\n  LocationsCatalog,\n} from '../catalog';\nimport { CommonDatabase } from '../database/CommonDatabase';\nimport {\n  AnnotateLocationEntityProcessor,\n  BitbucketDiscoveryProcessor,\n  BuiltinKindsEntityProcessor,\n  CatalogProcessor,\n  CatalogProcessorParser,\n  CodeOwnersProcessor,\n  FileReaderProcessor,\n  GithubDiscoveryProcessor,\n  GithubOrgReaderProcessor,\n  LdapOrgReaderProcessor,\n  MicrosoftGraphOrgReaderProcessor,\n  PlaceholderProcessor,\n  PlaceholderResolver,\n  UrlReaderProcessor,\n} from '../ingestion';\nimport { RepoLocationAnalyzer } from '../ingestion/LocationAnalyzer';\nimport {\n  jsonPlaceholderResolver,\n  textPlaceholderResolver,\n  yamlPlaceholderResolver,\n} from '../ingestion/processors/PlaceholderProcessor';\nimport { defaultEntityDataParser } from '../ingestion/processors/util/parse';\nimport { LocationAnalyzer } from '../ingestion/types';\nimport { CatalogProcessingEngine, LocationService } from '../next/types';\nimport { ConfigLocationEntityProvider } from './ConfigLocationEntityProvider';\nimport { DefaultProcessingDatabase } from './database/DefaultProcessingDatabase';\nimport { DefaultCatalogProcessingEngine } from './DefaultCatalogProcessingEngine';\nimport { DefaultCatalogProcessingOrchestrator } from './DefaultCatalogProcessingOrchestrator';\nimport { DefaultLocationService } from './DefaultLocationService';\nimport { DefaultLocationStore } from './DefaultLocationStore';\nimport { NextEntitiesCatalog } from './NextEntitiesCatalog';\nimport { Stitcher } from './Stitcher';\n\nexport type CatalogEnvironment = {\n  logger: Logger;\n  database: PluginDatabaseManager;\n  config: Config;\n  reader: UrlReader;\n};\n\n/**\n * A builder that helps wire up all of the component parts of the catalog.\n *\n * The touch points where you can replace or extend behavior are as follows:\n *\n * - Entity policies can be added or replaced. These are automatically run\n *   after the processors' pre-processing steps. All policies are given the\n *   chance to inspect the entity, and all of them have to pass in order for\n *   the entity to be considered valid from an overall point of view.\n * - Placeholder resolvers can be replaced or added. These run on the raw\n *   structured data between the parsing and pre-processing steps, to replace\n *   dollar-prefixed entries with their actual values (like $file).\n * - Field format validators can be replaced. These check the format of\n *   individual core fields such as metadata.name, to ensure that they adhere\n *   to certain rules.\n * - Processors can be added or replaced. These implement the functionality of\n *   reading, parsing, validating, and processing the entity data before it is\n *   persisted in the catalog.\n */\nexport class NextCatalogBuilder {\n  private readonly env: CatalogEnvironment;\n  private entityPolicies: EntityPolicy[];\n  private entityPoliciesReplace: boolean;\n  private placeholderResolvers: Record<string, PlaceholderResolver>;\n  private fieldFormatValidators: Partial<Validators>;\n  private processors: CatalogProcessor[];\n  private processorsReplace: boolean;\n  private parser: CatalogProcessorParser | undefined;\n\n  constructor(env: CatalogEnvironment) {\n    this.env = env;\n    this.entityPolicies = [];\n    this.entityPoliciesReplace = false;\n    this.placeholderResolvers = {};\n    this.fieldFormatValidators = {};\n    this.processors = [];\n    this.processorsReplace = false;\n    this.parser = undefined;\n  }\n\n  /**\n   * Adds policies that are used to validate entities between the pre-\n   * processing and post-processing stages. All such policies must pass for the\n   * entity to be considered valid.\n   *\n   * If what you want to do is to replace the rules for what format is allowed\n   * in various core entity fields (such as metadata.name), you may want to use\n   * {@link NextCatalogBuilder#setFieldFormatValidators} instead.\n   *\n   * @param policies One or more policies\n   */\n  addEntityPolicy(...policies: EntityPolicy[]): NextCatalogBuilder {\n    this.entityPolicies.push(...policies);\n    return this;\n  }\n\n  /**\n   * Sets what policies to use for validation of entities between the pre-\n   * processing and post-processing stages. All such policies must pass for the\n   * entity to be considered valid.\n   *\n   * If what you want to do is to replace the rules for what format is allowed\n   * in various core entity fields (such as metadata.name), you may want to use\n   * {@link NextCatalogBuilder#setFieldFormatValidators} instead.\n   *\n   * This function replaces the default set of policies; use with care.\n   *\n   * @param policies One or more policies\n   */\n  replaceEntityPolicies(policies: EntityPolicy[]): NextCatalogBuilder {\n    this.entityPolicies = [...policies];\n    this.entityPoliciesReplace = true;\n    return this;\n  }\n\n  /**\n   * Adds, or overwrites, a handler for placeholders (e.g. $file) in entity\n   * definition files.\n   *\n   * @param key The key that identifies the placeholder, e.g. \"file\"\n   * @param resolver The resolver that gets values for this placeholder\n   */\n  setPlaceholderResolver(\n    key: string,\n    resolver: PlaceholderResolver,\n  ): NextCatalogBuilder {\n    this.placeholderResolvers[key] = resolver;\n    return this;\n  }\n\n  /**\n   * Sets the validator function to use for one or more special fields of an\n   * entity. This is useful if the default rules for formatting of fields are\n   * not sufficient.\n   *\n   * This function has no effect if used together with\n   * {@link NextCatalogBuilder#replaceEntityPolicies}.\n   *\n   * @param validators The (subset of) validators to set\n   */\n  setFieldFormatValidators(\n    validators: Partial<Validators>,\n  ): NextCatalogBuilder {\n    lodash.merge(this.fieldFormatValidators, validators);\n    return this;\n  }\n\n  /**\n   * Adds entity processors. These are responsible for reading, parsing, and\n   * processing entities before they are persisted in the catalog.\n   *\n   * @param processors One or more processors\n   */\n  addProcessor(...processors: CatalogProcessor[]): NextCatalogBuilder {\n    this.processors.push(...processors);\n    return this;\n  }\n\n  /**\n   * Sets what entity processors to use. These are responsible for reading,\n   * parsing, and processing entities before they are persisted in the catalog.\n   *\n   * This function replaces the default set of processors; use with care.\n   *\n   * @param processors One or more processors\n   */\n  replaceProcessors(processors: CatalogProcessor[]): NextCatalogBuilder {\n    this.processors = [...processors];\n    this.processorsReplace = true;\n    return this;\n  }\n\n  /**\n   * Sets up the catalog to use a custom parser for entity data.\n   *\n   * This is the function that gets called immediately after some raw entity\n   * specification data has been read from a remote source, and needs to be\n   * parsed and emitted as structured data.\n   *\n   * @param parser The custom parser\n   */\n  setEntityDataParser(parser: CatalogProcessorParser): NextCatalogBuilder {\n    this.parser = parser;\n    return this;\n  }\n\n  /**\n   * Wires up and returns all of the component parts of the catalog\n   */\n  async build(): Promise<{\n    entitiesCatalog: EntitiesCatalog;\n    locationsCatalog: LocationsCatalog;\n    locationAnalyzer: LocationAnalyzer;\n    processingEngine: CatalogProcessingEngine;\n    locationService: LocationService;\n  }> {\n    const { config, database, logger } = this.env;\n\n    const policy = this.buildEntityPolicy();\n    const processors = this.buildProcessors();\n    const parser = this.parser || defaultEntityDataParser;\n\n    const dbClient = await database.getClient();\n    await dbClient.migrate.latest({\n      directory: resolvePackagePath(\n        '@backstage/plugin-catalog-backend',\n        'migrationsv2',\n      ),\n    });\n\n    const db = new CommonDatabase(dbClient, logger);\n\n    const processingDatabase = new DefaultProcessingDatabase(dbClient, logger);\n    const integrations = ScmIntegrations.fromConfig(config);\n    const orchestrator = new DefaultCatalogProcessingOrchestrator({\n      processors,\n      integrations,\n      logger,\n      parser,\n      policy,\n    });\n    const entitiesCatalog = new NextEntitiesCatalog(dbClient);\n\n    const locationStore = new DefaultLocationStore(dbClient);\n    const stitcher = new Stitcher(dbClient, logger);\n    const configLocationProvider = new ConfigLocationEntityProvider(config);\n    const processingEngine = new DefaultCatalogProcessingEngine(\n      logger,\n      [locationStore, configLocationProvider],\n      processingDatabase,\n      orchestrator,\n      stitcher,\n    );\n\n    const locationsCatalog = new DatabaseLocationsCatalog(db);\n    const locationAnalyzer = new RepoLocationAnalyzer(logger, integrations);\n    const locationService = new DefaultLocationService(\n      locationStore,\n      orchestrator,\n    );\n    return {\n      entitiesCatalog,\n      locationsCatalog,\n      locationAnalyzer,\n      processingEngine,\n      locationService,\n    };\n  }\n\n  private buildEntityPolicy(): EntityPolicy {\n    const entityPolicies: EntityPolicy[] = this.entityPoliciesReplace\n      ? [new SchemaValidEntityPolicy(), ...this.entityPolicies]\n      : [\n          new SchemaValidEntityPolicy(),\n          new DefaultNamespaceEntityPolicy(),\n          new NoForeignRootFieldsEntityPolicy(),\n          new FieldFormatEntityPolicy(\n            makeValidator(this.fieldFormatValidators),\n          ),\n          ...this.entityPolicies,\n        ];\n\n    return EntityPolicies.allOf(entityPolicies);\n  }\n\n  private buildProcessors(): CatalogProcessor[] {\n    const { config, logger, reader } = this.env;\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    this.checkDeprecatedReaderProcessors();\n\n    const placeholderResolvers: Record<string, PlaceholderResolver> = {\n      json: jsonPlaceholderResolver,\n      yaml: yamlPlaceholderResolver,\n      text: textPlaceholderResolver,\n      ...this.placeholderResolvers,\n    };\n\n    // These are always there no matter what\n    const processors: CatalogProcessor[] = [\n      new PlaceholderProcessor({ resolvers: placeholderResolvers, reader }),\n      new BuiltinKindsEntityProcessor(),\n    ];\n\n    // These are only added unless the user replaced them all\n    if (!this.processorsReplace) {\n      processors.push(\n        new FileReaderProcessor(),\n        BitbucketDiscoveryProcessor.fromConfig(config, { logger }),\n        GithubDiscoveryProcessor.fromConfig(config, { logger }),\n        GithubOrgReaderProcessor.fromConfig(config, { logger }),\n        LdapOrgReaderProcessor.fromConfig(config, { logger }),\n        MicrosoftGraphOrgReaderProcessor.fromConfig(config, { logger }),\n        new UrlReaderProcessor({ reader, logger }),\n        CodeOwnersProcessor.fromConfig(config, { logger, reader }),\n        new AnnotateLocationEntityProcessor({ integrations }),\n      );\n    }\n\n    // Add the ones (if any) that the user added\n    processors.push(...this.processors);\n\n    return processors;\n  }\n\n  // TODO(Rugvip): These old processors are removed, for a while we'll be throwing\n  //               errors here to make sure people know where to move the config\n  private checkDeprecatedReaderProcessors() {\n    const pc = this.env.config.getOptionalConfig('catalog.processors');\n    if (pc?.has('github')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.github, move to using integrations.github instead`,\n      );\n    }\n    if (pc?.has('gitlabApi')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.gitlabApi, move to using integrations.gitlab instead`,\n      );\n    }\n    if (pc?.has('bitbucketApi')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.bitbucketApi, move to using integrations.bitbucket instead`,\n      );\n    }\n    if (pc?.has('azureApi')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.azureApi, move to using integrations.azure instead`,\n      );\n    }\n  }\n}\n","/*\n * Copyright 2020 Spotify AB\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { errorHandler } from '@backstage/backend-common';\nimport {\n  analyzeLocationSchema,\n  locationSpecSchema,\n} from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { NotFoundError } from '@backstage/errors';\nimport express from 'express';\nimport Router from 'express-promise-router';\nimport { Logger } from 'winston';\nimport yn from 'yn';\nimport { EntitiesCatalog } from '../catalog';\nimport { LocationAnalyzer } from '../ingestion/types';\nimport {\n  basicEntityFilter,\n  parseEntityFilterParams,\n  parseEntityPaginationParams,\n  parseEntityTransformParams,\n} from '../service/request';\nimport { LocationService } from './types';\nimport { disallowReadonlyMode, validateRequestBody } from '../service/util';\n\nexport interface RouterOptions {\n  entitiesCatalog?: EntitiesCatalog;\n  locationAnalyzer?: LocationAnalyzer;\n  locationService: LocationService;\n  logger: Logger;\n  config: Config;\n}\n\nexport async function createNextRouter(\n  options: RouterOptions,\n): Promise<express.Router> {\n  const {\n    entitiesCatalog,\n    locationAnalyzer,\n    locationService,\n    config,\n    logger,\n  } = options;\n\n  const router = Router();\n  router.use(express.json());\n\n  const readonlyEnabled =\n    config.getOptionalBoolean('catalog.readonly') || false;\n  if (readonlyEnabled) {\n    logger.info('Catalog is running in readonly mode');\n  }\n\n  if (entitiesCatalog) {\n    router\n      .get('/entities', async (req, res) => {\n        const { entities, pageInfo } = await entitiesCatalog.entities({\n          filter: parseEntityFilterParams(req.query),\n          fields: parseEntityTransformParams(req.query),\n          pagination: parseEntityPaginationParams(req.query),\n        });\n\n        // Add a Link header to the next page\n        if (pageInfo.hasNextPage) {\n          const url = new URL(`http://ignored${req.url}`);\n          url.searchParams.delete('offset');\n          url.searchParams.set('after', pageInfo.endCursor);\n          res.setHeader('link', `<${url.pathname}${url.search}>; rel=\"next\"`);\n        }\n\n        // TODO(freben): encode the pageInfo in the response\n        res.json(entities);\n      })\n      .get('/entities/by-uid/:uid', async (req, res) => {\n        const { uid } = req.params;\n        const { entities } = await entitiesCatalog.entities({\n          filter: basicEntityFilter({ 'metadata.uid': uid }),\n        });\n        if (!entities.length) {\n          throw new NotFoundError(`No entity with uid ${uid}`);\n        }\n        res.status(200).json(entities[0]);\n      })\n      .delete('/entities/by-uid/:uid', async (req, res) => {\n        const { uid } = req.params;\n        await entitiesCatalog.removeEntityByUid(uid);\n        res.status(204).end();\n      })\n      .get('/entities/by-name/:kind/:namespace/:name', async (req, res) => {\n        const { kind, namespace, name } = req.params;\n        const { entities } = await entitiesCatalog.entities({\n          filter: basicEntityFilter({\n            kind: kind,\n            'metadata.namespace': namespace,\n            'metadata.name': name,\n          }),\n        });\n        if (!entities.length) {\n          throw new NotFoundError(\n            `No entity named '${name}' found, with kind '${kind}' in namespace '${namespace}'`,\n          );\n        }\n        res.status(200).json(entities[0]);\n      });\n  }\n\n  if (locationService) {\n    router\n      .post('/locations', async (req, res) => {\n        const input = await validateRequestBody(req, locationSpecSchema);\n        const dryRun = yn(req.query.dryRun, { default: false });\n\n        // when in dryRun addLocation is effectively a read operation so we don't\n        // need to disallow readonly\n        if (!dryRun) {\n          disallowReadonlyMode(readonlyEnabled);\n        }\n\n        const output = await locationService.createLocation(input, dryRun);\n        res.status(201).json(output);\n      })\n      .get('/locations', async (_req, res) => {\n        const locations = await locationService.listLocations();\n        res.status(200).json(locations.map(l => ({ data: l })));\n      })\n\n      .get('/locations/:id', async (req, res) => {\n        const { id } = req.params;\n        const output = await locationService.getLocation(id);\n        res.status(200).json(output);\n      })\n      .delete('/locations/:id', async (req, res) => {\n        disallowReadonlyMode(readonlyEnabled);\n\n        const { id } = req.params;\n        await locationService.deleteLocation(id);\n        res.status(204).end();\n      });\n  }\n\n  if (locationAnalyzer) {\n    router.post('/analyze-location', async (req, res) => {\n      const input = await validateRequestBody(req, analyzeLocationSchema);\n      const output = await locationAnalyzer.analyzeLocation(input);\n      res.status(200).json(output);\n    });\n  }\n\n  router.use(errorHandler());\n  return router;\n}\n"],"names":["InputError","lodash","groupBy","getEntityName","chunk","limiterFactory","ConflictError","serializeEntityRef","LOCATION_ANNOTATION","entityHasChanges","generateUpdatedEntity","ENTITY_DEFAULT_NAMESPACE","BATCH_SIZE","generateEntityUid","generateEntityEtag","NotFoundError","ENTITY_META_GENERATED_FIELDS","parseEntityName","resolvePackagePath","getVoidLogger","knexFactory","uuidv4","stringifyLocationReference","location","result.location","NotAllowedError","result.generalError","result.inputError","merge","pickBy","ORIGIN_LOCATION_ANNOTATION","VIEW_URL_ANNOTATION","EDIT_URL_ANNOTATION","SOURCE_LOCATION_ANNOTATION","identity","ScmIntegrations","parseGitUrl","AWS","entity","results.entity","fetch","getBitbucketRequestOptions","results.location","apiEntityV1alpha1Validator","componentEntityV1alpha1Validator","resourceEntityV1alpha1Validator","groupEntityV1alpha1Validator","locationEntityV1alpha1Validator","templateEntityV1alpha1Validator","templateEntityV1beta2Validator","userEntityV1alpha1Validator","systemEntityV1alpha1Validator","domainEntityV1alpha1Validator","parseEntityRef","result.relation","RELATION_OWNED_BY","RELATION_OWNER_OF","RELATION_PART_OF","RELATION_HAS_PART","RELATION_PROVIDES_API","RELATION_API_PROVIDED_BY","RELATION_CONSUMES_API","RELATION_API_CONSUMED_BY","RELATION_DEPENDS_ON","RELATION_DEPENDENCY_OF","RELATION_MEMBER_OF","RELATION_HAS_MEMBER","RELATION_CHILD_OF","RELATION_PARENT_OF","codeowners.parse","pipe","filter","reverse","head","get","yaml","result.entity","promisify","g","fs","path","result.notFoundError","GithubCredentialsProvider","parseUrl","graphql","escapeRegExp","ldap","mergeWith","msal.ConfidentialClientApplication","qs","SchemaValidEntityPolicy","DefaultNamespaceEntityPolicy","NoForeignRootFieldsEntityPolicy","FieldFormatEntityPolicy","makeValidator","EntityPolicies","Router","express","locationSpecSchema","yn","analyzeLocationSchema","errorHandler","createHash","stringifyEntityRef","errors","uuid","entityEnvelopeSchemaValidator","serializeError","entitySchemaValidator","parseLocationReference","results.inputError","toAbsoluteUrl","parsePagination","stringifyPagination","SPECIAL_KEYS","MAX_KEY_LENGTH","MAX_VALUE_LENGTH","traverse","mapToRows","stableStringify","ENTITY_STATUS_CATALOG_PROCESSING_TYPE","buildEntitySearch"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;2BAsBE,OACc;AACd,QAAM,eAAqD;AAE3D,aAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,QAAQ;AAChD,UAAM,SAAS,CAAC,OAAO;AAEvB,UAAM,IACJ,OAAO,eACH,aAAa,OACZ,aAAa,OAAO,CAAE,KAAK,cAAc;AAEhD,MAAE,aAAc,KAAK,GAAG;AAAA;AAG1B,SAAO,CAAE,OAAO,CAAC,CAAE,OAAO,OAAO,OAAO;AAAA;;2BCdxC,OACA,KACoB;AACpB,MAAI,UAAU,QAAW;AACvB,WAAO;AAAA;AAGT,MAAI,OAAO,UAAU,UAAU;AAC7B,UAAM,IAAIA,kBAAW,WAAW;AAAA;AAGlC,QAAM,SAAS,SAAS,OAAO;AAC/B,MAAI,CAAC,OAAO,UAAU,WAAW,OAAO,YAAY,OAAO;AACzD,UAAM,IAAIA,kBAAW,WAAW;AAAA;AAGlC,SAAO;AAAA;0BAOP,OACA,KACoB;AACpB,MAAI,UAAU,QAAW;AACvB,WAAO;AAAA;AAGT,MAAI,OAAO,UAAU,UAAU;AAC7B,UAAM,IAAIA,kBAAW,WAAW;AAAA;AAGlC,SAAO;AAAA;2BAQP,OACA,KACsB;AACtB,MAAI,UAAU,QAAW;AACvB,WAAO;AAAA;AAGT,QAAM,QAAQ,CAAC,OAAO;AACtB,MAAI,MAAM,KAAK,OAAK,OAAO,MAAM,WAAW;AAC1C,UAAM,IAAIA,kBAAW,WAAW;AAAA;AAGlC,SAAO;AAAA;;iCCpDP,QAC0B;AAE1B,QAAM,gBAAgB,kBAAkB,OAAO,QAAQ;AACvD,MAAI,CAAC,eAAe;AAClB,WAAO;AAAA;AAKT,QAAM,UAAU,cAAc,IAAI,yBAAyB,OAAO;AAClE,MAAI,CAAC,QAAQ,QAAQ;AACnB,WAAO;AAAA;AAGT,SAAO,CAAE,OAAO,QAAQ,IAAI,SAAQ,OAAO;AAAA;iCAQ3C,cACoC;AACpC,QAAM,aAAa,aAChB,MAAM,KACN,IAAI,OAAK,EAAE,QACX,OAAO;AAEV,MAAI,CAAC,WAAW,QAAQ;AACtB,WAAO;AAAA;AAGT,QAAM,eAAqD;AAE3D,aAAW,aAAa,YAAY;AAClC,UAAM,cAAc,UAAU,QAAQ;AACtC,QAAI,cAAc,GAAG;AACnB,YAAM,IAAIA,kBACR,oBAAoB;AAAA;AAIxB,UAAM,MAAM,UAAU,OAAO,GAAG,aAAa;AAC7C,UAAM,QAAQ,UAAU,OAAO,cAAc,GAAG;AAChD,QAAI,CAAC,OAAO,CAAC,OAAO;AAClB,YAAM,IAAIA,kBACR,oBAAoB;AAAA;AAIxB,UAAM,IACJ,OAAO,eACH,aAAa,OACZ,aAAa,OAAO,CAAE,KAAK,cAAc;AAChD,MAAE,aAAc,KAAK;AAAA;AAGvB,SAAO,OAAO,OAAO;AAAA;;qCC3DrB,QAC8B;AAC9B,QAAM,SAAS,kBAAkB,OAAO,QAAQ;AAChD,QAAM,QAAQ,kBAAkB,OAAO,OAAO;AAC9C,QAAM,QAAQ,iBAAiB,OAAO,OAAO;AAE7C,MAAI,WAAW,UAAa,UAAU,UAAa,UAAU,QAAW;AACtE,WAAO;AAAA;AAGT,MAAI,WAAW,UAAa,SAAS,GAAG;AACtC,UAAM,IAAIA,kBAAW;AAAA;AAEvB,MAAI,UAAU,UAAa,SAAS,GAAG;AACrC,UAAM,IAAIA,kBAAW;AAAA;AAEvB,MAAI,UAAU,UAAa,CAAC,OAAO;AACjC,UAAM,IAAIA,kBAAW;AAAA;AAGvB,SAAO;AAAA,OACD,WAAW,SAAY,CAAE,UAAW;AAAA,OACpC,UAAU,SAAY,CAAE,SAAU;AAAA,OAClC,UAAU,SAAY,CAAE,SAAU;AAAA;AAAA;;oCCzBxC,QAC0C;AAC1C,QAAM,gBAAgB,kBAAkB,OAAO,QAAQ;AACvD,MAAI,CAAC,eAAe;AAClB,WAAO;AAAA;AAGT,QAAM,SAAS,cACZ,IAAI,OAAK,EAAE,MAAM,MACjB,OACA,IAAI,OAAK,EAAE,QACX,OAAO;AAEV,MAAI,CAAC,OAAO,QAAQ;AAClB,WAAO;AAAA;AAGT,MAAI,OAAO,KAAK,OAAK,EAAE,SAAS,OAAO;AACrC,UAAM,IAAIA,kBAAW;AAAA;AAGvB,SAAO,WAAS;AACd,UAAM,SAAmC;AAEzC,eAAW,SAAS,QAAQ;AAC1B,YAAM,QAAQC,2BAAO,IAAI,OAAO;AAChC,UAAI,UAAU,QAAW;AACvB,mCAAO,IAAI,QAAQ,OAAO;AAAA;AAAA;AAI9B,WAAO;AAAA;AAAA;;sBC/BkB,gBAA0C;AACrE,QAAM,QAAQ,QAAQ,OAAO;AAC7B,QAAM,UAAU,MAAM,KAAK,MAAM,KAAK;AACtC,MAAI,UAAU,GAAG;AACf,WAAO,GAAG,QAAQ,QAAQ;AAAA;AAE5B,SAAO,GAAI,WAAU,KAAM,QAAQ;AAAA;;ACoBrC,MAAM,aAAa;AAKnB,MAAM,iBAAiB;AAGvB,MAAM,oBAAoB;8BAEsC;AAAA,EAC9D,YACmB,UACA,QACjB;AAFiB;AACA;AAAA;AAAA,QAGb,SAAS,SAAsD;AACnE,UAAM,YAA+B;AAAA,MACnC,QAAQ,mCAAS;AAAA,MACjB,YAAY,mCAAS;AAAA;AAGvB,UAAM,aAAa,MAAM,KAAK,SAAS,YAAY,QACjD,KAAK,SAAS,SAAS,IAAI;AAG7B,UAAM,WAAW,WAAW,SAAS,IAAI,OACvC,oCAAS,UAAS,QAAQ,OAAO,EAAE,UAAU,EAAE;AAGjD,WAAO;AAAA,MACL;AAAA,MACA,UAAU,WAAW;AAAA;AAAA;AAAA,QAInB,kBAAkB,KAA4B;AAClD,UAAM,KAAK,SAAS,YAAY,OAAM,OAAM;AAC1C,YAAM,KAAK,SAAS,kBAAkB,IAAI;AAAA;AAAA;AAAA,QAIxC,yBACJ,UACA,SAKiC;AAMjC,UAAM,6BAA6BC,eAAQ,UAAU,CAAC,CAAE,YAAa;AACnE,YAAM,OAAOC,2BAAc;AAC3B,aAAO,GAAG,KAAK,QAAQ,KAAK,YAAY;AAAA;AAM1C,UAAM,UAAU,OAAO,OAAO,4BAC3B,IAAI,aAAWC,aAAM,SAAS,aAC9B;AAKH,UAAM,UAAUC,mCAAe;AAC/B,UAAM,QAAQ,QAAQ,IAAI,WACxB,QAAQ,YAAY;AAElB,eAAS,UAAU,KAAK,EAAE,SAAS;AACjC,YAAI;AACF,iBAAO,KAAK,oCAAoC,OAAO;AAAA,iBAChD,GAAP;AACA,cAAI,aAAaC,wBAAiB,UAAU,gBAAgB;AAC1D,iBAAK,OAAO,KACV,oCAAoC,WAAW,mBAAmB;AAAA,iBAE/D;AACL,kBAAM;AAAA;AAAA;AAAA;AAAA;AAOhB,UAAM,YAAY,MAAM,QAAQ,IAAI;AACpC,WAAO,UAAU;AAAA;AAAA,QAKL,oCACZ,OACA,SAKA;AACA,UAAM,CAAE,MAAM,aAAcH,2BAAc,MAAM,GAAG;AACnD,UAAM,UAAU;AAAA,MACd;AAAA,MACA;AAAA,MACA,YAAY,mCAAS;AAAA;AAGvB,SAAK,OAAO,MACV,qBAAqBI,gCACnB,MAAM,GAAG,WACNA,gCAAmB,MAAM,MAAM,SAAS,GAAG,YAC9C,MAAM;AAIV,WAAO,KAAK,SAAS,YAAY,OAAM,OAAM;AAC3C,YAAM,CAAE,OAAO,UAAU,YAAa,MAAM,KAAK,aAC/C,OACA,SACA;AAGF,UAAI,YAAY,IAAI;AACpB,UAAI,MAAM,QAAQ;AAChB,cAAM,QAAQ,MAAM,KAAK,SAAS,OAAO,SAAS;AAClD,kBAAU,KAAK,GAAG;AAAA;AAEpB,UAAI,SAAS,QAAQ;AACnB,cAAM,QAAQ,MAAM,KAAK,YAAY,UAAU,SAAS;AACxD,kBAAU,KAAK,GAAG;AAAA;AAEpB,iBAAW,CAAE,QAAQ,cAAe,UAAU;AAG5C,cAAM,WAAW,OAAO,SAAS;AACjC,YAAI,UAAU;AACZ,gBAAM,KAAK,SAAS,aAAa,IAAI,UAAU;AAC/C,oBAAU,KAAK,CAAE;AAAA;AAAA;AAIrB,UAAI,oCAAS,mBAAkB,UAAU,SAAS,GAAG;AACnD,cAAM,kBAAkB,MAAM,KAAK,SAAS,SAAS,IAAI;AAAA,UACvD,QAAQ,kBAAkB;AAAA,YACxB,gBAAgB,UAAU,IAAI,OAAK,EAAE;AAAA;AAAA;AAGzC,oBAAY,gBAAgB,SAAS,IAAI;AAAM,UAC7C,UAAU,EAAE,OAAO,SAAS;AAAA,UAC5B,QAAQ,EAAE;AAAA;AAAA;AAMd,UAAI,mCAAS,QAAQ;AACnB,cAAM,GAAG;AACT,aAAK,OAAO,MAAM;AAAA;AAGpB,aAAO;AAAA;AAAA;AAAA,QAQG,aACZ,UACA,CAAE,MAAM,YACR,IAKC;AArOL;AAsOI,UAAM,gBAAgB,QAAQ;AAI9B,UAAM,QAAQ,SAAS,IAAI,CAAC,CAAE,YAAa,OAAO,SAAS;AAC3D,UAAM,sBAAsB,MAAM,KAAK,SAAS,SAAS,IAAI;AAAA,MAC3D,QAAQ,kBAAkB;AAAA,QACxB;AAAA,QACA,sBAAsB;AAAA,QACtB,iBAAiB;AAAA;AAAA;AAIrB,UAAM,oBAAoB,IAAI,IAC5B,oBAAoB,SAAS,IAAI,OAAK,CAAC,EAAE,OAAO,SAAS,MAAM,EAAE;AAGnE,UAAM,QAA+B;AACrC,UAAM,WAAkC;AACxC,UAAM,WAAkC;AAExC,eAAW,WAAW,UAAU;AAC9B,YAAM,YAAY,QAAQ;AAC1B,YAAM,YAAY,kBAAkB,IAAI,UAAU,SAAS;AAC3D,YAAM,cAAc,gBAAU,SAAS,gBAAnB,mBAAiCC;AACrD,YAAM,cACJ,6CAAW,SAAS,gBAApB,mBAAkCA;AACpC,UAAI,CAAC,WAAW;AACd,cAAM,KAAK;AAAA,iBACF,gBAAgB,aAAa;AACtC,aAAK,OAAO,KACV,6BAA6BD,gCAC3B,mBACQ,2CAA2C;AAEvD,iBAAS,KAAK;AAAA,iBACLE,8BAAiB,WAAW,YAAY;AAIjD,iBAAS,KAAK;AAAA,aACT;AAEL,iBAAS,KAAK,IAAK,SAAS,QAAQ;AAAA;AAAA;AAIxC,SAAK,OAAO,MACV,SAAS,MAAM,2BACb,SAAS,gCACe,aAAa;AAGzC,WAAO,CAAE,OAAO,UAAU;AAAA;AAAA,QAKd,SACZ,UACA,CAAE,aACF,IACiC;AACjC,UAAM,gBAAgB,QAAQ;AAE9B,UAAM,MAAM,MAAM,KAAK,SAAS,YAC9B,IACA,SAAS,IAAI,CAAC,CAAE,QAAQ;AAAiB,MACvC;AAAA,MACA;AAAA,MACA;AAAA;AAIJ,UAAM,YAAY,IAAI,IAAI,CAAC,CAAE;AAAc,MACzC,UAAU,OAAO,SAAS;AAAA;AAG5B,SAAK,OAAO,MACV,SAAS,SAAS,sBAAsB,aAAa;AAGvD,WAAO;AAAA;AAAA,QAKK,YACZ,UACA,CAAE,aACF,IACiC;AACjC,UAAM,gBAAgB,QAAQ;AAC9B,UAAM,YAAoC;AAG1C,eAAW,WAAW,UAAU;AAC9B,YAAM,MAAM,MAAM,KAAK,kBAAkB,IAAI,SAAS;AACtD,YAAM,WAAW,IAAI,SAAS;AAC9B,gBAAU,KAAK,CAAE;AAAA;AAGnB,SAAK,OAAO,MACV,WAAW,SAAS,sBAAsB,aAAa;AAGzD,WAAO;AAAA;AAAA,QAIK,kBACZ,IACA,CAAE,QAAQ,YACV,YACiB;AAGjB,UAAM,WAAW,OAAO,SAAS,MAC7B,MAAM,KAAK,SAAS,YAAY,IAAI,OAAO,SAAS,OACpD,MAAM,KAAK,SAAS,aAAa,IAAIN,2BAAc;AAIvD,QAAI;AACJ,QAAI,UAAU;AACZ,YAAM,UAAUO,mCAAsB,SAAS,QAAQ;AACvD,iBAAW,MAAM,KAAK,SAAS,aAC7B,IACA,CAAE,YAAY,QAAQ,SAAS,YAC/B,SAAS,OAAO,SAAS,MACzB,SAAS,OAAO,SAAS;AAAA,WAEtB;AACL,YAAM,QAAQ,MAAM,KAAK,SAAS,YAAY,IAAI;AAAA,QAChD,CAAE,YAAY,QAAQ;AAAA;AAExB,iBAAW,MAAM;AAAA;AAGnB,WAAO,SAAS;AAAA;AAAA;;IC1RR;AAAL,UAAK,kCAAL;AACL,6CAAO;AACP,gDAAU;AAAA,GAFA;;+BC/DsD;AAAA,EAChE,YAA6B,UAAoB;AAApB;AAAA;AAAA,QAEvB,YAAY,UAAuC;AACvD,WAAO,MAAM,KAAK,SAAS,YACzB,OAAM,OAAM,MAAM,KAAK,SAAS,YAAY,IAAI;AAAA;AAAA,QAI9C,eAAe,IAA2B;AAC9C,UAAM,KAAK,SAAS,YAAY,QAAM,KAAK,SAAS,eAAe,IAAI;AAAA;AAAA,QAGnE,YAAyC;AAC7C,UAAM,QAAQ,MAAM,KAAK,SAAS;AAClC,WAAO,MAAM,IAAI,CAAC,CAAE,SAAS,QAAQ,cAAc;AAAY,MAC7D,eAAe;AAAA,QACb;AAAA,QACA;AAAA,QACA;AAAA;AAAA,MAEF;AAAA;AAAA;AAAA,QAIE,gBAAgB,IAAuD;AAC3E,WAAO,KAAK,SAAS,gBAAgB;AAAA;AAAA,QAGjC,SAAS,IAAuC;AACpD,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,SACG;AAAA,QACD,MAAM,KAAK,SAAS,SAAS;AACjC,WAAO;AAAA,MACL,eAAe;AAAA,QACb;AAAA,QACA;AAAA,QACA;AAAA;AAAA,MAEF;AAAA;AAAA;AAAA,QAIE,iBACJ,YACA,YACe;AACf,UAAM,KAAK,SAAS,0BAClB,YACA,gCAAgC,SAChC;AAAA;AAAA,QAIE,iBACJ,YACA,OACA,YACe;AACf,UAAM,KAAK,SAAS,0BAClB,YACA,gCAAgC,MAChC,YACA,+BAAO;AAAA;AAAA;;ACpEb,MAAM,eAAe;AAAA,EACnB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAMF,MAAM,iBAAiB;AACvB,MAAM,mBAAmB;kBAkCA,MAAqB;AAC5C,QAAM,SAAe;AAErB,iBAAe,MAAc,SAAkB;AAC7C,QAAI,aAAa,SAAS,OAAO;AAC/B;AAAA;AAIF,QACE,YAAY,UACZ,YAAY,QACZ,CAAC,UAAU,UAAU,WAAW,SAAS,OAAO,UAChD;AACA,aAAO,KAAK,CAAE,KAAK,MAAM,OAAO;AAChC;AAAA;AAIF,QAAI,OAAO,YAAY,UAAU;AAC/B;AAAA;AAIF,QAAI,MAAM,QAAQ,UAAU;AAC1B,iBAAW,QAAQ,SAAS;AAc1B,cAAM,MAAM;AACZ,YAAI,OAAO,SAAS,UAAU;AAC5B,iBAAO,KAAK,CAAE,KAAK,GAAG,QAAQ,QAAQ,OAAO;AAAA;AAAA;AAGjD;AAAA;AAIF,eAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,UAAW;AACnD,YAAM,OAAO,GAAG,QAAQ,QAAQ,KAAK;AAAA;AAAA;AAIzC,QAAM,IAAI;AAEV,SAAO;AAAA;mBAKP,OACA,UACuB;AACvB,QAAM,SAAgC;AAEtC,aAAW,CAAE,KAAK,QAAQ,OAAO,aAAc,OAAO;AACpD,UAAM,MAAM,OAAO;AACnB,QAAI,aAAa,UAAa,aAAa,MAAM;AAC/C,aAAO,KAAK,CAAE,WAAW,UAAU,KAAK,OAAO;AAAA,WAC1C;AACL,YAAM,QAAQ,OAAO,UAAU;AAC/B,UAAI,IAAI,UAAU,kBAAkB,MAAM,UAAU,kBAAkB;AACpE,eAAO,KAAK,CAAE,WAAW,UAAU,KAAK;AAAA;AAAA;AAAA;AAK9C,SAAO;AAAA;2BAWP,UACA,QACuB;AAEvB,QAAM,MAAM,SAAS;AAIrB,MAAI,KAAK,CAAE,KAAK,iBAAiB,OAAO,OAAO,SAAS;AACxD,MAAI,KAAK,CAAE,KAAK,sBAAsB,OAAO,OAAO,SAAS;AAC7D,MAAI,KAAK,CAAE,KAAK,gBAAgB,OAAO,OAAO,SAAS;AAIvD,MAAI,CAAC,OAAO,SAAS,WAAW;AAC9B,QAAI,KAAK,CAAE,KAAK,sBAAsB,OAAOC;AAAA;AAG/C,SAAO,UAAU,KAAK;AAAA;;ACxHxB,MAAMC,eAAa;qBAK6B;AAAA,EAC9C,YACmB,UACA,QACjB;AAFiB;AACA;AAAA;AAAA,QAGb,YAAe,IAAiD;AACpE,QAAI;AACF,UAAI,SAAwB;AAE5B,YAAM,KAAK,SAAS,YAClB,OAAM,OAAM;AAGV,iBAAS,MAAM,GAAG;AAAA,SAEpB;AAAA,QAEE,uBAAuB;AAAA;AAI3B,aAAO;AAAA,aACA,GAAP;AACA,WAAK,OAAO,MAAM,6BAA6B;AAE/C,UACE,4BAA4B,KAAK,EAAE,YACnC,oBAAoB,KAAK,EAAE,UAC3B;AACA,cAAM,IAAIN,qBAAc,wCAAwC;AAAA;AAGlE,YAAM;AAAA;AAAA;AAAA,QAIJ,YACJ,UACA,SAC6B;AAC7B,UAAM,KAAK;AAEX,UAAM,SAA6B;AACnC,UAAM,aAA8B;AACpC,UAAM,eAAyC;AAC/C,UAAM,aAAoC;AAE1C,eAAW,CAAE,QAAQ,WAAW,eAAgB,SAAS;AACvD,UAAI,OAAO,SAAS,QAAQ,QAAW;AACrC,cAAM,IAAIN,kBAAW;AAAA,iBACZ,OAAO,SAAS,SAAS,QAAW;AAC7C,cAAM,IAAIA,kBAAW;AAAA,iBACZ,OAAO,SAAS,eAAe,QAAW;AACnD,cAAM,IAAIA,kBAAW;AAAA,iBACZ,OAAO,cAAc,QAAW;AACzC,cAAM,IAAIA,kBAAW;AAAA;AAGvB,YAAM,MAAMa;AACZ,YAAM,OAAOC;AACb,YAAM,aAAa;AACnB,YAAM,YAAY;AAAA,WACb;AAAA,QACH,UAAU;AAAA,aACL,OAAO;AAAA,UACV;AAAA,UACA;AAAA,UACA;AAAA;AAAA;AAIJ,aAAO,KAAK,CAAE,QAAQ,WAAW;AACjC,iBAAW,KAAK,KAAK,YAAY,YAAY;AAC7C,mBAAa,KAAK,GAAG,KAAK,eAAe,KAAK;AAC9C,iBAAW,KAAK,GAAG,kBAAkB,KAAK;AAAA;AAG5C,UAAM,GAAG,YAAY,YAAY,YAAYF;AAC7C,UAAM,GAAG,YAAY,sBAAsB,cAAcA;AACzD,UAAM,GAAG,YAAY,mBAAmB,YAAYA;AAEpD,WAAO;AAAA;AAAA,QAGH,aACJ,UACA,SACA,cACA,oBAC2B;AAC3B,UAAM,KAAK;AAEX,UAAM,CAAE,OAAQ,QAAQ,OAAO;AAC/B,QAAI,CAAC,KAAK;AACR,YAAM,IAAIZ,kBAAW;AAAA;AAIvB,UAAM,UAAU,MAAM,GAAkB,YACrC,MAAM,CAAE,IAAI,MACZ;AACH,QAAI,QAAQ,WAAW,GAAG;AACxB,YAAM,IAAIe,qBAAc;AAAA;AAE1B,UAAM,OAAO,QAAQ,GAAG;AACxB,UAAM,aAAa,OAAO,QAAQ,GAAG;AAIrC,QAAI,gBAAgB,iBAAiB,MAAM;AACzC,YAAM,IAAIT,qBACR,4BAA4B,wBAAwB;AAAA;AAGxD,QAAI,sBAAsB,uBAAuB,YAAY;AAC3D,YAAM,IAAIA,qBACR,kCAAkC,8BAA8B;AAAA;AAMpE,UAAM,SAAS,KAAK,YAAY,QAAQ,YAAY,QAAQ;AAC5D,UAAM,cAAc,MAAM,GAAkB,YACzC,MAAM,CAAE,IAAI,KAAK,OACjB,OAAO;AACV,QAAI,gBAAgB,GAAG;AACrB,YAAM,IAAIA,qBAAc;AAAA;AAG1B,UAAM,eAAe,KAAK,eAAe,KAAK,QAAQ;AACtD,UAAM,GAA2B,sBAC9B,MAAM,CAAE,uBAAuB,MAC/B;AACH,UAAM,GAAG,YAAY,sBAAsB,cAAcM;AAEzD,QAAI;AACF,YAAM,UAAU,kBAAkB,KAAK,QAAQ;AAC/C,YAAM,GAAwB,mBAC3B,MAAM,CAAE,WAAW,MACnB;AACH,YAAM,GAAG,YAAY,mBAAmB,SAASA;AAAA,YACjD;AAAA;AAKF,WAAO;AAAA;AAAA,QAGH,SACJ,UACA,SAC6B;AArNjC;AAsNI,UAAM,KAAK;AAEX,QAAI,gBAAgB,GAAkB;AAEtC,eAAW,gBAAgB,+CAAS,WAAT,mBAAiB,UAAjB,YAA0B,IAAI;AACvD,sBAAgB,cAAc,QAAQ,0BAA0B;AAC9D,mBAAW,CAAE,KAAK,iBAAkB,aAAa,OAAO;AAItD,gBAAM,aAAa,GAAwB,mBACxC,OAAO,aACP,MAAM,qBAAqB;AAC1B,iBAAK,SAAS,CAAE,KAAK,IAAI;AACzB,gBAAI,cAAc;AAChB,kBAAI,aAAa,WAAW,GAAG;AAC7B,qBAAK,SAAS,CAAE,OAAO,aAAa,GAAG;AAAA,yBAC9B,aAAa,SAAS,GAAG;AAClC,qBAAK,SACH,SACA,MACA,aAAa,IAAI,OAAK,EAAE;AAAA;AAAA;AAAA;AAKlC,eAAK,SAAS,MAAM,MAAM;AAAA;AAAA;AAAA;AAKhC,oBAAgB,cACb,OAAO,cACP,QAAQ,aAAa;AAExB,UAAM,CAAE,OAAO,UAAW,gBAAgB,mCAAS;AACnD,QAAI,UAAU,QAAW;AACvB,sBAAgB,cAAc,MAAM,QAAQ;AAAA;AAE9C,QAAI,WAAW,QAAW;AACxB,sBAAgB,cAAc,OAAO;AAAA;AAGvC,QAAI,OAAO,MAAM;AAEjB,QAAI;AACJ,QAAI,UAAU,UAAa,KAAK,UAAU,OAAO;AAC/C,iBAAW,CAAE,aAAa;AAAA,WACrB;AACL,aAAO,KAAK,MAAM,GAAG;AACrB,iBAAW;AAAA,QACT,aAAa;AAAA,QACb,WAAW,oBAAoB;AAAA,UAC7B;AAAA,UACA,QAAS,2BAAU,KAAK;AAAA;AAAA;AAAA;AAK9B,WAAO;AAAA,MACL,UAAU,MAAM,KAAK,kBAAkB,IAAI;AAAA,MAC3C;AAAA;AAAA;AAAA,QAIE,aACJ,UACA,MACuC;AACvC,UAAM,KAAK;AAEX,UAAM,OAAO,MAAM,GAAkB,YAClC,MAAM;AAAA,MACL,WAAW,GAAG,KAAK,QAAQ,KAAK,aAAa,KAAK,OAAO;AAAA,OAE1D;AAEH,QAAI,KAAK,WAAW,GAAG;AACrB,aAAO;AAAA;AAGT,WAAO,KAAK,kBAAkB,IAAI,MAAM,KAAK,OAAK,EAAE;AAAA;AAAA,QAGhD,YACJ,UACA,KACuC;AACvC,UAAM,KAAK;AAEX,UAAM,OAAO,MAAM,GAAkB,YAClC,MAAM,CAAE,IAAI,MACZ;AAEH,QAAI,KAAK,WAAW,GAAG;AACrB,aAAO;AAAA;AAGT,WAAO,KAAK,kBAAkB,IAAI,MAAM,KAAK,OAAK,EAAE;AAAA;AAAA,QAGhD,kBAAkB,UAAuB,KAA4B;AACzE,UAAM,KAAK;AAEX,UAAM,SAAS,MAAM,GAAkB,YAAY,MAAM,CAAE,IAAI,MAAO;AACtE,QAAI,CAAC,QAAQ;AACX,YAAM,IAAIG,qBAAc,2BAA2B;AAAA;AAAA;AAAA,QAIjD,aACJ,UACA,qBACA,WACe;AACf,UAAM,KAAK;AACX,UAAM,eAAe,KAAK,eAAe,qBAAqB;AAE9D,UAAM,GAA2B,sBAC9B,MAAM,CAAE,uBAAuB,sBAC/B;AACH,UAAM,GAAG,YAAY,sBAAsB,cAAcH;AAAA;AAAA,QAGrD,YACJ,UACA,UACyB;AACzB,UAAM,KAAK;AAEX,UAAM,MAAsB;AAAA,MAC1B,IAAI,SAAS;AAAA,MACb,MAAM,SAAS;AAAA,MACf,QAAQ,SAAS;AAAA;AAEnB,UAAM,GAAmB,aAAa,OAAO;AAC7C,WAAO;AAAA;AAAA,QAGH,eAAe,UAAuB,IAA2B;AACrE,UAAM,KAAK;AAEX,UAAM,YAAY,MAAM,GAAmB,aACxC,MAAM,CAAE,KACR;AACH,QAAI,CAAC,UAAU,QAAQ;AACrB,YAAM,IAAIG,qBAAc,6BAA6B;AAAA;AAGvD,QAAI,UAAU,GAAG,SAAS,aAAa;AACrC,YAAM,IAAIT,qBAAc;AAAA;AAG1B,UAAM,GAAkB,YACrB,MAAM,CAAE,aAAa,KACrB,OAAO,CAAE,aAAa;AACzB,UAAM,GAAmB,aAAa,MAAM,CAAE,KAAM;AAAA;AAAA,QAGhD,SAAS,IAA+C;AAC5D,UAAM,QAAQ,MAAM,KAAK,SAAmC,aACzD,MAAM,gBAAgB,IACtB,cACC,8BACA,gBACA,0CAED,OAAO,eAAe;AAAA,MACrB,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,SAAS;AAAA;AAGb,QAAI,CAAC,MAAM,QAAQ;AACjB,YAAM,IAAIS,qBAAc,6BAA6B;AAAA;AAEvD,WAAO,MAAM;AAAA;AAAA,QAGT,YAAiD;AACrD,UAAM,YAAY,MAAM,KAAK,SAAS,aACnC,cACC,8BACA,gBACA,0CAED,OAAO,eAAe;AAAA,MACrB,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,SAAS;AAAA;AAGb,WAAO;AAAA;AAAA,QAGH,gBAAgB,IAAuD;AAC3E,UAAM,SAAS,MAAM,KAAK,SACxB,uBAEC,MAAM,eAAe,IACrB,QAAQ,cAAc,QACtB,MAAM,IACN;AAEH,WAAO;AAAA;AAAA,QAGH,0BACJ,YACA,QACA,YACA,SACe;AAEf,UAAM,SAAS,IAAI;AACnB,WAAO,QAAQ,OAAO,YAAY;AAClC,UAAM,KAAK,SAAyC,uBACjD,MAAM,cAAc,KAAK,OAAO,eAChC;AAEH,UAAM,QAAmD,CAAC,YACvD,OACA,IAAI;AAAM,MACT;AAAA,MACA,aAAa;AAAA,MACb,aAAa;AAAA,MACb;AAAA;AAGJ,eAAW,SAASd,2BAAO,MAAM,OAAOW,eAAa;AACnD,YAAM,KAAK,SACT,uBACA,OAAO;AAAA;AAAA;AAAA,EAIL,YACN,YACA,QACe;AACf,UAAM,YAAY,OAAO,KAAK;AAC9B,UAAM,iBACJ,QAAO,SAAS,aAAaD,uCAC7B;AACF,UAAM,YAAY,OAAO,SAAS,KAAK;AAEvC,UAAM,OAAO;AAAA,SACR;AAAA,MACH,UAAUV,2BAAO,KAAK,OAAO,UAAU,GAAGe;AAAA;AAG5C,WAAO;AAAA,MACL,IAAI,OAAO,SAAS;AAAA,MACpB,aAAa,cAAc;AAAA,MAC3B,MAAM,OAAO,SAAS;AAAA,MACtB,YAAY,OAAO,SAAS;AAAA,MAC5B,WAAW,GAAG,aAAa,kBAAkB;AAAA,MAC7C,MAAM,KAAK,UAAU;AAAA;AAAA;AAAA,EAIjB,eACN,qBACA,WAC0B;AAC1B,UAAM,gBAAgB,CAAC,MACrB,GAAG,EAAE,QAAQ,EAAE,aAAa,EAAE,OAAO;AAEvC,UAAM,OAAO,UAAU,IAAI,CAAC,CAAE,QAAQ,QAAQ;AAAY,MACxD,uBAAuB;AAAA,MACvB,kBAAkB,cAAc;AAAA,MAChC,kBAAkB,cAAc;AAAA,MAChC;AAAA;AAGF,WAAO,qBAAqB;AAAA;AAAA,QAGhB,kBACZ,IACA,MAC6B;AA/ejC;AAkfI,UAAM,YAAY,MAAM,KAAK,wBAC3B,IACA,KAAK,IAAI,OAAK,EAAE;AAGlB,UAAM,SAAS,IAAI;AACnB,eAAW,OAAO,MAAM;AACtB,YAAM,SAAS,KAAK,MAAM,IAAI;AAC9B,aAAO,SAAS,MAAM,IAAI;AAC1B,aAAO,SAAS,OAAO,IAAI;AAC3B,aAAO,SAAS,aAAa,OAAO,IAAI;AAExC,aAAO,YAAa,iBAAU,IAAI,eAAd,YAA4B,IAAI,IAAI;AAAM,QAC5D,QAAQC,6BAAgB,EAAE;AAAA,QAC1B,MAAM,EAAE;AAAA;AAGV,aAAO,KAAK;AAAA,QACV,YAAY,IAAI,eAAe;AAAA,QAC/B;AAAA;AAAA;AAIJ,WAAO;AAAA;AAAA,QAKK,wBACZ,IACA,iBACmD;AACnD,UAAM,UAAUhB,2BAAO,MAAMA,2BAAO,KAAK,kBAAkB;AAE3D,UAAM,YAAY,IAAI;AACtB,eAAW,SAAS,SAAS;AAC3B,gBAAU,KACR,GAAI,MAAM,GAA2B,sBAClC,QAAQ,oBAAoB,OAC5B,QAAQ,CAAC,QAAQ,qBACjB;AAAA;AAIP,WAAOA,2BAAO,QACZ,qBAAqB,YACrB,OAAK,EAAE;AAAA;AAAA;AAKb,yBACE,OACqC;AACrC,MAAI,CAAC,OAAO;AACV,WAAO;AAAA;AAGT,MAAI,CAAE,OAAO,UAAW;AAExB,MAAI,MAAM,UAAU,QAAW;AAC7B,QAAI;AACJ,QAAI;AACF,YAAM,OAAO,OAAO,KAAK,MAAM,OAAO,UAAU,SAAS;AACzD,eAAS,KAAK,MAAM;AAAA,YACpB;AACA,YAAM,IAAID,kBAAW;AAAA;AAEvB,QAAI,OAAO,UAAU,QAAW;AAC9B,UAAI,CAAC,OAAO,UAAU,OAAO,QAAQ;AACnC,cAAM,IAAIA,kBAAW;AAAA;AAEvB,cAAQ,OAAO;AAAA;AAEjB,QAAI,OAAO,WAAW,QAAW;AAC/B,UAAI,CAAC,OAAO,UAAU,OAAO,SAAS;AACpC,cAAM,IAAIA,kBAAW;AAAA;AAEvB,eAAS,OAAO;AAAA;AAAA;AAIpB,SAAO,CAAE,OAAO;AAAA;AAGlB,6BAA6B,OAA0C;AACrE,QAAM,OAAO,KAAK,UAAU,CAAE,OAAO,MAAM,OAAO,QAAQ,MAAM;AAChE,QAAM,SAAS,OAAO,KAAK,MAAM,QAAQ,SAAS;AAClD,SAAO;AAAA;AAGT,8BACE,MAC0B;AAC1B,SAAOC,2BAAO,OACZ,MACA,OAAK,GAAG,EAAE,oBAAoB,EAAE,oBAAoB,EAAE;AAAA;;AC3jB1D,MAAM,gBAAgBiB,iCACpB,qCACA;AAOF,MAAM,iBAAwC;AAAA,EAC5C,QAAQC;AAAA;sBAGmB;AAAA,eACP,eAClB,MACA,UAA0C,IACvB;AACnB,UAAM,KAAK,QAAQ,OAAO;AAAA,MACxB,WAAW;AAAA;AAEb,UAAM,CAAE,UAAW,IAAK,mBAAmB;AAC3C,WAAO,IAAI,eAAe,MAAM;AAAA;AAAA,eAGd,yBAA4C;AAC9D,UAAM,OAAO,MAAM,KAAK;AACxB,WAAO,MAAM,KAAK,eAAe;AAAA;AAAA,eAGf,mCAAkD;AACpE,UAAM,OAAOC,gCAAY;AAAA,MACvB,QAAQ;AAAA,MACR,YAAY;AAAA,MACZ,kBAAkB;AAAA;AAGpB,SAAK,OAAO,KAAK,GAAG,iBAAiB,CAAC,UAAe,aAAkB;AACrE,eAAS,IAAI,4BAA4B,MAAM;AAAA;AAAA;AAGjD,WAAO;AAAA;AAAA,eAGW,qBAAwC;AAC1D,UAAM,OAAO,MAAM,KAAK;AACxB,WAAO,MAAM,KAAK,eAAe;AAAA;AAAA,eAGf,+BAA8C;AAChE,UAAM,SAA2B;AAAA,MAS/B,QAAQ;AAAA,MACR,YAAY;AAAA,MACZ,kBAAkB;AAAA;AAGpB,QAAI,OAAOA,gCAAY;AACvB,QAAI,OAAO,OAAO,eAAe,UAAU;AACzC,YAAM,aAAa,IAAIC,UAAS,QAAQ,MAAM;AAC9C,YAAM,KAAK,IAAI,mBAAmB;AAClC,aAAOD,gCAAY;AAAA,WACd;AAAA,QACH,YAAY;AAAA,aACP,OAAO;AAAA,UACV,UAAU;AAAA;AAAA;AAAA;AAKhB,SAAK,OAAO,KAAK,GAAG,iBAAiB,CAAC,UAAe,aAAkB;AACrE,eAAS,IAAI,4BAA4B,MAAM;AAAA;AAAA;AAGjD,WAAO;AAAA;AAAA;;yBC9EqB,IAAe,SAA6B;AAC1E,MAAI;AACJ,MAAI,YAAY;AAChB,QAAM,sBAAsB,IAAI,QAAc,aAAW;AACvD,aAAS,MAAM;AACb;AACA,kBAAY;AAAA;AAAA;AAIhB,QAAM,eAAe,YAAY;AAC/B,WAAO,CAAC,WAAW;AACjB,UAAI;AACF,cAAM;AAAA,cACN;AAAA;AAIF,YAAM,QAAQ,KAAK;AAAA,QACjB,IAAI,QAAQ,aAAW,WAAW,SAAS;AAAA,QAC3C;AAAA;AAAA;AAAA;AAIN;AAEA,SAAO;AAAA;;4BCd0D;AAAA,EACjE,YACmB,iBACA,kBACA,gBACA,QACjB;AAJiB;AACA;AACA;AACA;AAAA;AAAA,QAeb,YACJ,MACA,SAC4B;AAC5B,UAAM,SAAS,oCAAS,WAAU;AAGlC,UAAM,oBAAoB,MAAM,KAAK,iBAAiB;AACtD,UAAM,mBAAmB,kBAAkB,KACzC,OAAK,KAAK,SAAS,EAAE,KAAK,QAAQ,KAAK,WAAW,EAAE,KAAK;AAE3D,UAAM,WAAqB,mBACvB,iBAAiB,OACjB;AAAA,MACE,IAAIC;AAAA,MACJ,MAAM,KAAK;AAAA,MACX,QAAQ,KAAK;AAAA;AAInB,UAAM,eAAe,MAAM,KAAK,eAAe,KAAK;AACpD,QAAI,OAAO,aAAa,eAAe,aAAa,OAAO,QAAQ;AACjE,YAAM,OAAO,aAAa,OAAO;AACjC,YAAM,KAAK;AAAA;AAQb,QAAI,CAAC,oBAAoB,CAAC,QAAQ;AAGhC,YAAM,KAAK,iBAAiB,YAAY;AAAA;AAE1C,QAAI,aAAa,SAAS,WAAW,GAAG;AACtC,aAAO,CAAE,UAAU,UAAU;AAAA;AAG/B,UAAM,kBAAkB,MAAM,KAAK,gBAAgB,yBACjD,aAAa,UACb;AAAA,MACE,YAAY,SAAS,SAAY,SAAS;AAAA,MAC1C;AAAA,MACA,gBAAgB;AAAA;AAIpB,UAAM,WAAW,gBAAgB,IAAI,OAAK,EAAE;AAE5C,WAAO,CAAE,UAAU;AAAA;AAAA,QAWf,sBAAqC;AACzC,UAAM,iBAAiB,QAAQ;AAC/B,UAAM,SAAS,KAAK,OAAO,MAAM;AAAA,MAC/B,WAAW;AAAA;AAGb,WAAO,KAAK;AAEZ,UAAM,YAAY,MAAM,KAAK,iBAAiB;AAC9C,WAAO,KAAK,+BAA+B,UAAU;AAErD,eAAW,CAAE,MAAM,aAAc,WAAW;AAC1C,aAAO,KACL,0CAA0CC,wCACxC;AAGJ,UAAI;AACF,cAAM,KAAK,sBAAsB,UAAU;AAC3C,cAAM,KAAK,iBAAiB,iBAAiB,SAAS,IAAI;AAAA,eACnD,GAAP;AACA,eAAO,KACL,iDAAiDA,wCAC/C,cACI,EAAE;AAEV,cAAM,KAAK,iBAAiB,iBAAiB,SAAS,IAAI;AAAA;AAAA;AAI9D,WAAO,KACL,qDAAqD,aACnD;AAAA;AAAA,QAMQ,sBACZ,UACA,gBACA;AACA,QAAI,iBAAiB,QAAQ;AAC7B,UAAM,SAAS,kBAAkB,KAAK;AAEtC,UAAM,eAAe,MAAM,KAAK,eAAe,KAAK;AAAA,MAClD,MAAM,SAAS;AAAA,MACf,QAAQ,SAAS;AAAA;AAGnB,eAAW,QAAQ,aAAa,QAAQ;AACtC,aAAO,KACL,2BAA2BA,wCACzB,KAAK,cACD,KAAK,MAAM;AAAA;AAIrB,WAAO,KACL,QACE,aAAa,SAAS,iCACGA,wCACzB,gBACM,aAAa;AAGvB,qBAAiB,QAAQ;AAEzB,QAAI;AACF,YAAM,KAAK,gBAAgB,yBACzB,aAAa,UACb,CAAE,YAAY,SAAS;AAAA,aAElB,GAAP;AACA,iBAAW,UAAU,aAAa,UAAU;AAC1C,cAAM,KAAK,iBAAiB,iBAC1B,SAAS,IACT,GACA,OAAO,OAAO,SAAS;AAAA;AAG3B,YAAM;AAAA;AAGR,WAAO,MAAM;AAEb,UAAM,KAAK,iBAAiB,iBAC1B,SAAS,IACT,aAAa,SAAS,IAAI,OAAK,EAAE,OAAO,SAAS;AAGnD,WAAO,KACL,SACE,aAAa,SAAS,iCACGA,wCACzB,gBACM,aAAa;AAAA;AAAA;;uBC/LzB,YACA,SACwB;AACxB,SAAO;AAAA,IACL,MAAM;AAAA,IACN,UAAU;AAAA,IACV,OAAO,IAAIP,qBAAc;AAAA;AAAA;oBAK3B,YACA,SACwB;AACxB,SAAO;AAAA,IACL,MAAM;AAAA,IACN,UAAU;AAAA,IACV,OAAO,IAAIf,kBAAW;AAAA;AAAA;sBAKxB,YACA,SACwB;AACxB,SAAO,CAAE,MAAM,SAAS,UAAU,YAAY,OAAO,IAAI,MAAM;AAAA;kBAI/D,aACA,UACwB;AACxB,SAAO,CAAE,MAAM,YAAY,UAAU,aAAa;AAAA;gBAIlD,YACA,WACwB;AACxB,SAAO,CAAE,MAAM,UAAU,UAAU,YAAY,QAAQ;AAAA;kBAGhC,MAAkD;AACzE,SAAO,CAAE,MAAM,YAAY,UAAU;AAAA;;;;;;;;;;;;AC1BvC,MAAM,YAAY;sBAeqC;AAAA,EAGrD,YAAY,SAAkB;AAC5B,SAAK,UAAU;AAAA;AAAA,QAGX,KAAKuB,YAAqD;AAC9D,UAAM,CAAE,eAAe,UAAW,KAAK;AAEvC,UAAM,SAA6B;AAAA,MACjC,UAAU;AAAA,MACV,QAAQ;AAAA;AAEV,QAAI,QAAkC,CAACC,SAAgBD,YAAU;AAEjE,aAAS,QAAQ,GAAG,QAAQ,WAAW,EAAE,OAAO;AAC9C,YAAM,WAAqC;AAC3C,YAAM,OAA6B,OAAK,SAAS,KAAK;AAEtD,iBAAW,QAAQ,OAAO;AACxB,YAAI,KAAK,SAAS,YAAY;AAC5B,gBAAM,KAAK,eAAe,MAAM;AAAA,mBACvB,KAAK,SAAS,UAAU;AACjC,cAAI,cAAc,UAAU,KAAK,QAAQ,KAAK,WAAW;AACvD,kBAAM,YAAY;AAElB,kBAAM,SAAS,MAAM,KAAK,aACxB,MACA,gBAAc;AACZ,kBAAI,WAAW,SAAS,YAAY;AAClC,0BAAU,KAAK,WAAW;AAC1B;AAAA;AAEF,mBAAK;AAAA,eAEPA;AAGF,gBAAI,QAAQ;AACV,qBAAO,SAAS,KAAK;AAAA,gBACnB;AAAA,gBACA,UAAU,KAAK;AAAA,gBACf;AAAA;AAAA;AAAA,iBAGC;AACL,mBAAO,OAAO,KAAK;AAAA,cACjB,UAAU,KAAK;AAAA,cACf,OAAO,IAAIE,uBACT,kBACE,KAAK,OAAO,qCACmBH,wCAC/B,KAAK;AAAA;AAAA;AAAA,mBAKJ,KAAK,SAAS,SAAS;AAChC,gBAAM,KAAK,YAAY,MAAM;AAC7B,iBAAO,OAAO,KAAK;AAAA,YACjB,UAAU,KAAK;AAAA,YACf,OAAO,KAAK;AAAA;AAAA;AAAA;AAKlB,UAAI,SAAS,WAAW,GAAG;AACzB,eAAO;AAAA;AAGT,cAAQ;AAAA;AAGV,UAAM,UAAU,uBAAuB,kCAAkCC,WAAS,QAAQA,WAAS;AACnG,WAAO,KAAK;AACZ,WAAO,OAAO,KAAK,WAAEA,YAAU,OAAO,IAAI,MAAM;AAChD,WAAO;AAAA;AAAA,QAGK,eACZ,MACA,MACA;AACA,UAAM,CAAE,YAAY,UAAW,KAAK;AAEpC,UAAM,gBAAsC,gBAAc;AACxD,UAAI,WAAW,SAAS,YAAY;AAClC,cAAM,IAAI,MAAM;AAAA;AAElB,UACE,WAAW,SAAS,cACpB,WAAW,SAAS,SAAS,KAAK,SAAS,QAC3C,WAAW,SAAS,WAAW,KAAK,SAAS,QAC7C;AAIA;AAAA;AAEF,WAAK;AAAA;AAGP,eAAW,aAAa,YAAY;AAClC,UAAI,UAAU,cAAc;AAC1B,YAAI;AACF,cACE,MAAM,UAAU,aACd,KAAK,UACL,KAAK,UACL,eACA,KAAK,QAAQ,SAEf;AACA;AAAA;AAAA,iBAEK,GAAP;AACA,gBAAM,WAAU,aACd,UAAU,YAAY,8CACkBD,wCACxC,KAAK,cACD;AACN,eAAKI,aAAoB,KAAK,UAAU;AACxC,iBAAO,KAAK;AAAA;AAAA;AAAA;AAKlB,UAAM,UAAU,0CAA0CJ,wCACxD,KAAK;AAEP,SAAKK,WAAkB,KAAK,UAAU;AACtC,WAAO,KAAK;AAAA;AAAA,QAGA,aACZ,MACA,MACA,gBAC6B;AApMjC;AAqMI,UAAM,CAAE,YAAY,UAAW,KAAK;AAEpC,QAAI,UAAU,KAAK;AAInB,UAAM,OAAO,QAAQ,QAAQ;AAC7B,UAAM,YAAY,CAAC,QAAQ,WACvB,KACA,cAAQ,SAAS,cAAjB,YAA8BhB;AAClC,UAAM,OAAO,CAAC,QAAQ,WAAW,KAAK,QAAQ,SAAS;AAEvD,eAAW,aAAa,YAAY;AAClC,UAAI,UAAU,kBAAkB;AAC9B,YAAI;AACF,oBAAU,MAAM,UAAU,iBACxB,SACA,KAAK,UACL,MACA;AAAA,iBAEK,GAAP;AACA,gBAAM,UAAU,aACd,UAAU,YAAY,kDACsB,QAAQ,aAAa,WAAWW,wCAC5E,KAAK,cACD;AACN,eAAKI,aAAoB,KAAK,UAAU,EAAE;AAC1C,iBAAO,KAAK;AACZ,iBAAO;AAAA;AAAA;AAAA;AAKb,QAAI;AACF,YAAM,OAAO,MAAM,KAAK,QAAQ,OAAO,QAAQ;AAC/C,UAAI,CAAC,MAAM;AACT,cAAM,UAAU,+DAA+D,QAAQ,aAAa,WAAWJ,wCAC7G,KAAK;AAEP,aAAKI,aAAoB,KAAK,UAAU;AACxC,eAAO,KAAK;AACZ,eAAO;AAAA;AAET,gBAAU;AAAA,aACH,GAAP;AACA,YAAM,UAAU,8CAA8C,QAAQ,aAAa,WAAWJ,wCAC5F,KAAK,cACD;AACN,WAAKK,WAAkB,KAAK,UAAU,EAAE;AACxC,aAAO,KAAK;AACZ,aAAO;AAAA;AAGT,QAAI,UAAU;AACd,eAAW,aAAa,YAAY;AAClC,UAAI,UAAU,oBAAoB;AAChC,YAAI;AACF,oBAAU,MAAM,UAAU,mBAAmB;AAC7C,cAAI,SAAS;AACX;AAAA;AAAA,iBAEK,GAAP;AACA,gBAAM,UAAU,aACd,UAAU,YAAY,mDACuB,QAAQ,aAAa,WAAWL,wCAC7E,KAAK,cACD;AACN,eAAKK,WAAkB,KAAK,UAAU;AACtC,iBAAO,KAAK;AACZ,iBAAO;AAAA;AAAA;AAAA;AAIb,QAAI,CAAC,SAAS;AACZ,YAAM,UAAU,sCAAsC,QAAQ,aAAa,WAAWL,wCACpF,KAAK;AAEP,WAAKK,WAAkB,KAAK,UAAU;AACtC,aAAO,KAAK;AACZ,aAAO;AAAA;AAGT,eAAW,aAAa,YAAY;AAClC,UAAI,UAAU,mBAAmB;AAC/B,YAAI;AACF,oBAAU,MAAM,UAAU,kBACxB,SACA,KAAK,UACL;AAAA,iBAEK,GAAP;AACA,gBAAM,UAAU,aACd,UAAU,YAAY,mDACuB,QAAQ,aAAa,WAAWL,wCAC7E,KAAK,cACD;AACN,eAAKI,aAAoB,KAAK,UAAU;AACxC,iBAAO,KAAK;AACZ,iBAAO;AAAA;AAAA;AAAA;AAKb,WAAO;AAAA;AAAA,QAGK,YACZ,MACA,MACA;AACA,UAAM,CAAE,YAAY,UAAW,KAAK;AAEpC,WAAO,MACL,iCAAiCJ,wCAC/B,KAAK,cACD,KAAK;AAGb,UAAM,gBAAsC,gBAAc;AACxD,UAAI,WAAW,SAAS,YAAY;AAClC,cAAM,IAAI,MAAM;AAAA;AAGlB,WAAK;AAAA;AAGP,eAAW,aAAa,YAAY;AAClC,UAAI,UAAU,aAAa;AACzB,YAAI;AACF,gBAAM,UAAU,YAAY,KAAK,OAAO,KAAK,UAAU;AAAA,iBAChD,GAAP;AACA,gBAAM,UAAU,aACd,UAAU,YAAY,uDAC2BA,wCACjD,KAAK,cACD;AACN,eAAKI,aAAoB,KAAK,UAAU;AACxC,iBAAO,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;;sCC7SmD;AAAA,EACvE,YAA6B,SAAkB;AAAlB;AAAA;AAAA,QAEvB,iBACJ,QACA,UACA,GACA,gBACiB;AACjB,UAAM,CAAE,gBAAiB,KAAK;AAC9B,QAAI;AACJ,QAAI;AACJ,QAAI;AAEJ,QAAI,SAAS,SAAS,OAAO;AAC3B,YAAM,iBAAiB,aAAa,MAAM,SAAS;AAEnD,gBAAU,SAAS;AACnB,gBAAU,iDAAgB,eAAe,SAAS;AAElD,YAAM,YAAY,iDAAgB,WAAW;AAAA,QAC3C,KAAK;AAAA,QACL,MAAM,SAAS;AAAA;AAGjB,UAAI,WAAW;AACb,yBAAiBJ,wCAA2B;AAAA,UAC1C,MAAM;AAAA,UACN,QAAQ;AAAA;AAAA;AAAA;AAKd,WAAOM,aACL;AAAA,MACE,UAAU;AAAA,QACR,aAAaC,cACX;AAAA,WACGrB,mCAAsBc,wCAA2B;AAAA,WACjDQ,0CAA6BR,wCAC5B;AAAA,WAEDS,mCAAsB;AAAA,WACtBC,mCAAsB;AAAA,WACtBC,0CAA6B;AAAA,WAEhCC;AAAA;AAAA,OAIN;AAAA;AAAA;;AC3DN,MAAM,4BAA4B;qCAEsC;AAAA,EACtE,YACmB,MACjB;AADiB;AAAA;AAAA,SAGZ,WAAW,QAAgD;AAChE,WAAO,IAAI,+BAA+B;AAAA,MACxC,wBAAwBC,4BAAgB,WAAW;AAAA;AAAA;AAAA,QAIjD,iBACJ,QACA,UACiB;AAzCrB;AA0CI,QAAI,OAAO,SAAS,eAAe,SAAS,SAAS,OAAO;AAC1D,aAAO;AAAA;AAGT,UAAM,iBAAiB,KAAK,KAAK,uBAAuB,MACtD,SAAS;AAGX,QAAI,CAAC,kBAAkB,eAAe,SAAS,UAAU;AACvD,aAAO;AAAA;AAGT,UAAM,SAASC,gCAAY,SAAS;AACpC,QAAI,oBACF,aAAO,SAAS,gBAAhB,mBAA8B;AAEhC,QAAI,CAAC,mBAAmB;AACtB,0BAAoB,GAAG,OAAO,SAAS,OAAO;AAAA;AAGhD,WAAOR,aACL;AAAA,MACE,UAAU;AAAA,QACR,aAAaC,cACX;AAAA,WACG,4BAA4B;AAAA,WAE/BK;AAAA;AAAA,OAIN;AAAA;AAAA;;mCC5CJ,QAC+B;AAC/B,QAAM,iBAAiB,OAAO,kBAAkB;AAEhD,QAAM,UAAU,iDAAgB,kBAAkB;AAClD,SAAO;AAAA,IACL;AAAA;AAAA;;ACPJ,MAAM,0BAA0B;AAChC,MAAM,gBAAgB;AAEtB,MAAM,uBAA+B;AACrC,MAAM,iBAAyB;AAC/B,MAAM,0BAAkC;2CAOsC;AAAA,SAKrE,WAAW,QAAgB,SAA6B;AAC7D,UAAM,IAAI,OAAO,kBAAkB;AACnC,WAAO,IAAI,qCAAqC;AAAA,SAC3C;AAAA,MACH,UAAU,IAAI,0BAA0B,KAAK;AAAA;AAAA;AAAA,SAIlC,iBACb,QACyB;AACzB,UAAM,UAAU,OAAO;AACvB,QAAI,CAAC,SAAS;AACZ,aAAO;AAAA;AAGT,WAAO,IAAIG,wBAAI,8BAA8B;AAAA,MAC3C,QAAQ;AAAA,QACN,iBAAiB;AAAA,QACjB,SAAS;AAAA;AAAA;AAAA;AAAA,EAKf,YAAY,SAGT;AACD,SAAK,WAAW,QAAQ;AACxB,SAAK,SAAS,QAAQ;AACtB,UAAM,cAAc,qCAAqC,iBACvD,KAAK;AAEP,SAAK,gBAAgB,IAAIA,wBAAI,cAAc;AAAA,MACzC;AAAA,MACA,QAAQ;AAAA;AAAA;AAAA,EAIZ,cAAc,MAAsB;AAClC,WAAO,KACJ,OACA,oBACA,QAAQ,mBAAmB;AAAA;AAAA,EAGhC,0BACE,KAC+C;AAC/C,UAAM,QAAQ,IAAI,MAAM;AAExB,WAAO;AAAA,MACL,WAAW,MAAM,MAAM,SAAS;AAAA,MAChC,gBAAgB,MAAM,MAAM,SAAS;AAAA;AAAA;AAAA,QAInC,iBAAqC;AACzC,QAAI,cAAyB;AAC7B,QAAI,mBAAmB;AACvB,QAAI,YAAY;AAChB,WAAO,oBAAoB,WAAW;AACpC,yBAAmB;AACnB,YAAM,cAAoC,MAAM,KAAK,cAClD,aAAa,CAAE,WAAW,YAC1B;AACH,UAAI,YAAY,UAAU;AACxB,sBAAc,YAAY,OAAO,YAAY;AAAA;AAE/C,kBAAY,YAAY;AAAA;AAG1B,WAAO;AAAA;AAAA,EAGT,sBAAsB,SAA0C;AAC9D,UAAM,CAAE,WAAW,kBAAmB,KAAK,0BACzC,QAAQ;AAEV,WAAO;AAAA,MACL,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR,aAAa;AAAA,WACV,uBAAuB;AAAA,WACvB,iBAAiB,QAAQ,OAAO;AAAA,WAChC,0BAA0B;AAAA;AAAA,QAE7B,MAAM,KAAK,cAAc,QAAQ,QAAQ;AAAA,QACzC,WAAW;AAAA;AAAA,MAEb,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,OAAO;AAAA;AAAA;AAAA;AAAA,QAKP,aACJ,UACA,WACA,MACkB;AAClB,QAAI,SAAS,SAAS,eAAe;AACnC,aAAO;AAAA;AAGT,IAAC,OAAM,KAAK,kBACT,IAAI,aAAW,KAAK,sBAAsB,UAC1C,OAAO,YAAU;AAChB,UAAI,SAAS,WAAW,IAAI;AAC1B,YAAI,OAAO,SAAS,aAAa;AAC/B,iBACE,OAAO,SAAS,YAAY,6BAC5B,SAAS;AAAA;AAGb,eAAO;AAAA;AAET,aAAO;AAAA,OAER,QAAQ,CAACC,aAAmC;AAC3C,WAAKC,OAAe,UAAUD;AAAA;AAGlC,WAAO;AAAA;AAAA;;sBCpJkB;AAAA,EAG3B,YAAY,SAAiD;AAC3D,SAAK,SAAS,QAAQ;AAAA;AAAA,QAGlB,aAAa,SAAoD;AACrE,WAAO,KAAK,aAAa,GAAG,KAAK,OAAO,uBAAuB;AAAA;AAAA,QAG3D,iBACJ,YACA,SAC6B;AAC7B,WAAO,KAAK,aACV,GAAG,KAAK,OAAO,uBAAuB,oBACtC;AAAA;AAAA,QAIU,aACZ,UACA,SAC6B;AAC7B,UAAM,UAAU,IAAI,IAAI;AACxB,eAAW,OAAO,SAAS;AACzB,UAAI,QAAQ,MAAM;AAChB,gBAAQ,aAAa,OAAO,KAAK,QAAQ,KAAM;AAAA;AAAA;AAInD,UAAM,WAAW,MAAME,0BACrB,QAAQ,YACRC,uCAA2B,KAAK;AAElC,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,IAAI,MACR,qCAAqC,QAAQ,oCAC3C,SAAS,YACL,SAAS;AAAA;AAGnB,WAAO,SAAS,OAAO,KAAK,kBAAgB;AAC1C,aAAO;AAAA;AAAA;AAAA;0BAqBX,SACA,SACA;AACA,QAAM,OAAO,WAAW,CAAE,OAAO;AACjC,MAAI;AACJ,KAAG;AACD,UAAM,MAAM,QAAQ;AACpB,SAAK,QAAQ,IAAI;AACjB,eAAW,QAAQ,IAAI,QAAQ;AAC7B,YAAM;AAAA;AAAA,WAED,CAAC,IAAI;AAAA;;MCxEH,0BAAqD,yCAAwC;AAAA,EACxG;AAAA,GACC;AACD,QAAMC,SACJ;AAAA,IACE,MAAM;AAAA,IACN;AAAA,KAKF;AAAA;;kCCLiE;AAAA,SAK5D,WACL,QACA,SACA;AACA,UAAM,eAAeP,4BAAgB,WAAW;AAEhD,WAAO,IAAI,4BAA4B;AAAA,SAClC;AAAA,MACH;AAAA;AAAA;AAAA,EAIJ,YAAY,SAIT;AACD,SAAK,eAAe,QAAQ;AAC5B,SAAK,SAAS,QAAQ,UAAU;AAChC,SAAK,SAAS,QAAQ;AAAA;AAAA,QAGlB,aACJ,UACA,WACA,MACkB;AAClB,QAAI,SAAS,SAAS,uBAAuB;AAC3C,aAAO;AAAA;AAGT,UAAM,cAAc,KAAK,aAAa,UAAU,MAAM,SAAS;AAC/D,QAAI,CAAC,aAAa;AAChB,YAAM,IAAI,MACR,kDAAkD,SAAS;AAAA,eAEpD,YAAY,OAAO,SAAS,iBAAiB;AACtD,YAAM,IAAI,MACR;AAAA;AAIJ,UAAM,SAAS,IAAI,gBAAgB;AAAA,MACjC,QAAQ,YAAY;AAAA;AAEtB,UAAM,iBAAiB,KAAK;AAC5B,SAAK,OAAO,KAAK,uCAAuC,SAAS;AAEjE,UAAM,CAAE,eAAgB,SAAS,SAAS;AAE1C,UAAM,SAAS,MAAM,iBAAiB,QAAQ,SAAS;AAEvD,eAAW,cAAc,OAAO,SAAS;AACvC,uBAAiB,UAAU,KAAK,OAAO;AAAA,QACrC;AAAA,QACA,QAAQ,GAAG,WAAW,MAAM,KAAK,GAAG,OAAO;AAAA,QAC3C,QAAQ,KAAK;AAAA,UACX;AACF,aAAK;AAAA;AAAA;AAIT,UAAM,WAAa,OAAK,QAAQ,kBAAkB,KAAM,QAAQ;AAChE,SAAK,OAAO,MACV,QAAQ,OAAO,mCAAmC,OAAO,QAAQ,mCAAmC;AAGtG,WAAO;AAAA;AAAA;gCAKT,QACA,QACiB;AACjB,QAAM,CAAE,mBAAmB,kBAAmB,SAAS;AACvD,QAAM,WAAW,UAAU,aAAW,OAAO,aAAa;AAC1D,QAAM,SAAiB;AAAA,IACrB,SAAS;AAAA,IACT,SAAS;AAAA;AAGX,mBAAiB,WAAW,UAAU;AACpC,QAAI,CAAC,kBAAkB,KAAK,QAAQ,MAAM;AACxC;AAAA;AAEF,UAAM,eAAe,UAAU,aAC7B,OAAO,iBAAiB,QAAQ,KAAK;AAEvC,qBAAiB,cAAc,cAAc;AAC3C,aAAO;AACP,UAAI,eAAe,KAAK,WAAW,OAAO;AACxC,eAAO,QAAQ,KAAK;AAAA;AAAA;AAAA;AAI1B,SAAO;AAAA;AAGT,kBACE,WAC4E;AAC5E,QAAM,MAAM,IAAI,IAAI;AACpB,QAAM,OAAO,IAAI,SAAS,OAAO,GAAG,MAAM;AAG1C,MAAI,KAAK,SAAS,KAAK,KAAK,GAAG,UAAU,KAAK,GAAG,QAAQ;AACvD,WAAO;AAAA,MACL,mBAAmB,aAAa,mBAAmB,KAAK;AAAA,MACxD,gBAAgB,aAAa,mBAAmB,KAAK;AAAA,MACrD,aAAa,IAAI,mBAAmB,KAAK,MAAM,GAAG,KAAK;AAAA;AAAA;AAI3D,QAAM,IAAI,MAAM,mBAAmB;AAAA;AAGrC,sBAAsB,KAAqB;AACzC,SAAO,IAAI,OAAO,IAAI,IAAI,QAAQ,OAAO;AAAA;;kCClG0B;AAAA,EAA9D,cAzDP;AA0DmB,sBAAa;AAAA,MAC5BQ;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA;AAAA;AAAA,QAGI,mBAAmB,QAAkC;AACzD,eAAW,aAAa,KAAK,YAAY;AACvC,YAAM,UAAU,MAAM,UAAU,MAAM;AACtC,UAAI,SAAS;AACX,eAAO;AAAA;AAAA;AAIX,WAAO;AAAA;AAAA,QAGH,kBACJ,QACA,WACA,MACiB;AACjB,UAAM,UAAUjD,2BAAc;AAM9B,oBACE,SACA,SACA,kBACA,kBACM;AACN,UAAI,CAAC,SAAS;AACZ;AAAA;AAEF,iBAAW,UAAU,CAAC,SAAS,QAAQ;AACrC,cAAM,YAAYkD,4BAAe,QAAQ;AACzC,YAAI,UAAU,SAAS,QAAW;AAChC,gBAAM,IAAI,MACR,qBAAqB;AAAA;AAGzB,aACEC,SAAgB;AAAA,UACd,QAAQ;AAAA,UACR,MAAM;AAAA,UACN,QAAQ;AAAA,YACN,MAAM,UAAU;AAAA,YAChB,WAAW,UAAU;AAAA,YACrB,MAAM,UAAU;AAAA;AAAA;AAItB,aACEA,SAAgB;AAAA,UACd,QAAQ;AAAA,YACN,MAAM,UAAU;AAAA,YAChB,WAAW,UAAU;AAAA,YACrB,MAAM,UAAU;AAAA;AAAA,UAElB,MAAM;AAAA,UACN,QAAQ;AAAA;AAAA;AAAA;AAShB,QAAI,OAAO,SAAS,YAAY;AAC9B,YAAM,WAAW;AACjB,aACE,SAAS,KAAK,OACd,CAAE,aAAa,SAAS,kBAAkB,QAAQ,YAClDC,gCACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,aAAa;AAC/B,YAAM,YAAY;AAClB,aACE,UAAU,KAAK,OACf,CAAE,aAAa,SAAS,kBAAkB,QAAQ,YAClDD,gCACAC;AAEF,aACE,UAAU,KAAK,gBACf,CAAE,aAAa,aAAa,kBAAkB,QAAQ,YACtDC,+BACAC;AAEF,aACE,UAAU,KAAK,cACf,CAAE,aAAa,OAAO,kBAAkB,QAAQ,YAChDC,oCACAC;AAEF,aACE,UAAU,KAAK,cACf,CAAE,aAAa,OAAO,kBAAkB,QAAQ,YAChDC,oCACAC;AAEF,aACE,UAAU,KAAK,WACf,CAAE,kBAAkB,QAAQ,YAC5BC,kCACAC;AAEF,aACE,UAAU,KAAK,QACf,CAAE,aAAa,UAAU,kBAAkB,QAAQ,YACnDP,+BACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,OAAO;AACzB,YAAM,MAAM;AACZ,aACE,IAAI,KAAK,OACT,CAAE,aAAa,SAAS,kBAAkB,QAAQ,YAClDH,gCACAC;AAEF,aACE,IAAI,KAAK,QACT,CAAE,aAAa,UAAU,kBAAkB,QAAQ,YACnDC,+BACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,YAAY;AAC9B,YAAM,WAAW;AACjB,aACE,SAAS,KAAK,OACd,CAAE,aAAa,SAAS,kBAAkB,QAAQ,YAClDH,gCACAC;AAEF,aACE,SAAS,KAAK,WACd,CAAE,kBAAkB,QAAQ,YAC5BO,kCACAC;AAEF,aACE,SAAS,KAAK,QACd,CAAE,aAAa,UAAU,kBAAkB,QAAQ,YACnDP,+BACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,QAAQ;AAC1B,YAAM,OAAO;AACb,aACE,KAAK,KAAK,UACV,CAAE,aAAa,SAAS,kBAAkB,QAAQ,YAClDO,iCACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,SAAS;AAC3B,YAAM,QAAQ;AACd,aACE,MAAM,KAAK,QACX,CAAE,aAAa,SAAS,kBAAkB,QAAQ,YAClDC,gCACAC;AAEF,aACE,MAAM,KAAK,UACX,CAAE,aAAa,SAAS,kBAAkB,QAAQ,YAClDA,iCACAD;AAEF,aACE,MAAM,KAAK,SACX,CAAE,aAAa,QAAQ,kBAAkB,QAAQ,YACjDD,kCACAD;AAAA;AAQJ,QAAI,OAAO,SAAS,UAAU;AAC5B,YAAM,SAAS;AACf,aACE,OAAO,KAAK,OACZ,CAAE,aAAa,SAAS,kBAAkB,QAAQ,YAClDV,gCACAC;AAEF,aACE,OAAO,KAAK,QACZ,CAAE,aAAa,UAAU,kBAAkB,QAAQ,YACnDC,+BACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,UAAU;AAC5B,YAAM,SAAS;AACf,aACE,OAAO,KAAK,OACZ,CAAE,aAAa,SAAS,kBAAkB,QAAQ,YAClDH,gCACAC;AAAA;AAIJ,WAAO;AAAA;AAAA;;0BClST,UACA,UAAU,KACU;AACpB,QAAM,SAASa,iBAAiB;AAEhC,SAAOC,QACLC,UAAO,CAAC,MAAuB,EAAE,YAAY,UAC7CC,YACAC,SACAC,OAAI,WACJD,SACA,oBACA;AAAA;4BAG+B,OAAe;AAChD,MAAI,MAAM,MAAM,aAAa;AAC3B,WAAO,MAAM,MAAM,KAAK;AAAA,aACf,MAAM,MAAM,SAAS;AAC9B,WAAO,MAAM,UAAU;AAAA,aACd,MAAM,MAAM,gBAAgB;AACrC,WAAO,MAAM,MAAM,KAAK;AAAA;AAG1B,SAAO;AAAA;;AC7BT,MAAM,aAAa;MAEN,qBAA+C;AAAA,EAE1D,WAAW,CAAC,YAAY,cAAc;AAAA,EAGtC,QAAQ,CAAC,YAAY,WAAW,cAAc,QAAQ;AAAA,EAGtD,QAAQ,CAAC,YAAY,WAAW,cAAc,QAAQ;AAAA;;8BCFtD,QACA,WACA,iBAC6B;AAC7B,QAAM,oBAAoB,OAAO,SAAkC;AACjE,UAAM,MAAM,GAAG,YAAY;AAC3B,UAAM,OAAO,MAAM,OAAO,KAAK;AAC/B,WAAO,KAAK;AAAA;AAGd,QAAM,aAAa,gBAAgB,IAAI;AAEvC,SAAO,QAAQ,IAAI,YAAY,MAAM,CAAC,mBAAmC;AACvE,UAAM,YAAY,eAAe,OAAO,KACtC,WAAS,mBAAmB1D;AAG9B,QAAI,WAAW;AACb,YAAM;AAAA;AAGR,WAAO;AAAA;AAAA;qCAKT,QACA,WACA,gBAC6B;AArD/B;AAsDE,QAAM,kBAAkB,mBAAmB,uDAAgB,SAAhB,YAAwB;AAEnE,QAAM,YAAY,iDAAgB,WAAW;AAAA,IAC3C,KAAK;AAAA,IACL,MAAM;AAAA;AAGR,MAAI,CAAC,aAAa,CAAC,iBAAiB;AAClC,WAAO;AAAA;AAGT,QAAM,WAAW,MAAM,eAAe,QAAQ,WAAW;AAEzD,MAAI,CAAC,UAAU;AACb,WAAO;AAAA;AAGT,QAAM,QAAQ,iBAAiB;AAE/B,SAAO;AAAA;;ACjDT,MAAM,gBAAgB,CAAC,OAAO,aAAa,UAAU,YAAY;AAEjE,MAAM,yBAAyB;AAAA,EAC7B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;0BAG2D;AAAA,SAKpD,WACL,QACA,SACA;AACA,UAAM,eAAeoB,4BAAgB,WAAW;AAEhD,WAAO,IAAI,oBAAoB;AAAA,SAC1B;AAAA,MACH;AAAA;AAAA;AAAA,EAIJ,YAAY,SAIT;AACD,SAAK,eAAe,QAAQ;AAC5B,SAAK,SAAS,QAAQ;AACtB,SAAK,SAAS,QAAQ;AAAA;AAAA,QAGlB,iBACJ,QACA,UACiB;AAEjB,QACE,CAAC,UACD,CAAC,cAAc,SAAS,OAAO,SAC/B,CAAC,uBAAuB,SAAS,SAAS,SACzC,OAAO,QAAQ,OAAO,KAAK,OAC5B;AACA,aAAO;AAAA;AAGT,UAAM,iBAAiB,KAAK,aAAa,MAAM,SAAS;AACxD,QAAI,CAAC,gBAAgB;AACnB,aAAO;AAAA;AAGT,UAAM,QAAQ,MAAM,sBAClB,KAAK,QACL,SAAS,QACT;AAGF,QAAI,CAAC,OAAO;AACV,WAAK,OAAO,MACV,kDAAkD,SAAS;AAE7D,aAAO;AAAA;AAGT,WAAO;AAAA,SACF;AAAA,MACH,MAAM,IAAK,OAAO,MAAM;AAAA;AAAA;AAAA;;0BCtE5B,MACA,UACkC;AA7BpC;AA8BE,MAAI;AACJ,MAAI;AACF,gBAAYwC,yBAAK,kBAAkB,KAAK,SAAS,SAAS,OAAO,OAAK;AAAA,WAC/D,GAAP;AACA,UAAM,MAAMrD,wCAA2B;AACvC,UAAM,UAAU,2BAA2B,QAAQ;AACnD,UAAMI,aAAoB,UAAU;AACpC;AAAA;AAGF,aAAW,YAAY,WAAW;AAChC,QAAI,eAAS,WAAT,mBAAiB,QAAQ;AAC3B,YAAM,MAAMJ,wCAA2B;AACvC,YAAM,UAAU,iBAAiB,QAAQ,SAAS,OAAO;AACzD,YAAMI,aAAoB,UAAU;AAAA,WAC/B;AACL,YAAM,OAAO,SAAS;AACtB,UAAIzB,2BAAO,cAAc,OAAO;AAC9B,cAAM2E,OAAc,UAAU;AAAA,iBACrB,SAAS,MAAM,OAGnB;AACL,cAAM,UAAU,gCAAgC,OAAO;AACvD,cAAMlD,aAAoB,UAAU;AAAA;AAAA;AAAA;AAAA;MAM/B,0BAAkD,yCAAwC;AAAA,EACrG;AAAA,EACA;AAAA,GACC;AACD,aAAW,KAAK,gBAAgB,MAAM,WAAW;AAC/C,UAAM;AAAA;AAAA;;ACxCV,MAAM,OAAOmD,eAAUC;0BAEsC;AAAA,QACrD,aACJ,UACA,UACA,MACkB;AAClB,QAAI,SAAS,SAAS,QAAQ;AAC5B,aAAO;AAAA;AAGT,QAAI;AACF,YAAM,cAAc,MAAM,KAAK,SAAS;AAExC,UAAI,YAAY,SAAS,GAAG;AAC1B,mBAAW,aAAa,aAAa;AACnC,gBAAM,OAAO,MAAMC,uBAAG,SAAS;AAI/B,qBAAW,eAAe,gBAAgB,MAAM;AAAA,YAC9C,MAAM;AAAA,YACN,QAAQC,yBAAK,UAAU;AAAA,cACrB;AACF,iBAAK;AAAA;AAAA;AAAA,iBAGA,CAAC,UAAU;AACpB,cAAM,UAAU,GAAG,SAAS,QAAQ,SAAS;AAC7C,aAAKC,cAAqB,UAAU;AAAA;AAAA,aAE/B,GAAP;AACA,YAAM,UAAU,GAAG,SAAS,QAAQ,SAAS,6BAA6B;AAC1E,WAAKvD,aAAoB,UAAU;AAAA;AAGrC,WAAO;AAAA;AAAA;;oCCgBT,QACA,KACA,WACkC;AAClC,QAAM,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAkBd,QAAM,SAAS,CAAC,SAAe;AAC7B,UAAM,SAAqB;AAAA,MACzB,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR,MAAM,KAAK;AAAA,QACX,aAAa;AAAA,UACX,yBAAyB,KAAK;AAAA;AAAA;AAAA,MAGlC,MAAM;AAAA,QACJ,SAAS;AAAA,QACT,UAAU;AAAA;AAAA;AAId,QAAI,KAAK;AAAK,aAAO,SAAS,cAAc,KAAK;AACjD,QAAI,KAAK;AAAM,aAAO,KAAK,QAAS,cAAc,KAAK;AACvD,QAAI,KAAK;AAAO,aAAO,KAAK,QAAS,QAAQ,KAAK;AAClD,QAAI,KAAK;AAAW,aAAO,KAAK,QAAS,UAAU,KAAK;AAExD,WAAO;AAAA;AAGT,QAAM,QAAQ,MAAM,gBAClB,QACA,OACA,OAAE;AA/HN;AA+HS,mBAAE,iBAAF,mBAAgB;AAAA,KACrB,QACA,CAAE,KAAK,OAAO,cAAc;AAG9B,SAAO,CAAE;AAAA;oCAYT,QACA,KAIC;AACD,QAAM,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAsBd,QAAM,mBAAmB,IAAI;AAE7B,QAAM,SAAS,OAAO,SAAe;AACnC,UAAM,SAAsB;AAAA,MAC1B,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR,MAAM,KAAK;AAAA,QACX,aAAa;AAAA,UACX,wBAAwB,KAAK;AAAA;AAAA;AAAA,MAGjC,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,UAAU;AAAA;AAAA;AAId,QAAI,KAAK,aAAa;AACpB,aAAO,SAAS,cAAc,KAAK;AAAA;AAErC,QAAI,KAAK,MAAM;AACb,aAAO,KAAK,QAAS,cAAc,KAAK;AAAA;AAE1C,QAAI,KAAK,WAAW;AAClB,aAAO,KAAK,QAAS,UAAU,KAAK;AAAA;AAEtC,QAAI,KAAK,YAAY;AACnB,aAAO,KAAK,SAAS,KAAK,WAAW;AAAA;AAGvC,UAAM,cAAwB;AAC9B,qBAAiB,IAAI,KAAK,MAAM;AAEhC,QAAI,CAAC,KAAK,QAAQ,SAAS,aAAa;AAEtC,iBAAW,QAAQ,KAAK,QAAQ,OAAO;AACrC,oBAAY,KAAK,KAAK;AAAA;AAAA,WAEnB;AAGL,YAAM,CAAE,WAAY,MAAM,eAAe,QAAQ,KAAK,KAAK;AAC3D,iBAAW,aAAa,SAAS;AAC/B,oBAAY,KAAK;AAAA;AAAA;AAIrB,WAAO;AAAA;AAGT,QAAM,SAAS,MAAM,gBACnB,QACA,OACA,OAAE;AAnON;AAmOS,mBAAE,iBAAF,mBAAgB;AAAA,KACrB,QACA,CAAE;AAGJ,SAAO,CAAE,QAAQ;AAAA;2CAIjB,QACA,KACyC;AACzC,QAAM,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAkBd,QAAM,eAAe,MAAM,gBACzB,QACA,OACA,OAAE;AApQN;AAoQS,mBAAE,oBAAF,mBAAmB;AAAA,KACxB,OAAK,GACL,CAAE;AAGJ,SAAO,CAAE;AAAA;8BAaT,QACA,KACA,UACgC;AAChC,QAAM,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAYd,QAAM,UAAU,MAAM,gBACpB,QACA,OACA,OAAE;AAzSN;AAySS,yBAAE,iBAAF,mBAAgB,SAAhB,mBAAsB;AAAA,KAC3B,UAAQ,KAAK,OACb,CAAE,KAAK;AAGT,SAAO,CAAE;AAAA;+BA0BT,QACA,OACA,YACA,QACA,WACuB;AACvB,QAAM,SAAuB;AAE7B,MAAI,SAA6B;AACjC,WAAS,IAAI,GAAG,IAAI,KAA4B,EAAE,GAAG;AACnD,UAAM,WAAqB,MAAM,OAAO,OAAO;AAAA,SAC1C;AAAA,MACH;AAAA;AAGF,UAAM,OAAO,WAAW;AACxB,QAAI,CAAC,MAAM;AACT,YAAM,IAAI,MAAM,sBAAsB,KAAK,UAAU;AAAA;AAGvD,eAAW,QAAQ,KAAK,OAAO;AAC7B,aAAO,KAAK,MAAM,OAAO;AAAA;AAG3B,QAAI,CAAC,KAAK,SAAS,aAAa;AAC9B;AAAA,WACK;AACL,eAAS,KAAK,SAAS;AAAA;AAAA;AAI3B,SAAO;AAAA;;+BCxUyD;AAAA,SAIzD,WAAW,QAAgB,SAA6B;AAC7D,UAAM,eAAeS,4BAAgB,WAAW;AAEhD,WAAO,IAAI,yBAAyB;AAAA,SAC/B;AAAA,MACH;AAAA;AAAA;AAAA,EAIJ,YAAY,SAA4D;AACtE,SAAK,eAAe,QAAQ;AAC5B,SAAK,SAAS,QAAQ;AAAA;AAAA,QAGlB,aACJZ,YACA,WACA,MACkB;AArDtB;AAsDI,QAAIA,WAAS,SAAS,oBAAoB;AACxC,aAAO;AAAA;AAGT,UAAM,eAAe,WAAK,aAAa,OAAO,MAAMA,WAAS,YAAxC,mBACjB;AACJ,QAAI,CAAC,cAAc;AACjB,YAAM,IAAI,MACR,+CAA+CA,WAAS;AAAA;AAG5D,UAAM,CAAE,WAAY,MAAM2D,sCAA0B,OAClD,cACA,eAAe,CAAE,KAAK3D,WAAS;AACjC,UAAM,CAAE,KAAK,gBAAgB,eAAgB4D,WAAS5D,WAAS;AAE/D,UAAM,SAAS6D,gBAAQ,SAAS;AAAA,MAC9B,SAAS,aAAa;AAAA,MACtB;AAAA;AAIF,UAAM,iBAAiB,KAAK;AAC5B,SAAK,OAAO,KAAK,oCAAoC7D,WAAS;AAE9D,UAAM,CAAE,gBAAiB,MAAM,4BAA4B,QAAQ;AACnE,UAAM,WAAW,aAAa,OAC5B,OAAK,CAAC,EAAE,cAAc,eAAe,KAAK,EAAE;AAG9C,UAAM,WAAa,OAAK,QAAQ,kBAAkB,KAAM,QAAQ;AAChE,SAAK,OAAO,MACV,QAAQ,aAAa,+BAA+B,SAAS,mCAAmC;AAGlG,eAAW,cAAc,UAAU;AACjC,WACEmB,SACE;AAAA,QACE,MAAM;AAAA,QACN,QAAQ,GAAG,WAAW,MAAM;AAAA,SAK9B;AAAA;AAKN,WAAO;AAAA;AAAA;oBAST,WAC8D;AAC9D,QAAM,MAAM,IAAI,IAAI;AACpB,QAAM,OAAO,IAAI,SAAS,OAAO,GAAG,MAAM;AAG1C,MAAI,KAAK,SAAS,KAAK,KAAK,GAAG,UAAU,KAAK,GAAG,QAAQ;AACvD,WAAO;AAAA,MACL,KAAK,mBAAmB,KAAK;AAAA,MAC7B,gBAAgB2C,eAAa,mBAAmB,KAAK;AAAA,MACrD,aAAa,IAAI,mBAAmB,KAAK,MAAM,GAAG,KAAK;AAAA;AAAA;AAI3D,QAAM,IAAI,MAAM,mBAAmB;AAAA;wBAGR,KAAqB;AAChD,SAAO,IAAI,OAAO,IAAI,IAAI,QAAQ,OAAO;AAAA;;2BCjHT,QAAuB;AACvD,QAAM,eAAe,IAAI,IAAI,OAAO,IAAI,OAAK,CAAC,EAAE,SAAS,MAAM;AAM/D,aAAW,SAAS,QAAQ;AAC1B,UAAM,WAAW,MAAM,SAAS;AAChC,UAAM,aAAa,MAAM,KAAK;AAC9B,QAAI,YAAY;AACd,YAAM,SAAS,aAAa,IAAI;AAChC,UAAI,UAAU,CAAC,OAAO,KAAK,SAAS,SAAS,WAAW;AACtD,eAAO,KAAK,SAAS,KAAK;AAAA;AAAA;AAAA;AAShC,aAAW,SAAS,QAAQ;AAC1B,UAAM,WAAW,MAAM,SAAS;AAChC,eAAW,aAAa,MAAM,KAAK,UAAU;AAC3C,YAAM,QAAQ,aAAa,IAAI;AAC/B,UAAI,SAAS,CAAC,MAAM,KAAK,QAAQ;AAC/B,cAAM,KAAK,SAAS;AAAA;AAAA;AAAA;AAAA;uBAQE,QAAuB,OAAqB;AACxE,QAAM,eAAe,IAAI,IAAI,OAAO,IAAI,OAAK,CAAC,EAAE,SAAS,MAAM;AAE/D,QAAM,QAAQ,UAAQ;AACpB,UAAM,qBAAqB,IAAI;AAE/B,UAAM,OAAO;AAAA,MACX,GAAG,KAAK,KAAK;AAAA,MACb,GAAG,OACA,OAAO,OAAE;AA9DlB;AA8DqB,uBAAE,KAAK,YAAP,mBAAgB,SAAS,KAAK,SAAS;AAAA,SACnD,IAAI,OAAK,EAAE,SAAS;AAAA;AAGzB,eAAS;AACP,YAAM,UAAU,KAAK;AACrB,UAAI,CAAC,SAAS;AACZ;AAAA;AAGF,UAAI,CAAC,mBAAmB,IAAI,UAAU;AACpC,2BAAmB,IAAI;AACvB,cAAM,QAAQ,aAAa,IAAI;AAC/B,YAAI,+BAAO,KAAK,QAAQ;AACtB,eAAK,KAAK,MAAM,KAAK;AAAA;AAAA;AAAA;AAK3B,SAAK,KAAK,WAAW,CAAC,GAAG;AAAA;AAAA;;+BC9CqC;AAAA,SAIzD,WAAW,QAAgB,SAA6B;AAC7D,UAAM,eAAelD,4BAAgB,WAAW;AAEhD,WAAO,IAAI,yBAAyB;AAAA,SAC/B;AAAA,MACH;AAAA;AAAA;AAAA,EAIJ,YAAY,SAA4D;AACtE,SAAK,eAAe,QAAQ;AAC5B,SAAK,SAAS,QAAQ;AAAA;AAAA,QAGlB,aACJ,UACA,WACA,MACkB;AAClB,QAAI,SAAS,SAAS,cAAc;AAClC,aAAO;AAAA;AAGT,UAAM,CAAE,QAAQ,aAAc,MAAM,KAAK,aAAa,SAAS;AAC/D,UAAM,CAAE,OAAQgD,WAAS,SAAS;AAGlC,UAAM,iBAAiB,KAAK;AAC5B,SAAK,OAAO,KAAK;AAEjB,UAAM,CAAE,SAAU,MAAM,qBAAqB,QAAQ,KAAK;AAC1D,UAAM,CAAE,QAAQ,oBAAqB,MAAM,qBACzC,QACA;AAGF,UAAM,WAAa,OAAK,QAAQ,kBAAkB,KAAM,QAAQ;AAChE,SAAK,OAAO,MACV,QAAQ,MAAM,2BAA2B,OAAO,2BAA2B;AAI7E,UAAM,cAAc,IAAI,IAAI,MAAM,IAAI,OAAK,CAAC,EAAE,SAAS,MAAM;AAC7D,eAAW,CAAC,WAAW,cAAc,iBAAiB,WAAW;AAC/D,iBAAW,YAAY,WAAW;AAChC,cAAM,OAAO,YAAY,IAAI;AAC7B,YAAI,QAAQ,CAAC,KAAK,KAAK,SAAS,SAAS,YAAY;AACnD,eAAK,KAAK,SAAS,KAAK;AAAA;AAAA;AAAA;AAI9B,sBAAkB;AAGlB,eAAW,SAAS,QAAQ;AAC1B,WAAK5C,OAAe,UAAU;AAAA;AAEhC,eAAW,QAAQ,OAAO;AACxB,WAAKA,OAAe,UAAU;AAAA;AAGhC,WAAO;AAAA;AAAA,QAGK,aACZ,QAC+D;AAzGnE;AA0GI,UAAM,eAAe,WAAK,aAAa,OAAO,MAAM,YAA/B,mBAAwC;AAE7D,QAAI,CAAC,cAAc;AACjB,YAAM,IAAI,MACR,gDAAgD;AAAA;AAIpD,UAAM,sBAAsB2C,sCAA0B,OAAO;AAC7D,UAAM;AAAA,MACJ;AAAA,MACA,MAAM;AAAA,QACJ,MAAM,oBAAoB,eAAe;AAAA,MAC3C,KAAK;AAAA;AAGP,UAAM,SAASE,gBAAQ,SAAS;AAAA,MAC9B,SAAS,aAAa;AAAA,MACtB;AAAA;AAGF,WAAO,CAAE,QAAQ;AAAA;AAAA;oBAQI,WAAoC;AAC3D,QAAM,OAAO,IAAI,IAAI,WAAW,SAAS,OAAO,GAAG,MAAM;AAGzD,MAAI,KAAK,WAAW,KAAK,KAAK,GAAG,QAAQ;AACvC,WAAO,CAAE,KAAK,mBAAmB,KAAK;AAAA;AAGxC,QAAM,IAAI,MAAM;AAAA;;qBCxHU,OAAkB;AAC5C,SAAO,GAAG,MAAM,QAAQ,MAAM,SAAS,MAAM;AAAA;;MCelC,oBAAgC;AAAA,EAC3C,iBAAiB;AAAA,EACjB,mBAAmB;AAAA,EACnB,uBAAuB,CAAC,OAAO,SAAS;AACtC,WAAO,OAAO,OAAO,MAAM,WAAS;AAClC,aAAO,MAAM;AAAA;AAAA;AAAA;MAKN,wBAAoC;AAAA,EAC/C,iBAAiB;AAAA,EACjB,mBAAmB;AAAA,EACnB,uBAAuB,CAAC,OAAO,SAAS;AACtC,UAAM,UAAU,CAAC,UAA2B;AAC1C,UAAI,SAAS,sBAAsB,mBAAmB;AACpD,eAAO,WAAW;AAAA;AAEpB,aAAO,MAAM;AAAA;AAEf,WAAO,OAAO,OAAO,MAAM;AAAA;AAAA;AAK/B,gBACE,OACA,eACA,SACU;AACV,QAAM,SAAS,MAAM,IAAI;AACzB,MAAI,MAAM,QAAQ,SAAS;AACzB,WAAO,OAAO,IAAI,OAAK;AACrB,aAAO,QAAQ;AAAA;AAAA,aAER,QAAQ;AACjB,WAAO,CAAC,QAAQ;AAAA;AAElB,SAAO;AAAA;AAKT,oBAAoB,YAAqC;AACvD,MAAI;AACJ,MAAI,OAAO,eAAe,UAAU;AAClC,WAAO,IAAI,OAAO,YAAY;AAAA,SACzB;AACL,WAAO;AAAA;AAGT,MAAI,WAAW;AAGf,WAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AAEpC,QAAI,UAAU,KAAK,GAAG,SAAS;AAC/B,cAAU,KAAK,MAAM,KAAK,UAAU,IAAI;AAGxC,eAAW,SAAS,QAAQ,IAAI,MAAM;AAAA;AAExC,SAAO;AAAA;;iBCtEe;AAAA,EAiCtB,YAA6B,QAAgB;AAAhB;AAAA;AAAA,eA9BhB,OACX,QACA,QACA,MACqB;AACrB,UAAM,SAASE,yBAAK,aAAa,CAAE,KAAK;AAKxC,WAAO,GAAG,SAAS,CAAC,QAAoB;AACtC,aAAO,KAAK,+BAA+B,YAAY;AAAA;AAGzD,QAAI,CAAC,MAAM;AACT,aAAO,IAAI,WAAW;AAAA;AAGxB,WAAO,IAAI,QAAoB,CAAC,SAAS,WAAW;AAClD,YAAM,CAAE,IAAI,UAAW;AACvB,aAAO,KAAK,IAAI,QAAQ,SAAO;AAC7B,YAAI,KAAK;AACP,iBAAO,wBAAwB,OAAO,YAAY;AAAA,eAC7C;AACL,kBAAQ,IAAI,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA,QAczB,OAAO,IAAY,SAAgD;AACvE,QAAI;AACF,aAAO,MAAM,IAAI,QAAuB,CAAC,SAAS,WAAW;AAC3D,cAAM,SAAwB;AAE9B,aAAK,OAAO,OAAO,IAAI,SAAS,CAAC,KAAK,QAAQ;AAC5C,cAAI,KAAK;AACP,mBAAO,IAAI,MAAM,YAAY;AAC7B;AAAA;AAGF,cAAI,GAAG,mBAAmB,MAAM;AAC9B,mBAAO,IAAI,MAAM;AAAA;AAGnB,cAAI,GAAG,eAAe,WAAS;AAC7B,mBAAO,KAAK;AAAA;AAGd,cAAI,GAAG,SAAS,OAAK;AACnB,mBAAO,IAAI,MAAM,YAAY;AAAA;AAG/B,cAAI,GAAG,OAAO,OAAK;AACjB,gBAAI,CAAC,GAAG;AACN,qBAAO,IAAI,MAAM;AAAA,uBACR,EAAE,WAAW,GAAG;AACzB,qBAAO,IAAI,MAAM,cAAc,EAAE,WAAW,EAAE;AAAA,mBACzC;AACL,sBAAQ;AAAA;AAAA;AAAA;AAAA;AAAA,aAKT,GAAP;AACA,YAAM,IAAI,MAAM,sBAAsB,eAAe,EAAE;AAAA;AAAA;AAAA,QAUrD,YAAiC;AACrC,QAAI,KAAK,QAAQ;AACf,aAAO,KAAK;AAAA;AAEd,SAAK,SAAS,KAAK,aAChB,KAAK,UAAQ;AA1HpB;AA2HQ,UAAI,oBAAa,QAAL,mBAAU,sBAAqB;AACzC,eAAO;AAAA;AAET,aAAO;AAAA,OAER,MAAM,SAAO;AACZ,WAAK,SAAS;AACd,YAAM;AAAA;AAEV,WAAO,KAAK;AAAA;AAAA,QAQR,aAA+C;AACnD,UAAM,SAAS,MAAM,KAAK,OAAO,IAAI;AAAA,MACnC,OAAO;AAAA,MACP,QAAQ;AAAA;AAEV,QAAI,UAAU,OAAO,WAAW,GAAG;AACjC,aAAO,OAAO;AAAA;AAEhB,WAAO;AAAA;AAAA;;ACnBX,MAAM,gBAAgB;AAAA,EACpB,OAAO;AAAA,IACL,SAAS;AAAA,MACP,OAAO;AAAA,MACP,YAAY,CAAC,KAAK;AAAA;AAAA,IAEpB,KAAK;AAAA,MACH,KAAK;AAAA,MACL,MAAM;AAAA,MACN,aAAa;AAAA,MACb,OAAO;AAAA,MACP,UAAU;AAAA;AAAA;AAAA,EAGd,QAAQ;AAAA,IACN,SAAS;AAAA,MACP,OAAO;AAAA,MACP,YAAY,CAAC,KAAK;AAAA;AAAA,IAEpB,KAAK;AAAA,MACH,KAAK;AAAA,MACL,MAAM;AAAA,MACN,aAAa;AAAA,MACb,aAAa;AAAA,MACb,MAAM;AAAA,MACN,UAAU;AAAA,MACV,SAAS;AAAA;AAAA;AAAA;wBAUgB,QAAsC;AArKrE;AAsKE,0BACE,GACwC;AACxC,QAAI,CAAC,GAAG;AACN,aAAO;AAAA;AAET,WAAO;AAAA,MACL,IAAI,EAAE,UAAU;AAAA,MAChB,QAAQ,EAAE,UAAU;AAAA;AAAA;AAIxB,6BAA2B,GAAsC;AAC/D,QAAI,CAAC,GAAG;AACN,aAAO;AAAA;AAGT,UAAM,QAAQ,uBAAuB;AAErC,WAAO;AAAA,MACL,OAAO,EAAE,kBAAkB;AAAA,MAC3B,QAAQ,aAAa,EAAE,kBAAkB;AAAA,MACzC,YAAY,EAAE,uBAAuB;AAAA,SACjC,UAAU,SAAY,CAAE,SAAU;AAAA;AAAA;AAI1C,kCAAgC,GAAmC;AACjE,UAAM,cAAc,EAAE,YAAY;AAClC,QAAI,gBAAgB,QAAW;AAC7B,aAAO;AAAA;AAGT,QAAI,gBAAgB,QAAQ,gBAAgB,OAAO;AACjD,aAAO;AAAA;AAGT,UAAM,WAAW,EAAE,kBAAkB;AACrC,UAAM,YAAY,EAAE,mBAAmB;AACvC,WAAO;AAAA,SACD,aAAa,SAAY,CAAE,YAAa;AAAA,SACxC,cAAc,SAAY,CAAE,aAAc;AAAA;AAAA;AAIlD,yBACE,GAC2C;AAC3C,QAAI,CAAC,GAAG;AACN,aAAO;AAAA;AAET,WAAO,OAAO,YAAY,EAAE,OAAO,IAAI,UAAQ,CAAC,MAAM,EAAE,IAAI;AAAA;AAG9D,6BACE,GAC6C;AAC7C,QAAI,CAAC,GAAG;AACN,aAAO;AAAA;AAGT,WAAO;AAAA,MACL,KAAK,EAAE,kBAAkB;AAAA,MACzB,MAAM,EAAE,kBAAkB;AAAA,MAC1B,aAAa,EAAE,kBAAkB;AAAA,MACjC,aAAa,EAAE,kBAAkB;AAAA,MACjC,OAAO,EAAE,kBAAkB;AAAA,MAC3B,SAAS,EAAE,kBAAkB;AAAA,MAC7B,UAAU,EAAE,kBAAkB;AAAA;AAAA;AAIlC,8BACE,GAC8C;AAC9C,QAAI,CAAC,GAAG;AACN,aAAO;AAAA;AAGT,WAAO;AAAA,MACL,KAAK,EAAE,kBAAkB;AAAA,MACzB,MAAM,EAAE,kBAAkB;AAAA,MAC1B,aAAa,EAAE,kBAAkB;AAAA,MACjC,MAAM,EAAE,kBAAkB;AAAA,MAC1B,aAAa,EAAE,kBAAkB;AAAA,MACjC,OAAO,EAAE,kBAAkB;AAAA,MAC3B,SAAS,EAAE,kBAAkB;AAAA,MAC7B,UAAU,EAAE,kBAAkB;AAAA,MAC9B,SAAS,EAAE,kBAAkB;AAAA;AAAA;AAIjC,0BACE,GAC+C;AAC/C,WAAO;AAAA,MACL,IAAI,EAAE,UAAU;AAAA,MAChB,SAAS,kBAAkB,EAAE,kBAAkB;AAAA,MAC/C,KAAK,cAAc,EAAE,kBAAkB;AAAA,MACvC,KAAK,kBAAkB,EAAE,kBAAkB;AAAA;AAAA;AAI/C,2BACE,GACgD;AAChD,WAAO;AAAA,MACL,IAAI,EAAE,UAAU;AAAA,MAChB,SAAS,kBAAkB,EAAE,kBAAkB;AAAA,MAC/C,KAAK,cAAc,EAAE,kBAAkB;AAAA,MACvC,KAAK,mBAAmB,EAAE,kBAAkB;AAAA;AAAA;AAIhD,wBAAsB,QAAqC;AAxR7D;AA0RI,WAAO,wCAAQ,QAAQ,eAAe,UAA/B,oBAAsC;AAAA;AAG/C,QAAM,kBAAkB,aAAO,uBAAuB,iBAA9B,YAA8C;AACtE,SAAO,gBAAgB,IAAI,OAAK;AAC9B,UAAM,YAAY;AAAA,MAChB,QAAQ,EAAE,UAAU,UAAU,QAAQ,QAAQ;AAAA,MAC9C,MAAM,eAAe,EAAE,kBAAkB;AAAA,MACzC,OAAO,eAAe,EAAE,UAAU;AAAA,MAClC,QAAQ,gBAAgB,EAAE,UAAU;AAAA;AAEtC,UAAM,SAASC,8BAAU,IAAI,eAAe,WAAW,CAAC,OAAO,SAAS;AAEtE,aAAO,MAAM,QAAQ,QAAQ,OAAO;AAAA;AAEtC,WAAO;AAAA;AAAA;;MChRE,sBAAsB;MAWtB,qBAAqB;MAWrB,uBAAuB;;6BCXlC,QACA,QAIC;AACD,QAAM,CAAE,IAAI,SAAS,KAAK,OAAQ;AAClC,QAAM,SAAS,MAAM,OAAO;AAE5B,QAAM,UAAU,MAAM,OAAO,OAAO,IAAI;AAExC,QAAM,WAAyB;AAC/B,QAAM,eAAyC,IAAI;AAEnD,aAAW,SAAS,SAAS;AAC3B,UAAM,SAAqB;AAAA,MACzB,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR,MAAM;AAAA,QACN,aAAa;AAAA;AAAA,MAEf,MAAM;AAAA,QACJ,SAAS;AAAA,QACT,UAAU;AAAA;AAAA;AAId,QAAI,KAAK;AACP,iBAAW,CAAC,MAAM,UAAU,OAAO,QAAQ,MAAM;AAC/C,sCAAU,QAAQ,MAAM;AAAA;AAAA;AAI5B,kBAAc,OAAO,QAAQ,IAAI,MAAM,OAAK;AAC1C,aAAO,SAAS,OAAO;AAAA;AAEzB,kBAAc,OAAO,QAAQ,IAAI,aAAa,OAAK;AACjD,aAAO,SAAS,cAAc;AAAA;AAEhC,kBAAc,OAAO,QAAQ,IAAI,KAAK,OAAK;AACzC,aAAO,SAAS,YAAa,uBAAuB;AAAA;AAEtD,kBAAc,OAAO,QAAQ,OAAO,mBAAmB,OAAK;AAC1D,aAAO,SAAS,YAAa,wBAAwB;AAAA;AAEvD,kBAAc,OAAO,QAAQ,OAAO,iBAAiB,OAAK;AACxD,aAAO,SAAS,YAAa,sBAAsB;AAAA;AAErD,kBAAc,OAAO,QAAQ,IAAI,aAAa,OAAK;AACjD,aAAO,KAAK,QAAS,cAAc;AAAA;AAErC,kBAAc,OAAO,QAAQ,IAAI,OAAO,OAAK;AAC3C,aAAO,KAAK,QAAS,QAAQ;AAAA;AAE/B,kBAAc,OAAO,QAAQ,IAAI,SAAS,OAAK;AAC7C,aAAO,KAAK,QAAS,UAAU;AAAA;AAGjC,sBAAkB,OAAO,QAAQ,IAAI,UAAU,CAAC,MAAM,OAAO;AAC3D,kBAAY,cAAc,MAAM;AAAA;AAGlC,aAAS,KAAK;AAAA;AAGhB,SAAO,CAAE,OAAO,UAAU;AAAA;8BAU1B,QACA,QAKC;AACD,QAAM,CAAE,IAAI,SAAS,KAAK,OAAQ;AAClC,QAAM,SAAS,MAAM,OAAO;AAE5B,QAAM,UAAU,MAAM,OAAO,OAAO,IAAI;AAExC,QAAM,SAAwB;AAC9B,QAAM,gBAA0C,IAAI;AACpD,QAAM,cAAwC,IAAI;AAElD,aAAW,SAAS,SAAS;AAC3B,UAAM,SAAsB;AAAA,MAC1B,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR,MAAM;AAAA,QACN,aAAa;AAAA;AAAA,MAEf,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,UAAU;AAAA;AAAA;AAId,QAAI,KAAK;AACP,iBAAW,CAAC,MAAM,UAAU,OAAO,QAAQ,MAAM;AAC/C,sCAAU,QAAQ,MAAM;AAAA;AAAA;AAI5B,kBAAc,OAAO,QAAQ,IAAI,MAAM,OAAK;AAC1C,aAAO,SAAS,OAAO;AAAA;AAEzB,kBAAc,OAAO,QAAQ,IAAI,aAAa,OAAK;AACjD,aAAO,SAAS,cAAc;AAAA;AAEhC,kBAAc,OAAO,QAAQ,IAAI,KAAK,OAAK;AACzC,aAAO,SAAS,YAAa,uBAAuB;AAAA;AAEtD,kBAAc,OAAO,QAAQ,OAAO,mBAAmB,OAAK;AAC1D,aAAO,SAAS,YAAa,wBAAwB;AAAA;AAEvD,kBAAc,OAAO,QAAQ,OAAO,iBAAiB,OAAK;AACxD,aAAO,SAAS,YAAa,sBAAsB;AAAA;AAErD,kBAAc,OAAO,QAAQ,IAAI,MAAM,OAAK;AAC1C,aAAO,KAAK,OAAO;AAAA;AAErB,kBAAc,OAAO,QAAQ,IAAI,aAAa,OAAK;AACjD,aAAO,KAAK,QAAS,cAAc;AAAA;AAErC,kBAAc,OAAO,QAAQ,IAAI,OAAO,OAAK;AAC3C,aAAO,KAAK,QAAS,QAAQ;AAAA;AAE/B,kBAAc,OAAO,QAAQ,IAAI,SAAS,OAAK;AAC7C,aAAO,KAAK,QAAS,UAAU;AAAA;AAGjC,sBAAkB,OAAO,QAAQ,IAAI,UAAU,CAAC,MAAM,OAAO;AAC3D,kBAAY,eAAe,MAAM;AAAA;AAEnC,sBAAkB,OAAO,QAAQ,IAAI,SAAS,CAAC,MAAM,OAAO;AAC1D,kBAAY,aAAa,MAAM;AAAA;AAGjC,WAAO,KAAK;AAAA;AAGd,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA;AAAA;2BAgBF,QACA,YACA,aAIC;AACD,QAAM,CAAE,OAAO,gBAAiB,MAAM,cAAc,QAAQ;AAC5D,QAAM,CAAE,QAAQ,eAAe,eAAgB,MAAM,eACnD,QACA;AAGF,mBAAiB,QAAQ,OAAO,cAAc,eAAe;AAC7D,QAAM,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,KAAK,cAAc,EAAE,SAAS;AAC9D,SAAO,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,KAAK,cAAc,EAAE,SAAS;AAE/D,SAAO,CAAE,OAAO;AAAA;AAQlB,uBACE,OACA,QACA,eACA,QACA;AACA,MAAI,eAAe;AACjB,UAAM,SAAS,OAAO,sBAAsB,OAAO;AACnD,QAAI,UAAU,OAAO,WAAW,GAAG;AACjC,aAAO,OAAO;AAAA;AAAA;AAAA;AAMpB,2BACE,OACA,QACA,eACA,QACA;AACA,MAAI,eAAe;AACjB,UAAM,SAAS,OAAO,sBAAsB,OAAO;AACnD,UAAM,KAAK,OAAO,sBAAsB,OAAO,OAAO;AACtD,QAAI,UAAU,MAAM,GAAG,WAAW,GAAG;AACnC,aAAO,GAAG,IAAI;AAAA;AAAA;AAAA;AAMpB,qBACE,QACA,KACA,QACA;AACA,MAAI,KAAK;AACP,QAAI,MAAM,OAAO,IAAI;AACrB,QAAI,CAAC,KAAK;AACR,YAAM,IAAI;AACV,aAAO,IAAI,KAAK;AAAA;AAElB,eAAW,SAAS,QAAQ;AAC1B,UAAI,OAAO;AACT,YAAK,IAAI;AAAA;AAAA;AAAA;AAAA;0BAoBf,QACA,OACA,cACA,eACA,aACA;AAMA,QAAM,UAAmC,IAAI;AAC7C,QAAM,WAAqC,IAAI;AAC/C,aAAW,QAAQ,OAAO;AACxB,YAAQ,IAAI,KAAK,SAAS,MAAM;AAChC,YAAQ,IAAI,KAAK,SAAS,YAAa,qBAAqB;AAC5D,YAAQ,IAAI,KAAK,SAAS,YAAa,uBAAuB;AAAA;AAEhE,aAAW,SAAS,QAAQ;AAC1B,aAAS,IAAI,MAAM,SAAS,MAAM;AAClC,aAAS,IAAI,MAAM,SAAS,YAAa,qBAAqB;AAC9D,aAAS,IAAI,MAAM,SAAS,YAAa,uBAAuB;AAAA;AAIlE,UAAQ,OAAO;AACf,WAAS,OAAO;AAChB,UAAQ,OAAO;AACf,WAAS,OAAO;AAMhB,QAAM,kBAA4C,IAAI;AACtD,QAAM,kBAA4C,IAAI;AACtD,QAAM,mBAA6C,IAAI;AAOvD,aAAW,CAAC,OAAO,YAAY,aAAa,WAAW;AACrD,UAAM,OAAO,QAAQ,IAAI;AACzB,QAAI,MAAM;AACR,iBAAW,UAAU,SAAS;AAC5B,cAAM,QAAQ,SAAS,IAAI;AAC3B,YAAI,OAAO;AACT,sBAAY,iBAAiB,KAAK,SAAS,MAAM;AAAA,YAC/C,MAAM,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAMzB,aAAW,CAAC,QAAQ,aAAa,cAAc,WAAW;AACxD,UAAM,QAAQ,SAAS,IAAI;AAC3B,QAAI,OAAO;AACT,iBAAW,WAAW,UAAU;AAC9B,cAAM,cAAc,SAAS,IAAI;AACjC,YAAI,aAAa;AACf,sBAAY,iBAAiB,MAAM,SAAS,MAAM;AAAA,YAChD,YAAY,SAAS;AAAA;AAEvB,sBAAY,kBAAkB,YAAY,SAAS,MAAM;AAAA,YACvD,MAAM,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAMzB,aAAW,CAAC,QAAQ,aAAa,YAAY,WAAW;AACtD,UAAM,QAAQ,SAAS,IAAI;AAC3B,QAAI,OAAO;AACT,iBAAW,WAAW,UAAU;AAG9B,cAAM,aAAa,QAAQ,IAAI;AAC/B,YAAI,YAAY;AACd,sBAAY,iBAAiB,WAAW,SAAS,MAAM;AAAA,YACrD,MAAM,SAAS;AAAA;AAAA,eAEZ;AACL,gBAAM,cAAc,SAAS,IAAI;AACjC,cAAI,aAAa;AACf,wBAAY,kBAAkB,MAAM,SAAS,MAAM;AAAA,cACjD,YAAY,SAAS;AAAA;AAEvB,wBAAY,iBAAiB,YAAY,SAAS,MAAM;AAAA,cACtD,MAAM,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAS3B,aAAW,CAAC,OAAO,YAAY,gBAAgB,WAAW;AACxD,UAAM,OAAO,QAAQ,IAAI;AACzB,QAAI,MAAM;AACR,WAAK,KAAK,WAAW,MAAM,KAAK,SAAS;AAAA;AAAA;AAG7C,aAAW,CAAC,QAAQ,aAAa,gBAAgB,WAAW;AAC1D,QAAI,SAAS,SAAS,GAAG;AACvB,YAAM,QAAQ,SAAS,IAAI;AAC3B,UAAI,OAAO;AACT,cAAM,KAAK,SAAS,SAAS,SAAS,OAAO;AAAA;AAAA;AAAA;AAInD,aAAW,CAAC,QAAQ,cAAc,iBAAiB,WAAW;AAC5D,UAAM,QAAQ,SAAS,IAAI;AAC3B,QAAI,OAAO;AACT,YAAM,KAAK,WAAW,MAAM,KAAK,WAAW;AAAA;AAAA;AAKhD,oBAAkB;AAAA;;6BCjY4C;AAAA,SAIvD,WAAW,QAAgB,SAA6B;AAC7D,UAAM,IAAI,OAAO,kBAAkB;AACnC,WAAO,IAAI,uBAAuB;AAAA,SAC7B;AAAA,MACH,WAAW,IAAI,eAAe,KAAK;AAAA;AAAA;AAAA,EAIvC,YAAY,SAA8D;AACxE,SAAK,YAAY,QAAQ;AACzB,SAAK,SAAS,QAAQ;AAAA;AAAA,QAGlB,aACJ,UACA,WACA,MACkB;AAClB,QAAI,SAAS,SAAS,YAAY;AAChC,aAAO;AAAA;AAGT,UAAM,WAAW,KAAK,UAAU,KAAK,OAAK,SAAS,WAAW,EAAE;AAChE,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,MACR,8CAA8C,SAAS;AAAA;AAK3D,UAAM,iBAAiB,KAAK;AAC5B,SAAK,OAAO,KAAK;AAKjB,UAAM,SAAS,MAAM,WAAW,OAC9B,KAAK,QACL,SAAS,QACT,SAAS;AAEX,UAAM,CAAE,OAAO,UAAW,MAAM,YAC9B,QACA,SAAS,OACT,SAAS;AAGX,UAAM,WAAa,OAAK,QAAQ,kBAAkB,KAAM,QAAQ;AAChE,SAAK,OAAO,MACV,QAAQ,MAAM,yBAAyB,OAAO,yBAAyB;AAIzE,eAAW,SAAS,QAAQ;AAC1B,WAAKhD,OAAe,UAAU;AAAA;AAEhC,eAAW,QAAQ,OAAO;AACxB,WAAKA,OAAe,UAAU;AAAA;AAGhC,WAAO;AAAA;AAAA;;uBCxET,cACA,MACA,QACQ;AACR,MAAI;AACF,QAAI,KAAK,SAAS,QAAQ;AACxB,UAAI,OAAO,WAAW,MAAM;AAC1B,eAAOyC,yBAAK,KAAKA,yBAAK,QAAQ,KAAK,SAAS;AAAA;AAE9C,aAAO;AAAA;AAET,WAAO,aAAa,WAAW,CAAE,KAAK,QAAQ,MAAM,KAAK;AAAA,WAClD,GAAP;AACA,WAAO;AAAA;AAAA;8BAQsD;AAAA,EAC/D,YAA6B,SAAkB;AAAlB;AAAA;AAAA,QAEvB,kBACJ,QACAzD,YACA,MACiB;AACjB,QAAI,OAAO,SAAS,YAAY;AAC9B,YAAM,iBAAiB;AAEvB,YAAM,OAAO,eAAe,KAAK,QAAQA,WAAS;AAClD,UAAI,SAAS,UAAUA,WAAS,OAAO,SAASyD,yBAAK,MAAM;AACzD,aACErD,WACEJ,YACA,yCAAyC,kCAAkCA,WAAS;AAAA;AAK1F,YAAM,UAAU,IAAI;AACpB,UAAI,eAAe,KAAK,QAAQ;AAC9B,gBAAQ,KAAK,eAAe,KAAK;AAAA;AAEnC,UAAI,eAAe,KAAK,SAAS;AAC/B,gBAAQ,KAAK,GAAG,eAAe,KAAK;AAAA;AAGtC,iBAAW,uBAAuB,SAAS;AACzC,cAAM,SAAS,cACb,KAAK,QAAQ,cACbA,YACA;AAEF,aAAKC,SAAgB,CAAE,MAAM,SAAU;AAAA;AAAA;AAI3C,WAAO;AAAA;AAAA;;2BCnDuB;AAAA,EAahC,YACmB,SACA,KACjB;AAFiB;AACA;AAAA;AAAA,SAdZ,OAAO,QAA4D;AACxE,UAAM,eAAmC;AAAA,MACvC,MAAM;AAAA,QACJ,UAAU,OAAO;AAAA,QACjB,cAAc,OAAO;AAAA,QACrB,WAAW,GAAG,OAAO,aAAa,OAAO;AAAA;AAAA;AAG7C,UAAM,MAAM,IAAIgE,mCAAmC;AACnD,WAAO,IAAI,qBAAqB,OAAO,QAAQ;AAAA;AAAA,SAQ1C,kBACL,MACA,OACkB;AAClB,QAAI,WAAW,MAAM,KAAK,WAAW,MAAM;AAE3C,eAAS;AACP,UAAI,SAAS,WAAW,KAAK;AAC3B,cAAM,KAAK,YAAY,MAAM;AAAA;AAG/B,YAAM,SAAS,MAAM,SAAS;AAC9B,YAAM,WAAgB,OAAO;AAE7B,aAAO;AAGP,UAAI,CAAC,OAAO,oBAAoB;AAC9B;AAAA;AAGF,iBAAW,MAAM,KAAK,WAAW,OAAO;AAAA;AAAA;AAAA,QAItC,WAAW,MAAc,OAAuC;AA3ExE;AA4EI,UAAM,cAAcC,uBAAG,UACrB;AAAA,MACE,SAAS,+BAAO;AAAA,MAChB,SAAS,qCAAO,WAAP,mBAAe,KAAK;AAAA,MAC7B,SAAS,qCAAO,WAAP,mBAAe,KAAK;AAAA,OAE/B;AAAA,MACE,gBAAgB;AAAA,MAEhB,QAAQ;AAAA;AAIZ,WAAO,MAAM,KAAK,WAAW,GAAG,KAAK,WAAW,OAAO;AAAA;AAAA,QAGnD,WAAW,KAAgC;AAE/C,UAAM,QAAQ,MAAM,KAAK,IAAI,+BAA+B;AAAA,MAC1D,QAAQ,CAAC;AAAA;AAGX,QAAI,CAAC,OAAO;AACV,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO,MAAMjD,0BAAM,KAAK;AAAA,MACtB,SAAS;AAAA,QACP,eAAe,UAAU,MAAM;AAAA;AAAA;AAAA;AAAA,QAK/B,eAAe,QAA8C;AACjE,UAAM,WAAW,MAAM,KAAK,WAAW,SAAS;AAEhD,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,KAAK,YAAY,gBAAgB;AAAA;AAGzC,WAAO,MAAM,SAAS;AAAA;AAAA,QAGlB,0BACJ,QACA,SAC6B;AAC7B,WAAO,MAAM,KAAK,sBAAsB,SAAS,QAAQ;AAAA;AAAA,QAGrD,aACJ,QACA,QAC6B;AAC7B,WAAO,MAAM,KAAK,SAAS,SAAS,QAAQ;AAAA;AAAA,SAGvC,SAAS,OAAwD;AACtE,WAAO,KAAK,kBAAuC,SAAS;AAAA;AAAA,QAGxD,2BACJ,SACA,SAC6B;AAC7B,WAAO,MAAM,KAAK,sBAAsB,UAAU,SAAS;AAAA;AAAA,QAGvD,cACJ,SACA,QAC6B;AAC7B,WAAO,MAAM,KAAK,SAAS,UAAU,SAAS;AAAA;AAAA,SAGzC,UAAU,OAAyD;AACxE,WAAO,KAAK,kBAAwC,UAAU;AAAA;AAAA,SAGzD,gBAAgB,SAA6C;AAClE,WAAO,KAAK,kBAA+B,UAAU;AAAA;AAAA,QAGjD,gBACJ,UACsC;AACtC,UAAM,WAAW,MAAM,KAAK,WAAW,gBAAgB;AAEvD,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,KAAK,YAAY,gBAAgB,YAAY;AAAA;AAGrD,WAAO,MAAM,SAAS;AAAA;AAAA,QAGV,sBACZ,YACA,IACA,SAC6B;AAC7B,UAAM,WAAW,MAAM,KAAK,WAAW,GAAG,cAAc;AAExD,QAAI,SAAS,WAAW,KAAK;AAC3B,aAAO;AAAA,eACE,SAAS,WAAW,KAAK;AAClC,YAAM,KAAK,YAAY,GAAG,qBAAqB;AAAA;AAGjD,UAAM,SAAS,MAAM,SAAS;AAC9B,UAAM,SAAS,OAAO;AACtB,QAAI,gBAAyD;AAG7D,eAAW,KAAK,QAAQ;AACtB,UACE,CAAC,iBACA,EAAE,UAAW,cAAc,UAAW,EAAE,UAAW,SACpD;AACA,wBAAgB;AAAA;AAAA;AAIpB,QAAI,CAAC,eAAe;AAClB,aAAO;AAAA;AAGT,WAAO,MAAM,KAAK,SAAS,YAAY,IAAI,cAAc;AAAA;AAAA,QAG7C,SACZ,YACA,IACA,QAC6B;AAC7B,UAAM,OAAO,SACT,GAAG,cAAc,aAAa,kBAC9B,GAAG,cAAc;AACrB,UAAM,WAAW,MAAM,KAAK,WAAW;AAEvC,QAAI,SAAS,WAAW,KAAK;AAC3B,aAAO;AAAA,eACE,SAAS,WAAW,KAAK;AAClC,YAAM,KAAK,YAAY,SAAS;AAAA;AAGlC,WAAO,0BAA0B,OAAO,KACtC,MAAM,SAAS,eACf,SAAS;AAAA;AAAA,QAGC,YAAY,MAAc,UAAmC;AACzE,UAAM,SAAS,MAAM,SAAS;AAC9B,UAAM,QAAQ,OAAO;AAErB,UAAM,IAAI,MACR,uBAAuB,8BAA8B,MAAM,UAAU,MAAM;AAAA;AAAA;;kCCzK/E,QACgC;AA/DlC;AAgEE,QAAM,YAA4C;AAClD,QAAM,kBAAkB,aAAO,uBAAuB,iBAA9B,YAA8C;AAEtE,aAAW,kBAAkB,iBAAiB;AAC5C,UAAM,SAAS,eAAe,UAAU,UAAU,QAAQ,QAAQ;AAClE,UAAM,YACJ,sBAAe,kBAAkB,iBAAjC,mBAA+C,QAAQ,QAAQ,QAC/D;AACF,UAAM,WAAW,eAAe,UAAU;AAC1C,UAAM,WAAW,eAAe,UAAU;AAC1C,UAAM,eAAe,eAAe,UAAU;AAC9C,UAAM,aAAa,eAAe,kBAAkB;AACpD,UAAM,cAAc,eAAe,kBAAkB;AAErD,cAAU,KAAK;AAAA,MACb;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAIJ,SAAO;AAAA;;MCtEI,uCACX;MAKW,sCACX;MAKW,qCAAqC;;6BCNd,MAAsB;AACxD,SAAO,KACJ,OACA,oBACA,QAAQ,sBAAsB;AAAA;uCAIjC,QACA,SAGC;AACD,QAAM,WAAyB;AAC/B,QAAM,WAA4B;AAClC,QAAM,UAAUnC,mCAAe;AAE/B,mBAAiB,QAAQ,OAAO,SAAS;AAAA,IACvC,QAAQ,mCAAS;AAAA,IACjB,QAAQ,CAAC,MAAM,eAAe;AAAA,MAC5B;AACF,QAAI,CAAC,KAAK,MAAM,CAAC,KAAK,eAAe,CAAC,KAAK,MAAM;AAC/C;AAAA;AAGF,UAAM,OAAO,oBAAoB,KAAK;AACtC,UAAM,SAAqB;AAAA,MACzB,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR;AAAA,QACA,aAAa;AAAA,WACV,qCAAqC,KAAK;AAAA;AAAA;AAAA,MAG/C,MAAM;AAAA,QACJ,SAAS;AAAA,UACP,aAAa,KAAK;AAAA,UAClB,OAAO,KAAK;AAAA;AAAA,QAOd,UAAU;AAAA;AAAA;AAKd,UAAM,YAAY,QAAQ,YAAY;AACpC,aAAO,KAAK,QAAS,UAAU,MAAM,OAAO,0BAC1C,KAAK,IAGL;AAAA;AAIJ,aAAS,KAAK;AACd,aAAS,KAAK;AAAA;AAIhB,QAAM,QAAQ,IAAI;AAElB,SAAO,CAAE,OAAO;AAAA;8CAIhB,QACA,UAGC;AAED,QAAM,eAAe,MAAM,OAAO,gBAAgB;AAClD,QAAM,OAAO,oBAAoB,aAAa;AAC9C,QAAM,YAAyB;AAAA,IAC7B,YAAY;AAAA,IACZ,MAAM;AAAA,IACN,UAAU;AAAA,MACR;AAAA,MACA,aAAa,aAAa;AAAA,MAC1B,aAAa;AAAA,SACV,uCAAuC,aAAa;AAAA;AAAA;AAAA,IAGzD,MAAM;AAAA,MACJ,MAAM;AAAA,MACN,SAAS;AAAA,QACP,aAAa,aAAa;AAAA;AAAA,MAE5B,UAAU;AAAA;AAAA;AAId,SAAO,CAAE;AAAA;wCAIT,QACA,UACA,SAMC;AACD,QAAM,SAAwB;AAC9B,QAAM,cAAwC,IAAI;AAClD,QAAM,gBAA0C,IAAI;AACpD,QAAM,UAAUA,mCAAe;AAE/B,QAAM,CAAE,aAAc,MAAM,+BAA+B,QAAQ;AACnE,cAAY,IAAI,UAAU,SAAS,MAAM,IAAI;AAC7C,SAAO,KAAK;AAEZ,QAAM,WAA4B;AAElC,mBAAiB,SAAS,OAAO,UAAU;AAAA,IACzC,QAAQ,mCAAS;AAAA,IACjB,QAAQ,CAAC,MAAM,eAAe,eAAe,QAAQ;AAAA,MACnD;AACF,QAAI,CAAC,MAAM,MAAM,CAAC,MAAM,aAAa;AACnC;AAAA;AAGF,UAAM,OAAO,oBAAoB,MAAM,gBAAgB,MAAM;AAC7D,UAAM,SAAsB;AAAA,MAC1B,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR;AAAA,QACA,aAAa;AAAA,WACV,sCAAsC,MAAM;AAAA;AAAA;AAAA,MAGjD,MAAM;AAAA,QACJ,MAAM;AAAA,QACN,SAAS;AAAA,QACT,UAAU;AAAA;AAAA;AAId,QAAI,MAAM,aAAa;AACrB,aAAO,SAAS,cAAc,MAAM;AAAA;AAEtC,QAAI,MAAM,aAAa;AACrB,aAAO,KAAK,QAAS,cAAc,MAAM;AAAA;AAE3C,QAAI,MAAM,MAAM;AACd,aAAO,KAAK,QAAS,QAAQ,MAAM;AAAA;AAIrC,UAAM,mBAAmB,QAAQ,YAAY;AAC3C,uBAAiB,UAAU,OAAO,gBAAgB,MAAM,KAAM;AAC5D,YAAI,CAAC,OAAO,IAAI;AACd;AAAA;AAGF,YAAI,OAAO,mBAAmB,yBAAyB;AACrD,qBAAW,eAAe,OAAO,IAAI,MAAM;AAAA;AAG7C,YAAI,OAAO,mBAAmB,0BAA0B;AACtD,qBAAW,aAAa,MAAM,IAAK,OAAO;AAAA;AAAA;AAAA;AAkBhD,aAAS,KAAK;AACd,WAAO,KAAK;AAAA;AAId,QAAM,QAAQ,IAAI;AAElB,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA;AAAA;4BAKF,WACA,QACA,OACA,aACA,eACA;AAEA,QAAM,WAAqC,IAAI;AAE/C,aAAW,SAAS,QAAQ;AAC1B,QAAI,MAAM,SAAS,YAAa,sCAAsC;AACpE,eAAS,IACP,MAAM,SAAS,YAAa,sCAC5B;AAAA;AAGJ,QAAI,MAAM,SAAS,YAAa,uCAAuC;AACrE,eAAS,IACP,MAAM,SAAS,YAAa,uCAC5B;AAAA;AAAA;AAMN,QAAM,eAAe,IAAI;AAEzB,cAAY,QAAQ,CAAC,SAAS,YAC5B,QAAQ,QAAQ,OAAK,WAAW,cAAc,GAAG;AAInD,MAAI,WAAW;AACb,UAAM,WAAW,UAAU,SAAS,YAClC;AAGF,WAAO,QAAQ,WAAS;AACtB,YAAM,UAAU,MAAM,SAAS,YAC7B;AAGF,UAAI,CAAC,SAAS;AACZ;AAAA;AAGF,UAAI,cAAc,cAAc,SAAS,SAAS,GAAG;AACnD,mBAAW,cAAc,SAAS;AAClC,mBAAW,aAAa,UAAU;AAAA;AAAA;AAAA;AAKxC,SAAO,QAAQ,WAAS;AAxR1B;AAyRI,UAAM,KACJ,YAAM,SAAS,YAAa,yCAA5B,YACA,MAAM,SAAS,YAAa;AAE9B,kBAAc,aAAa,IAAI,QAAQ,OAAK;AAC1C,YAAM,aAAa,SAAS,IAAI;AAChC,UAAI,YAAY;AACd,cAAM,KAAK,SAAS,KAAK,WAAW,SAAS;AAAA;AAAA;AAIjD,kBAAc,cAAc,IAAI,QAAQ,OAAK;AAC3C,YAAM,cAAc,SAAS,IAAI;AACjC,UAAI,aAAa;AAEf,cAAM,KAAK,SAAS,YAAY,SAAS;AAAA;AAAA;AAAA;AAM/C,oBAAkB;AAGlB,QAAM,QAAQ,UAAQ;AACpB,UAAM,KAAK,KAAK,SAAS,YAAa;AAEtC,kBAAc,eAAe,IAAI,QAAQ,OAAK;AAC5C,YAAM,cAAc,SAAS,IAAI;AACjC,UAAI,aAAa;AACf,aAAK,KAAK,SAAS,KAAK,YAAY,SAAS;AAAA;AAAA;AAAA;AAMnD,gBAAc,QAAQ;AAAA;qCAItB,QACA,UACA,SACyD;AACzD,QAAM,CAAE,SAAU,MAAM,wBAAwB,QAAQ;AAAA,IACtD,YAAY,mCAAS;AAAA;AAEvB,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,MACE,MAAM,yBAAyB,QAAQ,UAAU;AAAA,IACnD,aAAa,mCAAS;AAAA;AAGxB,qBAAiB,WAAW,QAAQ,OAAO,aAAa;AACxD,QAAM,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,KAAK,cAAc,EAAE,SAAS;AAC9D,SAAO,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,KAAK,cAAc,EAAE,SAAS;AAE/D,SAAO,CAAE,OAAO;AAAA;AAGlB,oBACE,QACA,KACA,OACA;AACA,MAAI,MAAM,OAAO,IAAI;AACrB,MAAI,CAAC,KAAK;AACR,UAAM,IAAI;AACV,WAAO,IAAI,KAAK;AAAA;AAElB,MAAK,IAAI;AAAA;AAGX,uBACE,QACA,KACa;AAxWf;AAyWE,SAAO,aAAO,IAAI,SAAX,YAAmB,IAAI;AAAA;;uCC1U0C;AAAA,SAIjE,WAAW,QAAgB,SAA6B;AAC7D,UAAM,IAAI,OAAO,kBAAkB;AACnC,WAAO,IAAI,iCAAiC;AAAA,SACvC;AAAA,MACH,WAAW,IAAI,yBAAyB,KAAK;AAAA;AAAA;AAAA,EAIjD,YAAY,SAGT;AACD,SAAK,YAAY,QAAQ;AACzB,SAAK,SAAS,QAAQ;AAAA;AAAA,QAGlB,aACJ,UACA,WACA,MACkB;AAClB,QAAI,SAAS,SAAS,uBAAuB;AAC3C,aAAO;AAAA;AAGT,UAAM,WAAW,KAAK,UAAU,KAAK,OACnC,SAAS,OAAO,WAAW,EAAE;AAE/B,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,MACR,yDAAyD,SAAS;AAAA;AAKtE,UAAM,iBAAiB,KAAK;AAC5B,SAAK,OAAO,KAAK;AAGjB,UAAM,SAAS,qBAAqB,OAAO;AAC3C,UAAM,CAAE,OAAO,UAAW,MAAM,sBAC9B,QACA,SAAS,UACT;AAAA,MACE,YAAY,SAAS;AAAA,MACrB,aAAa,SAAS;AAAA;AAI1B,UAAM,WAAa,OAAK,QAAQ,kBAAkB,KAAM,QAAQ;AAChE,SAAK,OAAO,MACV,QAAQ,MAAM,oBAAoB,OAAO,yCAAyC;AAIpF,eAAW,SAAS,QAAQ;AAC1B,WAAKkC,OAAe,UAAU;AAAA;AAEhC,eAAW,QAAQ,OAAO;AACxB,WAAKA,OAAe,UAAU;AAAA;AAGhC,WAAO;AAAA;AAAA;;2BCrDmD;AAAA,EAC5D,YAA6B,SAAkB;AAAlB;AAAA;AAAA,QAEvB,iBACJ,QACA,UACiB;AACjB,UAAM,UAAU,OAAO,SAAuC;AAC5D,UAAI,CAAC,QAAQ,kBAAkB,SAAS;AAEtC,eAAO,CAAC,MAAM;AAAA;AAGhB,UAAI,MAAM,QAAQ,OAAO;AAEvB,cAAM,QAAQ,MAAM,QAAQ,IAAI,KAAK,IAAI,UAAQ,QAAQ;AACzD,eAAO,MAAM,MAAM,CAAC,GAAG,aAAa,CAAC,WACjC,CAAC,MAAM,SACP,CAAC,MAAM,IAAI,CAAC,CAAC,UAAU,OAAO;AAAA;AAGpC,YAAM,OAAO,OAAO,KAAK;AACzB,UAAI,CAAC,KAAK,KAAK,OAAK,EAAE,WAAW,OAAO;AAGtC,cAAM,UAAU,MAAM,QAAQ,IAC5B,OAAO,QAAQ,MAAM,IAAI,CAAC,CAAC,GAAG,OAC5B,QAAQ,GAAG,KAAK,QAAM,CAAC,GAAG;AAG9B,eAAO,QAAQ,MAAM,CAAC,GAAG,GAAG,cAAc,CAAC,WACvC,CAAC,MAAM,SACP,CAAC,OAAO,YAAY,QAAQ,IAAI,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,GAAG,MAAM;AAAA,iBACnD,KAAK,WAAW,GAAG;AAI5B,eAAO,CAAC,MAAM;AAAA;AAGhB,YAAM,cAAc,KAAK,GAAG,OAAO;AACnC,YAAM,gBAAgB,KAAK,KAAK;AAChC,YAAM,WAAW,KAAK,QAAQ,UAAU;AACxC,UAAI,CAAC,YAAY,OAAO,kBAAkB,UAAU;AAMlD,eAAO,CAAC,MAAM;AAAA;AAGhB,aAAO;AAAA,QACL,MAAM,SAAS;AAAA,UACb,KAAK;AAAA,UACL,OAAO;AAAA,UACP,SAAS,SAAS;AAAA,UAClB,MAAM,KAAK,QAAQ,OAAO,KAAK,KAAK,KAAK,QAAQ;AAAA;AAAA,QAEnD;AAAA;AAAA;AAIJ,UAAM,CAAC,UAAU,MAAM,QAAQ;AAC/B,WAAO;AAAA;AAAA;uCAST,QACoB;AAtHtB;AAuHE,QAAM,OAAO,MAAM,iBAAiB;AAEpC,MAAI;AACJ,MAAI;AACF,gBAAYoC,yBAAK,kBAAkB,MAAM,OAAO,OAAK;AAAA,WAC9C,GAAP;AACA,UAAM,IAAI,MACR,gBAAiB,OAAO,oCAAoC,OAAO,UAAU;AAAA;AAIjF,MAAI,UAAU,WAAW,GAAG;AAC1B,UAAM,IAAI,MACR,gBAAiB,OAAO,wDAAwD,OAAO,gBAAgB,UAAU;AAAA;AAIrH,QAAM,WAAW,UAAU;AAE3B,MAAI,eAAS,WAAT,mBAAiB,QAAQ;AAC3B,UAAM,IAAI,MACR,gBAAiB,OAAO,qCAAqC,OAAO,UAAU,SAAS,OAAO;AAAA;AAIlG,SAAO,SAAS;AAAA;uCAIhB,QACoB;AACpB,QAAM,OAAO,MAAM,iBAAiB;AAEpC,MAAI;AACF,WAAO,KAAK,MAAM;AAAA,WACX,GAAP;AACA,UAAM,IAAI,MACR,gBAAiB,OAAO,oCAAoC,OAAO,UAAU;AAAA;AAAA;uCAMjF,QACoB;AACpB,SAAO,MAAM,iBAAiB;AAAA;AAOhC,gCAAgC,QAAyC;AACvE,QAAM,SAAS,YAAY;AAE3B,MAAI;AACF,UAAM,OAAO,MAAM,OAAO,KAAK;AAC/B,WAAO,KAAK,SAAS;AAAA,WACd,GAAP;AACA,UAAM,IAAI,MACR,gBAAiB,OAAO,+BAA+B,OAAO,UAAU;AAAA;AAAA;AAK9E,qBAAqB,CAAE,KAAK,OAAO,UAAmC;AACpE,MAAI,OAAO,UAAU,UAAU;AAC7B,UAAM,IAAI,MACR,gBAAiB;AAAA;AAIrB,MAAI;AACJ,MAAI;AAEF,UAAM,IAAI,IAAI,OAAO;AAAA,UACrB;AACA,QAAI;AAEF,YAAM,IAAI,IAAI;AAAA,YACd;AAKA,YAAM,IAAI,MACR,gBAAiB,mCAAmC,eAAe;AAAA;AAAA;AAKzE,SAAO,IAAI;AAAA;;8BC7L2D;AAAA,EActE,YAA6B,iBAAiC;AAAjC;AAAA;AAAA,SAbtB,WAAW,QAAyC;AAtB7D;AAuBI,UAAM,YAA4B;AAElC,UAAM,WAAW,aAAO,uBAAuB,yBAA9B,YAAsD;AACvE,eAAW,WAAW,UAAU;AAC9B,YAAM,OAAO,QAAQ,UAAU;AAC/B,YAAM,SAAS,QAAQ,UAAU;AACjC,gBAAU,KAAK,CAAE,MAAM;AAAA;AAGzB,WAAO,IAAI,wBAAwB;AAAA;AAAA,QAK/B,aACJpD,YACA,WACA,MACkB;AAClB,QAAIA,WAAS,SAAS,aAAa;AACjC,aAAO;AAAA;AAGT,eAAW,kBAAkB,KAAK,iBAAiB;AACjD,WAAKC,SAAgB,gBAAgB;AAAA;AAGvC,WAAO;AAAA;AAAA;;ACpBX,MAAM,kBAAkB;AAAA,EACtB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;yBAQ0D;AAAA,EAC1D,YAA6B,SAAkB;AAAlB;AAAA;AAAA,QAEvB,aACJ,UACA,UACA,MACA,QACkB;AAClB,QAAI,gBAAgB,SAAS,SAAS,OAAO;AAE3C,WAAK,QAAQ,OAAO,KAClB,aAAa,SAAS,0CAA0C,SAAS;AAAA,eAGlE,SAAS,SAAS,OAAO;AAClC,aAAO;AAAA;AAGT,QAAI;AACF,YAAM,SAAS,MAAM,KAAK,OAAO,SAAS;AAC1C,iBAAW,QAAQ,QAAQ;AACzB,yBAAiB,eAAe,OAAO;AAAA,UACrC,MAAM,KAAK;AAAA,UACX,UAAU,CAAE,MAAM,SAAS,MAAM,QAAQ,KAAK;AAAA,YAC5C;AACF,eAAK;AAAA;AAAA;AAAA,aAGF,OAAP;AACA,YAAM,UAAU,kBAAkB,SAAS,SAAS;AAEpD,UAAI,MAAM,SAAS,iBAAiB;AAClC,YAAI,CAAC,UAAU;AACb,eAAKyD,cAAqB,UAAU;AAAA;AAAA,aAEjC;AACL,aAAKvD,aAAoB,UAAU;AAAA;AAAA;AAIvC,WAAO;AAAA;AAAA,QAGK,OACZ,UAC0C;AAG1C,UAAM,CAAE,YAAaU,gCAAY;AACjC,QAAI,qCAAU,MAAM,SAAS;AAC3B,YAAM,UAAU/B,mCAAe;AAC/B,YAAM,WAAW,MAAM,KAAK,QAAQ,OAAO,OAAO;AAClD,YAAM,SAAS,SAAS,MAAM,IAAI,OAAM;AAAS,QAC/C,KAAK,KAAK;AAAA,QACV,MAAM,MAAM,QAAQ,KAAK;AAAA;AAE3B,aAAO,QAAQ,IAAI;AAAA;AAIrB,UAAM,OAAO,MAAM,KAAK,QAAQ,OAAO,KAAK;AAC5C,WAAO,CAAC,CAAE,KAAK,UAAU;AAAA;AAAA;;6BC5EmC;AAAA,EAI9D,YAAY;AAAA,IACV;AAAA,IACA;AAAA,KAIC;AACD,SAAK,YAAY;AACjB,SAAK,mBACH,oBAAoB;AAAA;AAAA,EAGd,kBACR,QACA,MACQ;AACR,QAAI,YAAY;AAChB,eAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,OAAO;AAC/C,kBAAY,UAAU,QAAQ,IAAI,OAAO;AAAA;AAE3C,WAAO,UAAU;AAAA;AAAA,QAGb,UAAU;AACd,UAAM,UAAU,MAAM,KAAK,UAAU,WAAW;AAChD,UAAM,MAAM,MAAMmC,0BAAM,GAAG;AAC3B,UAAM,WAAqB,MAAM,IAAI;AACrC,WAAO,SAAS,IACd,CAAC,WAA0C;AA7DjD;AA8DQ,aAAO;AAAA,QACL,OAAO,OAAO,SAAS;AAAA,QACvB,UAAU,KAAK,kBAAkB,KAAK,kBAAkB;AAAA,UACtD,WAAW,OAAO,SAAS,aAAa;AAAA,UACxC,MAAM,OAAO;AAAA,UACb,MAAM,OAAO,SAAS;AAAA;AAAA,QAExB,MAAM,OAAO,SAAS,eAAe;AAAA,QACrC,eAAe,oBAAO,SAAP,mBAAa,SAAb,mBAAmB,eAAc;AAAA,QAChD,WAAW,OAAO,SAAS,aAAa;AAAA,QACxC,MAAM,OAAO;AAAA,QACb,WAAY,cAAO,SAAP,mBAAa,cAAwB;AAAA,QACjD,OAAQ,cAAO,SAAP,mBAAa,UAAoB;AAAA;AAAA;AAAA;AAAA;;AC9B5C,oCAA2B;AAAA,EA4EhC,YAA6B,OAAsB;AAAtB;AAAA;AAAA,SAlCtB,WAAW,QAAgB;AAChC,UAAM,QAAQ,IAAI;AAElB,QAAI,OAAO,IAAI,kBAAkB;AAC/B,YAAM,cAAc,OAAO,eAAe,iBAAiB,IAAI;AAAQ,QACrE,OAAO,IAAI,eAAe,SAAS,IAAI,YAAW;AAAA;AAEpD,YAAM,KAAK,GAAG;AAAA,WACT;AACL,YAAM,KAAK,GAAG,sBAAqB;AAAA;AAGrC,QAAI,OAAO,IAAI,sBAAsB;AACnC,YAAM,gBAAgB,OACnB,eAAe,qBACf,QAAQ,aAAW;AAClB,YAAI,CAAC,QAAQ,IAAI,UAAU;AACzB,iBAAO;AAAA;AAET,cAAM,OAAO,QAAQ,UAAU;AAC/B,cAAM,SAAS,QAAQ,UAAU;AAEjC,eAAO,QAAQ,eAAe,SAAS,IAAI;AAAa,UACtD,OAAO,SAAS,eAAe,SAAS,IAAI,YAAW;AAAA,UACvD,WAAW,CAAC,CAAE,MAAM;AAAA;AAAA;AAI1B,YAAM,KAAK,GAAG;AAAA;AAGhB,WAAO,IAAI,sBAAqB;AAAA;AAAA,EASlC,UAAU,QAAgB,UAAwB;AAChD,eAAW,QAAQ,KAAK,OAAO;AAC7B,UAAI,CAAC,KAAK,cAAc,UAAU,KAAK,YAAY;AACjD;AAAA;AAGF,UAAI,KAAK,YAAY,QAAQ,KAAK,QAAQ;AACxC,eAAO;AAAA;AAAA;AAIX,WAAO;AAAA;AAAA,EAGD,cACN,UACA,UACS;AACT,QAAI,CAAC,UAAU;AACb,aAAO;AAAA;AAGT,eAAW,WAAW,UAAU;AAC9B,UAAI,QAAQ,+CAAmB,OAAM;AACnC;AAAA;AAEF,UAAI,QAAQ,UAAU,QAAQ,iDAAqB,SAAQ;AACzD;AAAA;AAEF,aAAO;AAAA;AAGT,WAAO;AAAA;AAAA,EAGD,YAAY,QAAgB,UAAqC;AAjK3E;AAkKI,QAAI,CAAC,UAAU;AACb,aAAO;AAAA;AAGT,eAAW,WAAW,UAAU;AAC9B,UAAI,wCAAQ,SAAR,mBAAc,mBAAkB,QAAQ,KAAK,eAAe;AAC9D;AAAA;AAGF,aAAO;AAAA;AAGT,WAAO;AAAA;AAAA;;AAlIJ,qBAMW,eAA8B;AAAA,EAC5C;AAAA,IACE,OAAO,CAAC,aAAa,OAAO,YAAY,IAAI,YAAW;AAAA;AAAA;;2BC1BC;AAAA,EAI5D,YAAY,QAAgB,iBAAyC;AACnE,SAAK,SAAS;AACd,SAAK,kBAAkB;AAAA;AAAA,QAEnB,gBACJ,SACkC;AAClC,UAAM,CAAE,OAAO,QAASJ,gCAAY,QAAQ,SAAS;AACrD,UAAM,SAAiB;AAAA,MACrB,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR;AAAA;AAAA,MAEF,MAAM,CAAE,MAAM,SAAS,WAAW;AAAA;AAGpC,UAAM,cAAc,KAAK,gBAAgB,MAAM,QAAQ,SAAS;AAChE,QAAI;AACJ,YAAQ,2CAAa;AAAA,WACd;AACH,2BAAmB;AACnB;AAAA,WACG;AACH,2BAAmB;AACnB;AAAA,WACG;AACH,2BAAmB;AACnB;AAAA,WACG;AACH,2BAAmB;AACnB;AAEA;AAGJ,QAAI,kBAAkB;AACpB,aAAO,SAAS,cAAc;AAAA,SAC3B,GAAG,kCAAkC,GAAG,SAAS;AAAA;AAAA;AAItD,SAAK,OAAO,MAAM,sBAAsB,QAAQ,SAAS;AACzD,WAAO;AAAA,MACL,qBAAqB;AAAA,MACrB,kBAAkB,CAAC,CAAE,QAAQ,QAAQ;AAAA;AAAA;AAAA;;qBCoBf;AAAA,EAU1B,YAAY,KAAyB;AACnC,SAAK,MAAM;AACX,SAAK,iBAAiB;AACtB,SAAK,wBAAwB;AAC7B,SAAK,uBAAuB;AAC5B,SAAK,wBAAwB;AAC7B,SAAK,aAAa;AAClB,SAAK,oBAAoB;AACzB,SAAK,SAAS;AAAA;AAAA,EAchB,mBAAmB,UAA0C;AAC3D,SAAK,eAAe,KAAK,GAAG;AAC5B,WAAO;AAAA;AAAA,EAgBT,sBAAsB,UAA0C;AAC9D,SAAK,iBAAiB,CAAC,GAAG;AAC1B,SAAK,wBAAwB;AAC7B,WAAO;AAAA;AAAA,EAUT,uBACE,KACA,UACgB;AAChB,SAAK,qBAAqB,OAAO;AACjC,WAAO;AAAA;AAAA,EAaT,yBAAyB,YAAiD;AACxE,+BAAO,MAAM,KAAK,uBAAuB;AACzC,WAAO;AAAA;AAAA,EAST,gBAAgB,YAAgD;AAC9D,SAAK,WAAW,KAAK,GAAG;AACxB,WAAO;AAAA;AAAA,EAWT,kBAAkB,YAAgD;AAChE,SAAK,aAAa,CAAC,GAAG;AACtB,SAAK,oBAAoB;AACzB,WAAO;AAAA;AAAA,EAYT,oBAAoB,QAAgD;AAClE,SAAK,SAAS;AACd,WAAO;AAAA;AAAA,QAMH,QAKH;AACD,UAAM,CAAE,QAAQ,UAAU,UAAW,KAAK;AAC1C,UAAM,eAAeD,4BAAgB,WAAW;AAEhD,UAAM,SAAS,KAAK;AACpB,UAAM,aAAa,KAAK;AACxB,UAAM,gBAAgB,qBAAqB,WAAW;AACtD,UAAM,SAAS,KAAK,UAAU;AAE9B,UAAM,iBAAiB,IAAI,gBAAgB;AAAA,SACtC,KAAK;AAAA,MACR;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAGF,UAAM,KAAK,MAAM,gBAAgB,eAC/B,MAAM,SAAS,aACf,CAAE;AAGJ,UAAM,kBAAkB,IAAI,wBAAwB,IAAI,KAAK,IAAI;AACjE,UAAM,mBAAmB,IAAI,yBAAyB;AACtD,UAAM,uBAAuB,IAAI,sBAC/B,iBACA,kBACA,gBACA;AAEF,UAAM,mBAAmB,IAAI,qBAAqB,QAAQ;AAE1D,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAAA,EAII,oBAAkC;AACxC,UAAM,iBAAiC,KAAK,wBACxC,CAAC,IAAIuD,wCAA2B,GAAG,KAAK,kBACxC;AAAA,MACE,IAAIA;AAAA,MACJ,IAAIC;AAAA,MACJ,IAAIC;AAAA,MACJ,IAAIC,qCACFC,2BAAc,KAAK;AAAA,MAErB,GAAG,KAAK;AAAA;AAGd,WAAOC,4BAAe,MAAM;AAAA;AAAA,EAGtB,kBAAsC;AAC5C,UAAM,CAAE,QAAQ,QAAQ,UAAW,KAAK;AACxC,UAAM,eAAe5D,4BAAgB,WAAW;AAEhD,SAAK;AAEL,UAAM,uBAA4D;AAAA,MAChE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,MAAM;AAAA,SACH,KAAK;AAAA;AAIV,UAAM,aAAiC;AAAA,MACrC,wBAAwB,WAAW;AAAA,MACnC,IAAI,qBAAqB,CAAE,WAAW,sBAAsB;AAAA,MAC5D,IAAI;AAAA;AAIN,QAAI,CAAC,KAAK,mBAAmB;AAC3B,iBAAW,KACT,IAAI,uBACJ,4BAA4B,WAAW,QAAQ,CAAE,UACjD,yBAAyB,WAAW,QAAQ,CAAE,UAC9C,yBAAyB,WAAW,QAAQ,CAAE,UAC9C,uBAAuB,WAAW,QAAQ,CAAE,UAC5C,iCAAiC,WAAW,QAAQ,CAAE,UACtD,IAAI,mBAAmB,CAAE,QAAQ,UACjC,oBAAoB,WAAW,QAAQ,CAAE,QAAQ,UACjD,IAAI,wBAAwB,CAAE,gBAC9B,IAAI,gCAAgC,CAAE;AAAA;AAK1C,eAAW,KAAK,GAAG,KAAK;AAExB,WAAO;AAAA;AAAA,EAKD,kCAAkC;AACxC,UAAM,KAAK,KAAK,IAAI,OAAO,kBAAkB;AAC7C,QAAI,yBAAI,IAAI,WAAW;AACrB,YAAM,IAAI,MACR;AAAA;AAGJ,QAAI,yBAAI,IAAI,cAAc;AACxB,YAAM,IAAI,MACR;AAAA;AAGJ,QAAI,yBAAI,IAAI,iBAAiB;AAC3B,YAAM,IAAI,MACR;AAAA;AAGJ,QAAI,yBAAI,IAAI,aAAa;AACvB,YAAM,IAAI,MACR;AAAA;AAAA;AAAA;;kCCtUiC,KAAgC;AACvE,QAAM,cAAc,IAAI,OAAO;AAC/B,MAAI,CAAC,aAAa;AAChB,UAAM,IAAInC,kBAAW;AAAA,aACZ,CAAC,YAAY,MAAM,4BAA4B;AACxD,UAAM,IAAIA,kBAAW;AAAA;AAGvB,QAAM,OAAO,IAAI;AACjB,MAAI,CAAC,MAAM;AACT,UAAM,IAAIA,kBAAW;AAAA,aACZ,CAACC,2BAAO,cAAc,OAAO;AACtC,UAAM,IAAID,kBAAW;AAAA,aACZ,OAAO,KAAK,MAAM,WAAW,GAAG;AAEzC,UAAM,IAAIA,kBAAW;AAAA;AAGvB,SAAO;AAAA;mCAIP,KACA,QACY;AACZ,QAAM,OAAO,MAAM,mBAAmB;AAEtC,MAAI;AACF,UAAM,OAAO,SAAS,MAAM,CAAE,QAAQ;AAAA,WAC/B,GAAP;AACA,UAAM,IAAIA,kBAAW,sBAAsB;AAAA;AAG7C,SAAQ;AAAA;8BAG2B,UAAmB;AACtD,MAAI,UAAU;AACZ,UAAM,IAAIyB,uBAAgB;AAAA;AAAA;;4BCP5B,SACyB;AACzB,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,MACE;AAEJ,QAAM,SAASuE;AACf,SAAO,IAAIC,4BAAQ;AAEnB,QAAM,kBACJ,OAAO,mBAAmB,uBAAuB;AACnD,MAAI,iBAAiB;AACnB,WAAO,KAAK;AAAA;AAGd,MAAI,iBAAiB;AACnB,WACG,IAAI,aAAa,OAAO,KAAK,QAAQ;AACpC,YAAM,CAAE,UAAU,YAAa,MAAM,gBAAgB,SAAS;AAAA,QAC5D,QAAQ,wBAAwB,IAAI;AAAA,QACpC,QAAQ,2BAA2B,IAAI;AAAA,QACvC,YAAY,4BAA4B,IAAI;AAAA;AAI9C,UAAI,SAAS,aAAa;AACxB,cAAM,MAAM,IAAI,IAAI,iBAAiB,IAAI;AACzC,YAAI,aAAa,OAAO;AACxB,YAAI,aAAa,IAAI,SAAS,SAAS;AACvC,YAAI,UAAU,QAAQ,IAAI,IAAI,WAAW,IAAI;AAAA;AAI/C,UAAI,KAAK;AAAA,OAEV,KAAK,aAAa,OAAO,KAAK,QAAQ;AAWrC,2BAAqB;AAErB,YAAM,OAAO,MAAM,mBAAmB;AACtC,YAAM,CAAC,UAAU,MAAM,gBAAgB,yBAAyB;AAAA,QAC9D,CAAE,QAAQ,MAAgB,WAAW;AAAA;AAEvC,YAAM,WAAW,MAAM,gBAAgB,SAAS;AAAA,QAC9C,QAAQ,kBAAkB,CAAE,gBAAgB,OAAO;AAAA;AAErD,UAAI,OAAO,KAAK,KAAK,SAAS,SAAS;AAAA,OAExC,IAAI,yBAAyB,OAAO,KAAK,QAAQ;AAChD,YAAM,CAAE,OAAQ,IAAI;AACpB,YAAM,CAAE,YAAa,MAAM,gBAAgB,SAAS;AAAA,QAClD,QAAQ,kBAAkB,CAAE,gBAAgB;AAAA;AAE9C,UAAI,CAAC,SAAS,QAAQ;AACpB,cAAM,IAAIlF,qBAAc,sBAAsB;AAAA;AAEhD,UAAI,OAAO,KAAK,KAAK,SAAS;AAAA,OAE/B,OAAO,yBAAyB,OAAO,KAAK,QAAQ;AACnD,YAAM,CAAE,OAAQ,IAAI;AACpB,YAAM,gBAAgB,kBAAkB;AACxC,UAAI,OAAO,KAAK;AAAA,OAEjB,IAAI,4CAA4C,OAAO,KAAK,QAAQ;AACnE,YAAM,CAAE,MAAM,WAAW,QAAS,IAAI;AACtC,YAAM,CAAE,YAAa,MAAM,gBAAgB,SAAS;AAAA,QAClD,QAAQ,kBAAkB;AAAA,UACxB;AAAA,UACA,sBAAsB;AAAA,UACtB,iBAAiB;AAAA;AAAA;AAGrB,UAAI,CAAC,SAAS,QAAQ;AACpB,cAAM,IAAIA,qBACR,oBAAoB,2BAA2B,uBAAuB;AAAA;AAG1E,UAAI,OAAO,KAAK,KAAK,SAAS;AAAA;AAAA;AAIpC,MAAI,sBAAsB;AACxB,WAAO,KAAK,cAAc,OAAO,KAAK,QAAQ;AAC5C,YAAM,QAAQ,MAAM,oBAAoB,KAAKmF;AAC7C,YAAM,SAASC,uBAAG,IAAI,MAAM,QAAQ,CAAE,SAAS;AAI/C,UAAI,CAAC,QAAQ;AACX,6BAAqB;AAAA;AAGvB,YAAM,SAAS,MAAM,qBAAqB,YAAY,OAAO,CAAE;AAC/D,UAAI,OAAO,KAAK,KAAK;AAAA;AAAA;AAIzB,MAAI,kBAAkB;AACpB,WACG,IAAI,cAAc,OAAO,MAAM,QAAQ;AACtC,YAAM,SAAS,MAAM,iBAAiB;AACtC,UAAI,OAAO,KAAK,KAAK;AAAA,OAEtB,IAAI,0BAA0B,OAAO,KAAK,QAAQ;AACjD,YAAM,CAAE,MAAO,IAAI;AACnB,YAAM,SAAS,MAAM,iBAAiB,gBAAgB;AACtD,UAAI,OAAO,KAAK,KAAK;AAAA,OAEtB,IAAI,kBAAkB,OAAO,KAAK,QAAQ;AACzC,YAAM,CAAE,MAAO,IAAI;AACnB,YAAM,SAAS,MAAM,iBAAiB,SAAS;AAC/C,UAAI,OAAO,KAAK,KAAK;AAAA,OAEtB,OAAO,kBAAkB,OAAO,KAAK,QAAQ;AAC5C,2BAAqB;AAErB,YAAM,CAAE,MAAO,IAAI;AACnB,YAAM,iBAAiB,eAAe;AACtC,UAAI,OAAO,KAAK;AAAA;AAAA;AAItB,MAAI,kBAAkB;AACpB,WAAO,KAAK,qBAAqB,OAAO,KAAK,QAAQ;AACnD,YAAM,QAAQ,MAAM,oBAAoB,KAAKC;AAC7C,YAAM,SAAS,MAAM,iBAAiB,gBAAgB;AACtD,UAAI,OAAO,KAAK,KAAK;AAAA;AAAA;AAIzB,SAAO,IAAIC;AACX,SAAO;AAAA;;oCC1KkC,UAAwB;AACjE,QAAM,OAAOC,kBAAW,QACrB,OAAO,GAAG,SAAS,QAAQ,SAAS,UACpC,OAAO;AAEV,SAAO,aAAa;AAAA;sCAIpB,UACA,cACwB;AAtC1B;AAuCE,MAAI;AACJ,MAAI;AACJ,MAAI,cAAc;AAChB,UAAM,mBACJ,mBAAa,SAAS,gBAAtB,mBAAoC9F;AACtC,QAAI,CAAC,kBAAkB;AACrB,YAAM,IAAI,MACR,kBAAkB+F,gCAChB,+BACiBjF,wCACjB;AAAA;AAIN,kBAAc;AACd,UAAM,sBACJ,mBAAa,SAAS,gBAAtB,mBAAoCQ;AACtC,QAAI,CAAC,qBAAqB;AACxB,YAAM,IAAI,MACR,kBAAkByE,gCAChB,+BACiBjF,wCACjB;AAAA;AAIN,qBAAiB;AAAA,SACZ;AACL,kBAAcA,wCAA2B;AACzC,qBAAiB;AAAA;AAGnB,QAAM,SAAiC;AAAA,IACrC,YAAY;AAAA,IACZ,MAAM;AAAA,IACN,UAAU;AAAA,MACR,MAAM,2BAA2B;AAAA,MACjC,aAAa;AAAA,SACVd,mCAAsB;AAAA,SACtBsB,0CAA6B;AAAA;AAAA;AAAA,IAGlC,MAAM;AAAA,MACJ,MAAM,SAAS;AAAA,MACf,QAAQ,SAAS;AAAA;AAAA;AAIrB,SAAO;AAAA;;mCClE2D;AAAA,EAGlE,YAA6B,QAAgB;AAAhB;AAAA;AAAA,EAE7B,kBAA0B;AACxB,WAAO;AAAA;AAAA,QAGH,QAAQ,YAAqD;AA9BrE;AA+BI,SAAK,aAAa;AAElB,UAAM,kBACJ,WAAK,OAAO,uBAAuB,yBAAnC,YAA2D;AAE7D,UAAM,WAAW,gBAAgB,IAAI,cAAY;AAC/C,YAAM,OAAO,SAAS,UAAU;AAChC,YAAM,SAAS,SAAS,UAAU;AAClC,aAAO,6BAA6B;AAAA,QAClC;AAAA,QACA,QAAQ,SAAS,SAASkD,yBAAK,QAAQ,UAAU;AAAA;AAAA;AAIrD,UAAM,KAAK,WAAW,cAAc;AAAA,MAClC,MAAM;AAAA,MACN;AAAA;AAAA;AAAA;;ACcN,MAAMpE,eAAa;gCAEkD;AAAA,EACnE,YACmB,UACA,QACjB;AAFiB;AACA;AAAA;AAAA,QAGb,sBACJ,UACA,SACe;AACf,UAAM,KAAK;AACX,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,cACA4F;AAAA,MACA;AAAA,MACA;AAAA,QACE;AAEJ,UAAM,gBAAgB,MAAM,GAAsB,iBAC/C,OAAO;AAAA,MACN,kBAAkB,KAAK,UAAU;AAAA,MACjC,OAAO,KAAK,UAAU;AAAA,cACtBA;AAAA,OAED,MAAM,aAAa;AACtB,QAAI,kBAAkB,GAAG;AACvB,YAAM,IAAIzF,qBAAc,kCAAkC;AAAA;AAI5D,UAAM,KAAK,uBAAuB,IAAI;AAAA,MACpC,UAAU;AAAA,MACV,WAAWwF,gCAAmB;AAAA;AAMhC,UAAM,GAAmB,aACtB,MAAM,CAAE,uBAAuB,KAC/B;AAGH,UAAM,eAAiC,UAAU,IAC/C,CAAC,CAAE,QAAQ,QAAQ;AAAY,MAC7B,uBAAuB;AAAA,MACvB,mBAAmBA,gCAAmB;AAAA,MACtC,mBAAmBA,gCAAmB;AAAA,MACtC;AAAA;AAGJ,UAAM,GAAG,YACP,aACA,KAAK,qBAAqB,eAC1B3F;AAAA;AAAA,QAIE,4BACJ,UACA,SACe;AACf,UAAM,KAAK;AACX,UAAM,CAAE,IAAI,UAAW;AAEvB,UAAM,GAAsB,iBACzB,OAAO;AAAA,MACN;AAAA,OAED,MAAM,aAAa;AAAA;AAAA,EAGhB,qBAAqB,MAA0C;AACrE,WAAOX,2BAAO,OACZ,MACA,OAAK,GAAG,EAAE,qBAAqB,EAAE,qBAAqB,EAAE;AAAA;AAAA,QAI9C,YACZ,IACA,SACkD;AAClD,QAAI,QAAQ,SAAS,SAAS;AAC5B,aAAO;AAAA,QACL,OAAO,QAAQ;AAAA,QACf,UAAU,QAAQ,QAAQ,IAAI,OAAKsG,gCAAmB;AAAA;AAAA;AAI1D,UAAM,UAAU,MAAM,GACpB,4BAEC,MAAM,CAAE,YAAY,QAAQ,YAC5B,OAAO,qBACP,KAAK,UAAQ,KAAK,IAAI,OAAK,EAAE;AAEhC,UAAM,QAAQ,QAAQ,MAAM,IAAI;AAAW,MACzC;AAAA,MACA,KAAKA,gCAAmB;AAAA;AAG1B,UAAM,aAAa,IAAI,IAAI;AAC3B,UAAM,aAAa,IAAI,IAAI,MAAM,IAAI,UAAQ,KAAK;AAClD,UAAM,QAAQ,MAAM,OAAO,UAAQ,CAAC,WAAW,IAAI,KAAK;AACxD,UAAM,WAAW,QAAQ,OAAO,SAAO,CAAC,WAAW,IAAI;AAEvD,WAAO,CAAE,OAAO,MAAM,IAAI,CAAC,CAAE,YAAa,SAAS;AAAA;AAAA,QAG/C,2BACJ,UACA,SACe;AACf,UAAM,KAAK;AAEX,UAAM,CAAE,OAAO,YAAa,MAAM,KAAK,YAAY,IAAI;AAEvD,QAAI,SAAS,QAAQ;AAqCnB,YAAM,eAAe,MAAM,GAAsB,iBAC9C,QAAQ,cAAc,4BAA4B,SAAS;AAC1D,eACE,QAEG,cAAc,eAAe,qBAAqB,OAAO;AACxD,iBAAO,MACJ,OAAO,CAAE,SAAS,MAAM,YAAY,sBACpC,KAAK,4BACL,MAAM,cAAc,QAAQ,WAC5B,QAAQ,qBAAqB,UAC7B,MAAM,mBAAmB,OAAO;AAC/B,mBAAO,MACJ,OAAO;AAAA,cACN,SAAS;AAAA,cACT,YACE;AAAA,eAEH,KAAK,eACL,KAAK,4BAA4B;AAAA,cAChC,0BACE;AAAA;AAAA;AAAA,WAKX,cAAc,aAAa,mBAAmB,OAAO;AACpD,iBAAO,MACJ,OAAO;AAAA,YACN,SAAS,GAAG,IAAI,qBAAqB;AAAA,YACrC,gBAAgB;AAAA,YAChB,eAAe;AAAA,aAEhB,KAAK,eACL,MAAM,mBAAmB,OAAO;AAC/B,mBAAO,MACJ,OAAO;AAAA,cACN,SAAS,GAAG,IACV,0DACA;AAAA,cAEF,gBAAgB;AAAA,cAChB,eAAe;AAAA,eAEhB,KAAK,aACL,KAAK,4BAA4B;AAAA,cAChC,mBAAmB;AAAA;AAAA;AAAA,WAK5B,OAAO,0BACP,KAAK,eAEL,cAAc,aAAa,0BAA0B;AACpD,eAAK,GACH,2BACA,KACA;AAEF,eAAK,aAAa;AAClB,eAAK,MAAM,qBAAqB,MAAM;AAAA,WAEvC,UAAU;AAAA,SAGhB;AAEH,YAAM,GAAgC,4BACnC,MAAM,cAAc,KAAK,QAAQ,WACjC,QAAQ,qBAAqB,UAC7B;AAEH,WAAK,OAAO,MACV,YAAY,0BAA0B,KAAK,UAAU;AAAA;AAIzD,QAAI,MAAM,QAAQ;AAChB,YAAM,QAA4C,MAAM,IAAI;AAAW,QACrE,WAAWE;AAAA,QACX,YAAYF,gCAAmB;AAAA,QAC/B,oBAAoB,KAAK,UAAU;AAAA,QACnC,QAAQ;AAAA,QACR,gBAAgB,GAAG,GAAG;AAAA,QACtB,mBAAmB,GAAG,GAAG;AAAA;AAG3B,YAAM,kBAAiD,MAAM,IAC3D;AAAW,QACT,YAAY,QAAQ;AAAA,QACpB,mBAAmBA,gCAAmB;AAAA;AAI1C,YAAM,GAAG,YAAY,iBAAiB,OAAO3F;AAC7C,YAAM,GAAG,YACP,4BACA,iBACAA;AAAA;AAAA;AAAA,QAKA,uBACJ,UACA,SACe;AACf,UAAM,KAAK;AAEX,UAAM,YAAY,QAAQ,SAAS,IACjC;AACG,MACC,WAAW6F;AAAA,MACX,YAAYF,gCAAmB;AAAA,MAC/B,oBAAoB,KAAK,UAAU;AAAA,MACnC,QAAQ;AAAA,MACR,gBAAgB,GAAG,GAAG;AAAA,MACtB,mBAAmB,GAAG,GAAG;AAAA;AAG/B,UAAM,qBAAqB,UAAU,IACnC;AACG,MACC,mBAAmB,QAAQ;AAAA,MAC3B,mBAAmB,SAAS;AAAA;AAOlC,eAAW,OAAO,WAAW;AAC3B,YAAM,GAAsB,iBACzB,OAAO,KACP,WAAW,cACX,MAAM,CAAC,sBAAsB;AAAA;AAIlC,UAAM,GAAgC,4BACnC,MAAM,CAAE,mBAAmB,QAAQ,YACnC;AACH,UAAM,GAAG,YACP,4BACA,oBACA3F;AAAA;AAAA,QAIE,uBACJ,UACA,SACuC;AACvC,UAAM,KAAK;AAEX,UAAM,QAAQ,MAAM,GAAsB,iBACvC,SACA,MAAM,kBAAkB,MAAM,GAAG,GAAG,OACpC,MAAM,QAAQ,kBACd,QAAQ,kBAAkB;AAE7B,UAAM,GAAsB,iBACzB,QACC,cACA,MAAM,IAAI,OAAK,EAAE,aAElB,OAAO;AAAA,MACN,gBACE,GAAG,OAAO,OAAO,WAAW,YACxB,GAAG,IAAI,sBAAsB,CAAC,kBAC9B,GAAG,IAAI;AAAA;AAGjB,WAAO;AAAA,MACL,OAAO,MAAM,IACX;AACG,QACC,IAAI,EAAE;AAAA,QACN,WAAW,EAAE;AAAA,QACb,mBAAmB,KAAK,MAAM,EAAE;AAAA,QAChC,iBAAiB,EAAE,mBACd,KAAK,MAAM,EAAE,oBACd;AAAA,QACJ,cAAc,EAAE;AAAA,QAChB,iBAAiB,EAAE;AAAA,QACnB,OAAO,EAAE,QACL,KAAK,MAAM,EAAE,SACb,IAAI;AAAA,QACR,QAAQ,EAAE;AAAA;AAAA;AAAA;AAAA,QAMd,YAAe,IAAiD;AACpE,QAAI;AACF,UAAI,SAAwB;AAE5B,YAAM,KAAK,SAAS,YAClB,OAAM,OAAM;AAGV,iBAAS,MAAM,GAAG;AAAA,SAEpB;AAAA,QAEE,uBAAuB;AAAA;AAI3B,aAAO;AAAA,aACA,GAAP;AACA,WAAK,OAAO,MAAM,6BAA6B;AAE/C,UACE,4BAA4B,KAAK,EAAE,YACnC,oBAAoB,KAAK,EAAE,UAC3B;AACA,cAAM,IAAIN,qBAAc,wCAAwC;AAAA;AAGlE,YAAM;AAAA;AAAA;AAAA;;ACzZZ,iBAAqD;AAAA,EAGnD,YACmB,QAIjB;AAJiB;AAHV,kCAAyBoG;AAAA;AAAA,QAS5B,cAAc,UAAiD;AACnE,UAAM,KAAK,KAAK,OAAO;AAEvB,QAAI,SAAS,SAAS,QAAQ;AAC5B,WAAK,MAAM,SAAS;AACpB,YAAM,GAAG,YAAY,OAAM,OAAM;AAC/B,cAAM,GAAG,2BAA2B,IAAI;AAAA,UACtC,WAAW,KAAK,OAAO;AAAA,UACvB,MAAM;AAAA,UACN,OAAO,SAAS;AAAA;AAAA;AAGpB;AAAA;AAGF,SAAK,MAAM,SAAS;AACpB,SAAK,MAAM,SAAS;AACpB,UAAM,GAAG,YAAY,OAAM,OAAM;AAC/B,YAAM,GAAG,2BAA2B,IAAI;AAAA,QACtC,WAAW,KAAK,OAAO;AAAA,QACvB,MAAM;AAAA,QACN,OAAO,SAAS;AAAA,QAChB,SAAS,SAAS;AAAA;AAAA;AAAA;AAAA,EAKhB,MAAM,UAAoB;AAChC,eAAW,UAAU,UAAU;AAC7B,UAAI;AACF,aAAK,uBAAuB;AAAA,eACrB,GAAP;AACA,cAAM,IAAI,UAAU,8BAA8B;AAAA;AAAA;AAAA;AAAA;qCAMqB;AAAA,EAG7E,YACmB,QACA,iBACA,oBACA,cACA,UACjB;AALiB;AACA;AACA;AACA;AACA;AAPX,mBAAU;AAAA;AAAA,QAUZ,QAAQ;AACZ,eAAW,YAAY,KAAK,iBAAiB;AAC3C,YAAM,SAAS,QACb,IAAI,WAAW;AAAA,QACb,oBAAoB,KAAK;AAAA,QACzB,IAAI,SAAS;AAAA;AAAA;AAInB,SAAK,UAAU;AACf,SAAK;AAAA;AAAA,QAGO,MAAM;AAClB,WAAO,KAAK,SAAS;AACnB,UAAI;AAGF,cAAM,KAAK;AAAA,eACJ,GAAP;AACA,aAAK,OAAO,KAAK,2BAA2B;AAG5C,cAAM,KAAK;AAAA;AAAA;AAAA;AAAA,QAKH,UAAU;AACtB,UAAM,CAAE,SAAU,MAAM,KAAK,mBAAmB,YAAY,OAAM,OAAM;AACtE,aAAO,KAAK,mBAAmB,uBAAuB,IAAI;AAAA,QACxD,kBAAkB;AAAA;AAAA;AAItB,QAAI,CAAC,MAAM,QAAQ;AAEjB,YAAM,KAAK;AACX;AAAA;AAIF,UAAM,QAAQ,IACZ,MAAM,IAAI,OAAM,SAAQ;AACtB,YAAM,CAAE,IAAI,OAAO,mBAAmB,aAAc;AACpD,YAAM,SAAS,MAAM,KAAK,aAAa,QAAQ;AAAA,QAC7C,QAAQ;AAAA,QACR;AAAA;AAGF,iBAAW,SAAS,OAAO,QAAQ;AAGjC,aAAK,OAAO,KAAK,MAAM,SAAS;AAAA,UAC9B,QAAQ;AAAA;AAAA;AAGZ,YAAM,eAAe,KAAK,UACxB,OAAO,OAAO,IAAI,OAAKC,sBAAe;AAUxC,UAAI,CAAC,OAAO,IAAI;AACd,cAAM,KAAK,mBAAmB,YAAY,OAAM,OAAM;AACpD,gBAAM,KAAK,mBAAmB,4BAA4B,IAAI;AAAA,YAC5D;AAAA,YACA,QAAQ;AAAA;AAAA;AAGZ,cAAM,KAAK,SAAS,OAClB,IAAI,IAAI,CAACJ,gCAAmB;AAE9B;AAAA;AAGF,aAAO,gBAAgB,SAAS,MAAM;AACtC,YAAM,KAAK,mBAAmB,YAAY,OAAM,OAAM;AACpD,cAAM,KAAK,mBAAmB,sBAAsB,IAAI;AAAA,UACtD;AAAA,UACA,iBAAiB,OAAO;AAAA,UACxB,OAAO,OAAO;AAAA,UACd,QAAQ;AAAA,UACR,WAAW,OAAO;AAAA,UAClB,kBAAkB,OAAO;AAAA;AAAA;AAI7B,YAAM,sBAAsB,IAAI,IAAY;AAAA,QAC1CA,gCAAmB,OAAO;AAAA,QAC1B,GAAG,OAAO,UAAU,IAAI,cACtBA,gCAAmB,SAAS;AAAA;AAGhC,YAAM,KAAK,SAAS,OAAO;AAAA;AAAA;AAAA,QAKnB,OAAO;AACnB,UAAM,IAAI,QAAc,aAAW,WAAW,SAAS;AAAA;AAAA,QAGnD,OAAO;AACX,SAAK,UAAU;AAAA;AAAA;;AC1JnB,MAAM,iBAAiBK;AACvB,MAAM,yBAAyBF;AAE/B,0BAA0B,QAA0C;AAClE,SAAO,OAAO,SAAS;AAAA;AAGzB,8BAA8B,QAAwB;AAtDtD;AAuDE,QAAM,MAAM,aAAO,SAAS,gBAAhB,mBAA8BlG;AAC1C,MAAI,CAAC,KAAK;AACR,UAAM,YAAY+F,gCAAmB;AACrC,UAAM,IAAIvG,kBAAW,WAAW;AAAA;AAElC,SAAO;AAAA;AAGT,oCAAoC,QAAwB;AA/D5D;AAgEE,QAAM,MAAM,aAAO,SAAS,gBAAhB,mBAA8B8B;AAC1C,MAAI,CAAC,KAAK;AACR,UAAM,YAAYyE,gCAAmB;AACrC,UAAM,IAAIvG,kBACR,WAAW;AAAA;AAGf,SAAO;AAAA;AAGT,yBACE,cACA,MACA,MACA,QACQ;AACR,MAAI,KAAK,SAAS,MAAM;AACtB,WAAO;AAAA;AAET,MAAI;AACF,QAAI,SAAS,QAAQ;AACnB,UAAI,OAAO,WAAW,MAAM;AAC1B,eAAOgF,yBAAK,KAAKA,yBAAK,QAAQ,KAAK,SAAS;AAAA;AAE9C,aAAO;AAAA,eACE,SAAS,OAAO;AACzB,aAAO,aAAa,WAAW,CAAE,KAAK,QAAQ,MAAM,KAAK;AAAA;AAE3D,WAAO;AAAA,WACA,GAAP;AACA,WAAO;AAAA;AAAA;2CAKgC;AAAA,EACzC,YACmB,SAOjB;AAPiB;AAAA;AAAA,QASb,QACJ,SACiC;AAEjC,WAAO,KAAK,oBAAoB,QAAQ;AAAA;AAAA,QAG5B,oBACZ,mBACiC;AACjC,UAAM,UAAU,cAAc,KAAK,QAAQ,QAAQ;AACnD,QAAI;AAEF,UAAI,SAAiB;AAMrB,UAAI;AACF,+BAAuB;AAAA,eAChB,GAAP;AACA,cAAM,IAAIhF,kBACR,uDACA;AAAA;AAIJ,YAAM,YAAYuG,gCAAmB;AAErC,YAAM,cAAc,qBAAqB;AACzC,YAAM,WAAWM,oCAAuB;AACxC,YAAM,iBAAiBA,oCACrB,2BAA2B;AAI7B,iBAAW,aAAa,KAAK,QAAQ,YAAY;AAC/C,YAAI,UAAU,kBAAkB;AAC9B,cAAI;AACF,qBAAS,MAAM,UAAU,iBACvB,QACA,UACA,QAAQ,MACR;AAAA,mBAEK,GAAP;AACA,kBAAM,IAAI7G,kBACR,aAAa,UAAU,YAAY,2CACnC;AAAA;AAAA;AAAA;AAOR,UAAI;AACJ,UAAI;AACF,+BAAuB,MAAM,KAAK,QAAQ,OAAO,QAAQ;AAAA,eAClD,GAAP;AACA,cAAM,IAAIA,kBAAW,uBAAuB;AAAA;AAE9C,UAAI,CAAC,sBAAsB;AACzB,cAAM,IAAI,MAAM;AAAA;AAElB,eAAS;AAGT,UAAI;AACF,uBAAe;AAAA,eACR,GAAP;AACA,cAAM,IAAIM,qBACR,yDACA;AAAA;AAKJ,UAAI,cAAc;AAClB,iBAAW,aAAa,KAAK,QAAQ,YAAY;AAC/C,YAAI,UAAU,oBAAoB;AAChC,cAAI;AACF,0BAAc,MAAM,UAAU,mBAAmB;AACjD,gBAAI,aAAa;AACf;AAAA;AAAA,mBAEK,GAAP;AACA,kBAAM,IAAIN,kBACR,aAAa,UAAU,YAAY,mDACnC;AAAA;AAAA;AAAA;AAKR,UAAI,CAAC,aAAa;AAChB,cAAM,IAAIA,kBACR;AAAA;AAMJ,UAAIuG,gCAAmB,YAAY,WAAW;AAC5C,cAAM,IAAIjG,qBACR;AAAA;AAKJ,UAAI,iBAAiB,SAAS;AAC5B,cAAM,CAAE,OAAO,SAAS,QAAS,OAAO;AACxC,cAAM,UAAU,IAAI;AACpB,YAAI,OAAO,KAAK,QAAQ;AACtB,kBAAQ,KAAK,OAAO,KAAK;AAAA;AAE3B,YAAI,OAAO,KAAK,SAAS;AACvB,kBAAQ,KAAK,GAAG,OAAO,KAAK;AAAA;AAG9B,mBAAW,uBAAuB,SAAS;AACzC,cAAI,SAAS,UAAU,oBAAoB,SAAS0E,yBAAK,MAAM;AAC7D,oBAAQ,KACN8B,WACE,UACA,yCAAyC,kCAAkC,SAAS;AAGxF;AAAA;AAEF,gBAAM,SAASC,gBACb,KAAK,QAAQ,cACb,UACA,MACA;AAGF,cAAI,UAAU;AACd,qBAAW,aAAa,KAAK,QAAQ,YAAY;AAC/C,gBAAI,UAAU,cAAc;AAC1B,kBAAI;AACF,sBAAM,OAAO,MAAM,UAAU,aAC3B;AAAA,kBACE;AAAA,kBACA;AAAA,kBACA,UAAU;AAAA,mBAEZ,OACA,QAAQ,MACR,KAAK,QAAQ;AAEf,oBAAI,MAAM;AACR,4BAAU;AACV;AAAA;AAAA,uBAEK,GAAP;AACA,sBAAM,IAAI/G,kBACR,aAAa,UAAU,YAAY,qCAAqC,QAAQ,UAChF;AAAA;AAAA;AAAA;AAKR,cAAI,CAAC,SAAS;AACZ,kBAAM,IAAIA,kBACR,8CAA8C,QAAQ;AAAA;AAAA;AAAA;AAO9D,iBAAW,aAAa,KAAK,QAAQ,YAAY;AAC/C,YAAI,UAAU,mBAAmB;AAC/B,cAAI;AACF,qBAAS,MAAM,UAAU,kBACvB,QACA,UACA,QAAQ;AAAA,mBAEH,GAAP;AACA,kBAAM,IAAIA,kBACR,aAAa,UAAU,YAAY,4CACnC;AAAA;AAAA;AAAA;AAMR,aAAO;AAAA,WACF,QAAQ;AAAA,QACX,iBAAiB;AAAA,QACjB,OAAO,IAAI;AAAA,QACX,IAAI;AAAA;AAAA,aAEC,OAAP;AACA,WAAK,QAAQ,OAAO,KAAK,MAAM;AAC/B,aAAO;AAAA,QACL,IAAI;AAAA,QACJ,QAAQ,QAAQ,UAAU,OAAO,OAAO;AAAA;AAAA;AAAA;AAAA;AAMhD,uBAAuB,QAAgB,cAAsB;AAC3D,MAAI,OAAO;AAEX,QAAM,SAAS,IAAI;AACnB,QAAM,YAAY,IAAI;AACtB,QAAM,mBAAmB,IAAI;AAE7B,QAAM,OAAO,CAAC,MAA8B;AAC1C,QAAI,MAAM;AACR,aAAO,KACL,gBAAgB,EAAE,sDAChB,IAAI,QAAQ;AAGhB;AAAA;AAGF,QAAI,EAAE,SAAS,UAAU;AACvB,UAAI;AACJ,UAAI;AACF,iBAAS,uBAAuB,EAAE;AAAA,eAC3B,GAAP;AACA,eAAO,MAAM,iCAAiC,EAAE,aAAa;AAC7D,eAAO,KAAK;AACZ;AAAA;AAQF,YAAM,cAAc,OAAO,SAAS,eAAe;AACnD,UAAI,OAAO,gBAAgB,YAAY,CAAC,MAAM,QAAQ,cAAc;AAClE,cAAM,iBAAiB,2BAA2B;AAClD,cAAM,WAAWsB,wCAA2B,EAAE;AAC9C,iBAAS;AAAA,aACJ;AAAA,UACH,UAAU;AAAA,eACL,OAAO;AAAA,YACV,aAAa;AAAA,iBACR;AAAA,eACFQ,0CAA6B;AAAA,eAC7BtB,mCAAsB;AAAA;AAAA;AAAA;AAAA;AAM/B,uBAAiB,KAAK;AAAA,eACb,EAAE,SAAS,YAAY;AAChC,uBAAiB,KACf,6BAA6B,EAAE,UAAU;AAAA,eAElC,EAAE,SAAS,YAAY;AAChC,gBAAU,KAAK,EAAE;AAAA,eACR,EAAE,SAAS,SAAS;AAC7B,aAAO,KAAK,EAAE;AAAA;AAAA;AAIlB,SAAO;AAAA,IACL;AAAA,IACA,UAAU;AACR,aAAO;AACP,aAAO;AAAA,QACL;AAAA,QACA;AAAA,QACA;AAAA;AAAA;AAAA;AAAA;;6BCjWuD;AAAA,EAC7D,YACmB,OACA,cACjB;AAFiB;AACA;AAAA;AAAA,QAGb,eACJ,MACA,QACqD;AACrD,QAAI,QAAQ;AACV,aAAO,KAAK,qBAAqB;AAAA;AAEnC,UAAM,WAAW,MAAM,KAAK,MAAM,eAAe;AACjD,WAAO,CAAE,UAAU,UAAU;AAAA;AAAA,EAG/B,gBAAqC;AACnC,WAAO,KAAK,MAAM;AAAA;AAAA,EAEpB,YAAY,IAA+B;AACzC,WAAO,KAAK,MAAM,YAAY;AAAA;AAAA,EAEhC,eAAe,IAA2B;AACxC,WAAO,KAAK,MAAM,eAAe;AAAA;AAAA,QAGrB,qBACZ,MACqD;AACrD,UAAM,SAAS;AAAA,MACb,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR,MAAM,2BAA2B;AAAA,UAC/B,MAAM,KAAK;AAAA,UACX,QAAQ,KAAK;AAAA;AAAA,QAEf,WAAW;AAAA,QACX,aAAa;AAAA,WACVA,mCAAsB,GAAG,KAAK,QAAQ,KAAK;AAAA,WAC3CsB,0CAA6B,GAAG,KAAK,QAAQ,KAAK;AAAA;AAAA;AAAA,MAGvD,MAAM;AAAA,QACJ,MAAM,KAAK;AAAA,QACX,QAAQ,KAAK;AAAA;AAAA;AAGjB,UAAM,sBAAgC,CAAC;AACvC,UAAM,WAAqB;AAC3B,UAAM,QAAQ,IAAI;AAClB,WAAO,oBAAoB,QAAQ;AACjC,YAAM,gBAAgB,oBAAoB;AAC1C,UAAI,CAAC,eAAe;AAClB;AAAA;AAEF,YAAM,YAAY,MAAM,KAAK,aAAa,QAAQ;AAAA,QAChD,QAAQ;AAAA,QACR;AAAA;AAGF,UAAI,UAAU,IAAI;AAChB,4BAAoB,KAAK,GAAG,UAAU;AACtC,iBAAS,KAAK,UAAU;AAAA,aACnB;AACL,cAAM,MAAM,UAAU,OAAO,IAAI,QAAQ,KAAK;AAAA;AAAA;AAIlD,WAAO;AAAA,MACL,UAAU,IAAK,MAAM,IAAI,GAAG,KAAK,QAAQ,KAAK;AAAA,MAC9C;AAAA;AAAA;AAAA;;2BCpEqE;AAAA,EAGzE,YAA6B,IAAU;AAAV;AAAA;AAAA,EAE7B,kBAA0B;AACxB,WAAO;AAAA;AAAA,QAGH,eAAe,MAAuC;AAC1D,UAAM,WAAW,MAAM,KAAK,GAAG,YAAY,OAAM,OAAM;AAErD,YAAM,oBAAoB,MAAM,KAAK,UAAU;AAG/C,YAAM,mBAAmB,kBAAkB,KACzC,OAAK,KAAK,SAAS,EAAE,QAAQ,KAAK,WAAW,EAAE;AAEjD,UAAI,kBAAkB;AACpB,cAAM,IAAIxB,qBACR,YAAY,KAAK,QAAQ,KAAK;AAAA;AAIlC,YAAM,QAAwB;AAAA,QAC5B,IAAImG;AAAA,QACJ,MAAM,KAAK;AAAA,QACX,QAAQ,KAAK;AAAA;AAGf,YAAM,GAAmB,aAAa,OAAO;AAE7C,aAAO;AAAA;AAGT,UAAM,KAAK,WAAW,cAAc;AAAA,MAClC,MAAM;AAAA,MACN,OAAO,CAAC,6BAA6B;AAAA,MACrC,SAAS;AAAA;AAGX,WAAO;AAAA;AAAA,QAGH,gBAAqC;AACzC,WAAO,MAAM,KAAK;AAAA;AAAA,QAGd,YAAY,IAA+B;AAC/C,UAAM,QAAQ,MAAM,KAAK,GAAmB,aACzC,MAAM,CAAE,KACR;AAEH,QAAI,CAAC,MAAM,QAAQ;AACjB,YAAM,IAAI1F,qBAAc,6BAA6B;AAAA;AAEvD,WAAO,MAAM;AAAA;AAAA,QAGT,eAAe,IAA2B;AAC9C,QAAI,CAAC,KAAK,YAAY;AACpB,YAAM,IAAI,MAAM;AAAA;AAGlB,UAAM,UAAU,MAAM,KAAK,GAAG,YAAY,OAAM,OAAM;AACpD,YAAM,CAAC,YAAY,MAAM,GAAmB,aACzC,MAAM,CAAE,KACR;AAEH,UAAI,CAAC,UAAU;AACb,cAAM,IAAIA,qBAAc,6BAA6B;AAAA;AAGvD,YAAM,GAAmB,aAAa,MAAM,CAAE,KAAM;AACpD,aAAO;AAAA;AAGT,UAAM,KAAK,WAAW,cAAc;AAAA,MAClC,MAAM;AAAA,MACN,OAAO;AAAA,MACP,SAAS,CAAC,6BAA6B;AAAA;AAAA;AAAA,MAI/B,aAAuC;AACjD,QAAI,CAAC,KAAK,aAAa;AACrB,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO,KAAK;AAAA;AAAA,QAGR,QAAQ,YAAqD;AACjE,SAAK,cAAc;AAEnB,UAAM,YAAY,MAAM,KAAK;AAE7B,UAAM,WAAW,UAAU,IAAI,cAAY;AACzC,aAAO,6BAA6B;AAAA;AAGtC,UAAM,KAAK,WAAW,cAAc;AAAA,MAClC,MAAM;AAAA,MACN;AAAA;AAAA;AAAA,QAIU,UAAU,SAAkC,KAAK,IAAI;AACjE,UAAM,YAAY,MAAM,OAAuB,aAAa;AAC5D,WACE,UAGG,OAAO,CAAC,CAAE,UAAW,SAAS,aAC9B,IAAI;AAAS,MACZ,IAAI,KAAK;AAAA,MACT,QAAQ,KAAK;AAAA,MACb,MAAM,KAAK;AAAA;AAAA;AAAA;;AC1HrB,2BACE,OACqC;AACrC,MAAI,CAAC,OAAO;AACV,WAAO;AAAA;AAGT,MAAI,CAAE,OAAO,UAAW;AAExB,MAAI,MAAM,UAAU,QAAW;AAC7B,QAAI;AACJ,QAAI;AACF,YAAM,OAAO,OAAO,KAAK,MAAM,OAAO,UAAU,SAAS;AACzD,eAAS,KAAK,MAAM;AAAA,YACpB;AACA,YAAM,IAAIf,kBAAW;AAAA;AAEvB,QAAI,OAAO,UAAU,QAAW;AAC9B,UAAI,CAAC,OAAO,UAAU,OAAO,QAAQ;AACnC,cAAM,IAAIA,kBAAW;AAAA;AAEvB,cAAQ,OAAO;AAAA;AAEjB,QAAI,OAAO,WAAW,QAAW;AAC/B,UAAI,CAAC,OAAO,UAAU,OAAO,SAAS;AACpC,cAAM,IAAIA,kBAAW;AAAA;AAEvB,eAAS,OAAO;AAAA;AAAA;AAIpB,SAAO,CAAE,OAAO;AAAA;AAGlB,+BAA6B,OAA0C;AACrE,QAAM,OAAO,KAAK,UAAU,CAAE,OAAO,MAAM,OAAO,QAAQ,MAAM;AAChE,QAAM,SAAS,OAAO,KAAK,MAAM,QAAQ,SAAS;AAClD,SAAO;AAAA;0BAGmD;AAAA,EAC1D,YAA6B,UAAgB;AAAhB;AAAA;AAAA,QAEvB,SAAS,SAAsD;AAvEvE;AAwEI,UAAM,KAAK,KAAK;AAEhB,QAAI,gBAAgB,GAAuB;AAE3C,eAAW,gBAAgB,+CAAS,WAAT,mBAAiB,UAAjB,YAA0B,IAAI;AACvD,sBAAgB,cAAc,QAAQ,0BAA0B;AAC9D,mBAAW,CAAE,KAAK,iBAAkB,aAAa,OAAO;AAItD,gBAAM,aAAa,GAAwB,UACxC,OAAO,aACP,MAAM,qBAAqB;AAC1B,iBAAK,SAAS,CAAE,KAAK,IAAI;AACzB,gBAAI,cAAc;AAChB,kBAAI,aAAa,WAAW,GAAG;AAC7B,qBAAK,SAAS,CAAE,OAAO,aAAa,GAAG;AAAA,yBAC9B,aAAa,SAAS,GAAG;AAClC,qBAAK,SACH,SACA,MACA,aAAa,IAAI,OAAK,EAAE;AAAA;AAAA;AAAA;AAKlC,eAAK,SAAS,aAAa,MAAM;AAAA;AAAA;AAAA;AAMvC,oBAAgB,cACb,OAAO,oBACP,aAAa,+BACb,QAAQ,aAAa;AAExB,UAAM,CAAE,OAAO,UAAWgH,kBAAgB,mCAAS;AACnD,QAAI,UAAU,QAAW;AACvB,sBAAgB,cAAc,MAAM,QAAQ;AAAA;AAE9C,QAAI,WAAW,QAAW;AACxB,sBAAgB,cAAc,OAAO;AAAA;AAGvC,QAAI,OAAO,MAAM;AAEjB,QAAI;AACJ,QAAI,UAAU,UAAa,KAAK,UAAU,OAAO;AAC/C,iBAAW,CAAE,aAAa;AAAA,WACrB;AACL,aAAO,KAAK,MAAM,GAAG;AACrB,iBAAW;AAAA,QACT,aAAa;AAAA,QACb,WAAWC,sBAAoB;AAAA,UAC7B;AAAA,UACA,QAAS,2BAAU,KAAK;AAAA;AAAA;AAAA;AAK9B,WAAO;AAAA,MACL,UAAU,KAAK,IAAI,OAAK,KAAK,MAAM,EAAE;AAAA,MACrC;AAAA;AAAA;AAAA,QAIE,kBAAkB,KAA4B;AAClD,UAAM,KAAK,SAA4B,iBACpC,MAAM,aAAa,KACnB;AAAA;AAAA,QAGC,2BAA2C;AAC/C,UAAM,IAAI,MAAM;AAAA;AAAA;;ACnHpB,MAAMC,iBAAe;AAAA,EACnB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAMF,MAAMC,mBAAiB;AACvB,MAAMC,qBAAmB;oBAkCA,MAAqB;AAC5C,QAAM,SAAe;AAErB,iBAAe,MAAc,SAAkB;AAC7C,QAAIF,eAAa,SAAS,OAAO;AAC/B;AAAA;AAIF,QACE,YAAY,UACZ,YAAY,QACZ,CAAC,UAAU,UAAU,WAAW,SAAS,OAAO,UAChD;AACA,aAAO,KAAK,CAAE,KAAK,MAAM,OAAO;AAChC;AAAA;AAIF,QAAI,OAAO,YAAY,UAAU;AAC/B;AAAA;AAIF,QAAI,MAAM,QAAQ,UAAU;AAC1B,iBAAW,QAAQ,SAAS;AAc1B,cAAM,MAAM;AACZ,YAAI,OAAO,SAAS,UAAU;AAC5B,iBAAO,KAAK,CAAE,KAAK,GAAG,QAAQ,QAAQ,OAAO;AAAA;AAAA;AAGjD;AAAA;AAIF,eAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,UAAW;AACnD,YAAM,OAAO,GAAG,QAAQ,QAAQ,KAAK;AAAA;AAAA;AAIzC,QAAM,IAAI;AAEV,SAAO;AAAA;qBAIiB,OAAa,UAAiC;AACtE,QAAM,SAAwB;AAE9B,aAAW,CAAE,KAAK,QAAQ,OAAO,aAAc,OAAO;AACpD,UAAM,MAAM,OAAO,kBAAkB;AACrC,QAAI,aAAa,UAAa,aAAa,MAAM;AAC/C,aAAO,KAAK,CAAE,WAAW,UAAU,KAAK,OAAO;AAAA,WAC1C;AACL,YAAM,QAAQ,OAAO,UAAU,kBAAkB;AACjD,UAAI,IAAI,UAAUC,oBAAkB,MAAM,UAAUC,oBAAkB;AACpE,eAAO,KAAK,CAAE,WAAW,UAAU,KAAK;AAAA;AAAA;AAAA;AAK9C,SAAO;AAAA;6BAWP,UACA,QACe;AAvKjB;AAyKE,QAAM,MAAMC,WAAS;AAIrB,MAAI,KAAK,CAAE,KAAK,iBAAiB,OAAO,OAAO,SAAS;AACxD,MAAI,KAAK,CAAE,KAAK,sBAAsB,OAAO,OAAO,SAAS;AAC7D,MAAI,KAAK,CAAE,KAAK,gBAAgB,OAAO,OAAO,SAAS;AAIvD,MAAI,CAAC,OAAO,SAAS,WAAW;AAC9B,QAAI,KAAK,CAAE,KAAK,sBAAsB,OAAO1G;AAAA;AAI/C,aAAW,YAAY,aAAO,cAAP,YAAoB,IAAI;AAC7C,QAAI,KAAK;AAAA,MACP,KAAK,aAAa,SAAS;AAAA,MAC3B,OAAO4F,gCAAmB,SAAS;AAAA;AAAA;AAIvC,SAAOe,YAAU,KAAK;AAAA;;AC5JxB,MAAM1G,eAAa;AASnB,4BAA4B,QAAgB;AAC1C,SAAO0F,kBAAW,QACf,OAAOiB,oCAAgB,IAAK,UAC5B,OAAO;AAAA;eAQU;AAAA,EACpB,YACmB,UACA,QACjB;AAFiB;AACA;AAAA;AAAA,QAGb,OAAO,YAAyB;AA7DxC;AA8DI,eAAW,aAAa,YAAY;AAClC,UAAI;AACF,cAAM,eAAe,MAAM,KAAK,SAC9B,iBAEC,MAAM,CAAE,YAAY,YACpB,MAAM,GACN,OAAO;AACV,YAAI,CAAC,aAAa,QAAQ;AAExB;AAAA;AAIF,cAAM,SAASd;AACf,cAAM,KAAK,SAA6B,kBACrC,OAAO;AAAA,UACN,WAAW,aAAa,GAAG;AAAA,UAC3B,MAAM;AAAA,UACN,eAAe;AAAA,WAEhB,WAAW,aACX,MAAM,CAAC;AASV,cAAM,SAQD,MAAM,KAAK,SACb,KAAK,uBAAuB,4BAA4B,SAAS;AAChE,iBAAO,QACJ,KAAK,4BACL,MAAM,CAAE,mBAAmB,YAC3B,MAAM,CAAE,OAAO;AAAA,WAEnB,OAAO;AAAA,UACN,UAAU;AAAA,UACV,iBAAiB;AAAA,UACjB,QAAQ;AAAA,UACR,wBAAwB;AAAA,UACxB,cAAc;AAAA,UACd,cAAc;AAAA,UACd,gBAAgB;AAAA,WAEjB,KAAK,iBACL,MAAM,CAAE,4BAA4B,YACpC,UAAU,KAAK,SAAS,IAAI,wBAC5B,cAAc,kBAAkB;AAAA,UAC/B,4BAA4B;AAAA,WAE7B,cAAc,aAAa;AAAA,UAC1B,+BAA+B;AAAA,WAEhC,QAAQ,gBAAgB,OACxB,QAAQ,kBAAkB;AAM7B,YAAI,CAAC,OAAO,QAAQ;AAClB,eAAK,OAAO,MACV,oBAAoB;AAEtB;AAAA;AAGF,cAAM;AAAA,UACJ;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,YACE,OAAO;AAMX,YAAI,CAAC,iBAAiB;AACpB,eAAK,OAAO,MACV,oBAAoB;AAEtB;AAAA;AAKF,cAAM,SAAS,KAAK,MAAM;AAC1B,cAAM,WAAW,OAAO,4BAA4B;AACpD,YAAI,cAA2C;AAE/C,YAAI,UAAU;AACZ,eAAK,OAAO,MAAM,GAAG;AACrB,iBAAO,SAAS,cAAc;AAAA,eACzB,OAAO,SAAS;AAAA,aAClB,wBAAwB;AAAA;AAAA;AAG7B,YAAI,QAAQ;AACV,gBAAM,eAAe,KAAK,MAAM;AAChC,cAAI,MAAM,QAAQ,iBAAiB,aAAa,QAAQ;AACtD,0BAAc,aAAa,IAAI;AAAM,cACnC,MAAMe;AAAA,cACN,OAAO;AAAA,cACP,SAAS,GAAG,EAAE,SAAS,EAAE;AAAA,cACzB,OAAO;AAAA;AAAA;AAAA;AAOb,eAAO,YAAY,OAChB,OAAO,SAAO,IAAI,cAClB,IAAI;AAAQ,UACX,MAAM,IAAI;AAAA,UACV,QAAQnE,4BAAe,IAAI;AAAA;AAE/B,YAAI,YAAY,QAAQ;AACtB,iBAAO,SAAS;AAAA,eACX,OAAO;AAAA,YACV,OAAO,CAAC,GAAI,mBAAO,WAAP,mBAAe,UAAf,YAAwB,IAAK,GAAG;AAAA;AAAA;AAKhD,cAAM,OAAO,mBAAmB;AAChC,YAAI,SAAS,cAAc;AACzB,eAAK,OAAO,MAAM,wBAAwB;AAC1C;AAAA;AAGF,eAAO,SAAS,MAAM;AACtB,eAAO,SAAS,aAAa;AAC7B,YAAI,CAAC,OAAO,SAAS,MAAM;AAGzB,iBAAO,SAAS,OAAO;AAAA;AAGzB,cAAM,cAAc,MAAM,KAAK,SAC7B,kBAEC,OAAO;AAAA,UACN,cAAc,KAAK,UAAU;AAAA,UAC7B;AAAA,WAED,MAAM,aAAa,UACnB,MAAM,iBAAiB,QACvB,WAAW,aACX,MAAM,CAAC,gBAAgB;AAE1B,YAAI,YAAY,WAAW,GAAG;AAC5B,eAAK,OAAO,MACV,UAAU;AAEZ;AAAA;AAUF,cAAM,gBAAgBoE,oBAAkB,UAAU;AAClD,cAAM,KAAK,SAAsB,UAC9B,MAAM,CAAE,WAAW,WACnB;AACH,cAAM,KAAK,SAAS,YAAY,UAAU,eAAe7G;AAAA,eAClD,OAAP;AACA,aAAK,OAAO,MAAM,oBAAoB,cAAc;AAAA;AAAA;AAAA;AAAA;;yBCjJ5B;AAAA,EAU9B,YAAY,KAAyB;AACnC,SAAK,MAAM;AACX,SAAK,iBAAiB;AACtB,SAAK,wBAAwB;AAC7B,SAAK,uBAAuB;AAC5B,SAAK,wBAAwB;AAC7B,SAAK,aAAa;AAClB,SAAK,oBAAoB;AACzB,SAAK,SAAS;AAAA;AAAA,EAchB,mBAAmB,UAA8C;AAC/D,SAAK,eAAe,KAAK,GAAG;AAC5B,WAAO;AAAA;AAAA,EAgBT,sBAAsB,UAA8C;AAClE,SAAK,iBAAiB,CAAC,GAAG;AAC1B,SAAK,wBAAwB;AAC7B,WAAO;AAAA;AAAA,EAUT,uBACE,KACA,UACoB;AACpB,SAAK,qBAAqB,OAAO;AACjC,WAAO;AAAA;AAAA,EAaT,yBACE,YACoB;AACpB,+BAAO,MAAM,KAAK,uBAAuB;AACzC,WAAO;AAAA;AAAA,EAST,gBAAgB,YAAoD;AAClE,SAAK,WAAW,KAAK,GAAG;AACxB,WAAO;AAAA;AAAA,EAWT,kBAAkB,YAAoD;AACpE,SAAK,aAAa,CAAC,GAAG;AACtB,SAAK,oBAAoB;AACzB,WAAO;AAAA;AAAA,EAYT,oBAAoB,QAAoD;AACtE,SAAK,SAAS;AACd,WAAO;AAAA;AAAA,QAMH,QAMH;AACD,UAAM,CAAE,QAAQ,UAAU,UAAW,KAAK;AAE1C,UAAM,SAAS,KAAK;AACpB,UAAM,aAAa,KAAK;AACxB,UAAM,SAAS,KAAK,UAAU;AAE9B,UAAM,WAAW,MAAM,SAAS;AAChC,UAAM,SAAS,QAAQ,OAAO;AAAA,MAC5B,WAAWM,iCACT,qCACA;AAAA;AAIJ,UAAM,KAAK,IAAI,eAAe,UAAU;AAExC,UAAM,qBAAqB,IAAI,0BAA0B,UAAU;AACnE,UAAM,eAAeiB,4BAAgB,WAAW;AAChD,UAAM,eAAe,IAAI,qCAAqC;AAAA,MAC5D;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAEF,UAAM,kBAAkB,IAAI,oBAAoB;AAEhD,UAAM,gBAAgB,IAAI,qBAAqB;AAC/C,UAAM,WAAW,IAAI,SAAS,UAAU;AACxC,UAAM,yBAAyB,IAAI,6BAA6B;AAChE,UAAM,mBAAmB,IAAI,+BAC3B,QACA,CAAC,eAAe,yBAChB,oBACA,cACA;AAGF,UAAM,mBAAmB,IAAI,yBAAyB;AACtD,UAAM,mBAAmB,IAAI,qBAAqB,QAAQ;AAC1D,UAAM,kBAAkB,IAAI,uBAC1B,eACA;AAEF,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAAA,EAII,oBAAkC;AACxC,UAAM,iBAAiC,KAAK,wBACxC,CAAC,IAAIuD,wCAA2B,GAAG,KAAK,kBACxC;AAAA,MACE,IAAIA;AAAA,MACJ,IAAIC;AAAA,MACJ,IAAIC;AAAA,MACJ,IAAIC,qCACFC,2BAAc,KAAK;AAAA,MAErB,GAAG,KAAK;AAAA;AAGd,WAAOC,4BAAe,MAAM;AAAA;AAAA,EAGtB,kBAAsC;AAC5C,UAAM,CAAE,QAAQ,QAAQ,UAAW,KAAK;AACxC,UAAM,eAAe5D,4BAAgB,WAAW;AAEhD,SAAK;AAEL,UAAM,uBAA4D;AAAA,MAChE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,MAAM;AAAA,SACH,KAAK;AAAA;AAIV,UAAM,aAAiC;AAAA,MACrC,IAAI,qBAAqB,CAAE,WAAW,sBAAsB;AAAA,MAC5D,IAAI;AAAA;AAIN,QAAI,CAAC,KAAK,mBAAmB;AAC3B,iBAAW,KACT,IAAI,uBACJ,4BAA4B,WAAW,QAAQ,CAAE,UACjD,yBAAyB,WAAW,QAAQ,CAAE,UAC9C,yBAAyB,WAAW,QAAQ,CAAE,UAC9C,uBAAuB,WAAW,QAAQ,CAAE,UAC5C,iCAAiC,WAAW,QAAQ,CAAE,UACtD,IAAI,mBAAmB,CAAE,QAAQ,UACjC,oBAAoB,WAAW,QAAQ,CAAE,QAAQ,UACjD,IAAI,gCAAgC,CAAE;AAAA;AAK1C,eAAW,KAAK,GAAG,KAAK;AAExB,WAAO;AAAA;AAAA,EAKD,kCAAkC;AACxC,UAAM,KAAK,KAAK,IAAI,OAAO,kBAAkB;AAC7C,QAAI,yBAAI,IAAI,WAAW;AACrB,YAAM,IAAI,MACR;AAAA;AAGJ,QAAI,yBAAI,IAAI,cAAc;AACxB,YAAM,IAAI,MACR;AAAA;AAGJ,QAAI,yBAAI,IAAI,iBAAiB;AAC3B,YAAM,IAAI,MACR;AAAA;AAGJ,QAAI,yBAAI,IAAI,aAAa;AACvB,YAAM,IAAI,MACR;AAAA;AAAA;AAAA;;gCCjUN,SACyB;AACzB,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,MACE;AAEJ,QAAM,SAAS6D;AACf,SAAO,IAAIC,4BAAQ;AAEnB,QAAM,kBACJ,OAAO,mBAAmB,uBAAuB;AACnD,MAAI,iBAAiB;AACnB,WAAO,KAAK;AAAA;AAGd,MAAI,iBAAiB;AACnB,WACG,IAAI,aAAa,OAAO,KAAK,QAAQ;AACpC,YAAM,CAAE,UAAU,YAAa,MAAM,gBAAgB,SAAS;AAAA,QAC5D,QAAQ,wBAAwB,IAAI;AAAA,QACpC,QAAQ,2BAA2B,IAAI;AAAA,QACvC,YAAY,4BAA4B,IAAI;AAAA;AAI9C,UAAI,SAAS,aAAa;AACxB,cAAM,MAAM,IAAI,IAAI,iBAAiB,IAAI;AACzC,YAAI,aAAa,OAAO;AACxB,YAAI,aAAa,IAAI,SAAS,SAAS;AACvC,YAAI,UAAU,QAAQ,IAAI,IAAI,WAAW,IAAI;AAAA;AAI/C,UAAI,KAAK;AAAA,OAEV,IAAI,yBAAyB,OAAO,KAAK,QAAQ;AAChD,YAAM,CAAE,OAAQ,IAAI;AACpB,YAAM,CAAE,YAAa,MAAM,gBAAgB,SAAS;AAAA,QAClD,QAAQ,kBAAkB,CAAE,gBAAgB;AAAA;AAE9C,UAAI,CAAC,SAAS,QAAQ;AACpB,cAAM,IAAIlF,qBAAc,sBAAsB;AAAA;AAEhD,UAAI,OAAO,KAAK,KAAK,SAAS;AAAA,OAE/B,OAAO,yBAAyB,OAAO,KAAK,QAAQ;AACnD,YAAM,CAAE,OAAQ,IAAI;AACpB,YAAM,gBAAgB,kBAAkB;AACxC,UAAI,OAAO,KAAK;AAAA,OAEjB,IAAI,4CAA4C,OAAO,KAAK,QAAQ;AACnE,YAAM,CAAE,MAAM,WAAW,QAAS,IAAI;AACtC,YAAM,CAAE,YAAa,MAAM,gBAAgB,SAAS;AAAA,QAClD,QAAQ,kBAAkB;AAAA,UACxB;AAAA,UACA,sBAAsB;AAAA,UACtB,iBAAiB;AAAA;AAAA;AAGrB,UAAI,CAAC,SAAS,QAAQ;AACpB,cAAM,IAAIA,qBACR,oBAAoB,2BAA2B,uBAAuB;AAAA;AAG1E,UAAI,OAAO,KAAK,KAAK,SAAS;AAAA;AAAA;AAIpC,MAAI,iBAAiB;AACnB,WACG,KAAK,cAAc,OAAO,KAAK,QAAQ;AACtC,YAAM,QAAQ,MAAM,oBAAoB,KAAKmF;AAC7C,YAAM,SAASC,uBAAG,IAAI,MAAM,QAAQ,CAAE,SAAS;AAI/C,UAAI,CAAC,QAAQ;AACX,6BAAqB;AAAA;AAGvB,YAAM,SAAS,MAAM,gBAAgB,eAAe,OAAO;AAC3D,UAAI,OAAO,KAAK,KAAK;AAAA,OAEtB,IAAI,cAAc,OAAO,MAAM,QAAQ;AACtC,YAAM,YAAY,MAAM,gBAAgB;AACxC,UAAI,OAAO,KAAK,KAAK,UAAU,IAAI,SAAQ,MAAM;AAAA,OAGlD,IAAI,kBAAkB,OAAO,KAAK,QAAQ;AACzC,YAAM,CAAE,MAAO,IAAI;AACnB,YAAM,SAAS,MAAM,gBAAgB,YAAY;AACjD,UAAI,OAAO,KAAK,KAAK;AAAA,OAEtB,OAAO,kBAAkB,OAAO,KAAK,QAAQ;AAC5C,2BAAqB;AAErB,YAAM,CAAE,MAAO,IAAI;AACnB,YAAM,gBAAgB,eAAe;AACrC,UAAI,OAAO,KAAK;AAAA;AAAA;AAItB,MAAI,kBAAkB;AACpB,WAAO,KAAK,qBAAqB,OAAO,KAAK,QAAQ;AACnD,YAAM,QAAQ,MAAM,oBAAoB,KAAKC;AAC7C,YAAM,SAAS,MAAM,iBAAiB,gBAAgB;AACtD,UAAI,OAAO,KAAK,KAAK;AAAA;AAAA;AAIzB,SAAO,IAAIC;AACX,SAAO;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;"}