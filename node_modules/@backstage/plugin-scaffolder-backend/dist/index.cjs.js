'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var errors = require('@backstage/errors');
var catalogModel = require('@backstage/catalog-model');
var path = require('path');
var fs = require('fs-extra');
var integration = require('@backstage/integration');
var rest = require('@octokit/rest');
var globby = require('globby');
var backendCommon = require('@backstage/backend-common');
var lodash = require('lodash');
var octokitPluginCreatePullRequest = require('octokit-plugin-create-pull-request');
var azureDevopsNodeApi = require('azure-devops-node-api');
var node = require('@gitbeaker/node');
var fetch = require('cross-fetch');
var parseGitUrl = require('git-url-parse');
var url = require('url');
var child_process = require('child_process');
var stream = require('stream');
var yaml = require('yaml');
var os = require('os');
var uuid = require('uuid');
var winston = require('winston');
var express = require('express');
var Router = require('express-promise-router');
var jsonschema = require('jsonschema');
var luxon = require('luxon');
var Handlebars = require('handlebars');

function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }

var path__default = /*#__PURE__*/_interopDefaultLegacy(path);
var fs__default = /*#__PURE__*/_interopDefaultLegacy(fs);
var globby__default = /*#__PURE__*/_interopDefaultLegacy(globby);
var fetch__default = /*#__PURE__*/_interopDefaultLegacy(fetch);
var parseGitUrl__default = /*#__PURE__*/_interopDefaultLegacy(parseGitUrl);
var os__default = /*#__PURE__*/_interopDefaultLegacy(os);
var express__default = /*#__PURE__*/_interopDefaultLegacy(express);
var Router__default = /*#__PURE__*/_interopDefaultLegacy(Router);

const createTemplateAction = (templateAction) => {
  return templateAction;
};

function createCatalogRegisterAction(options) {
  const {catalogClient, integrations} = options;
  return createTemplateAction({
    id: "catalog:register",
    description: "Registers entities from a catalog descriptor file in the workspace into the software catalog.",
    schema: {
      input: {
        oneOf: [
          {
            type: "object",
            required: ["catalogInfoUrl"],
            properties: {
              catalogInfoUrl: {
                title: "Catalog Info URL",
                description: "An absolute URL pointing to the catalog info file location",
                type: "string"
              }
            }
          },
          {
            type: "object",
            required: ["repoContentsUrl"],
            properties: {
              repoContentsUrl: {
                title: "Repository Contents URL",
                description: "An absolute URL pointing to the root of a repository directory tree",
                type: "string"
              },
              catalogInfoPath: {
                title: "Fetch URL",
                description: "A relative path from the repo root pointing to the catalog info file, defaults to /catalog-info.yaml",
                type: "string"
              }
            }
          }
        ]
      }
    },
    async handler(ctx) {
      const {input} = ctx;
      let catalogInfoUrl;
      if ("catalogInfoUrl" in input) {
        catalogInfoUrl = input.catalogInfoUrl;
      } else {
        const {
          repoContentsUrl,
          catalogInfoPath = "/catalog-info.yaml"
        } = input;
        const integration = integrations.byUrl(repoContentsUrl);
        if (!integration) {
          throw new errors.InputError(`No integration found for host ${repoContentsUrl}`);
        }
        catalogInfoUrl = integration.resolveUrl({
          base: repoContentsUrl,
          url: catalogInfoPath
        });
      }
      ctx.logger.info(`Registering ${catalogInfoUrl} in the catalog`);
      const result = await catalogClient.addLocation({
        type: "url",
        target: catalogInfoUrl
      }, ctx.token ? {token: ctx.token} : {});
      if (result.entities.length >= 1) {
        const {kind, name, namespace} = catalogModel.getEntityName(result.entities[0]);
        ctx.output("entityRef", `${kind}:${namespace}/${name}`);
        ctx.output("catalogInfoUrl", catalogInfoUrl);
      }
    }
  });
}

async function fetchContents({
  reader,
  integrations,
  baseUrl,
  fetchUrl = ".",
  outputPath
}) {
  if (typeof fetchUrl !== "string") {
    throw new errors.InputError(`Invalid url parameter, expected string, got ${typeof fetchUrl}`);
  }
  let fetchUrlIsAbsolute = false;
  try {
    new URL(fetchUrl);
    fetchUrlIsAbsolute = true;
  } catch {
  }
  if (!fetchUrlIsAbsolute && (baseUrl == null ? void 0 : baseUrl.startsWith("file://"))) {
    const basePath = baseUrl.slice("file://".length);
    if (path.isAbsolute(fetchUrl)) {
      throw new errors.InputError(`Fetch URL may not be absolute for file locations, ${fetchUrl}`);
    }
    const srcDir = path.resolve(basePath, "..", fetchUrl);
    await fs__default['default'].copy(srcDir, outputPath);
  } else {
    let readUrl;
    if (fetchUrlIsAbsolute) {
      readUrl = fetchUrl;
    } else if (baseUrl) {
      const integration = integrations.byUrl(baseUrl);
      if (!integration) {
        throw new errors.InputError(`No integration found for location ${baseUrl}`);
      }
      readUrl = integration.resolveUrl({
        url: fetchUrl,
        base: baseUrl
      });
    } else {
      throw new errors.InputError(`Failed to fetch, template location could not be determined and the fetch URL is relative, ${fetchUrl}`);
    }
    const res = await reader.readTree(readUrl);
    await fs__default['default'].ensureDir(outputPath);
    await res.dir({targetDir: outputPath});
  }
}

function createFetchPlainAction(options) {
  const {reader, integrations} = options;
  return createTemplateAction({
    id: "fetch:plain",
    description: "Downloads content and places it in the workspace, or optionally in a subdirectory specified by the 'targetPath' input option.",
    schema: {
      input: {
        type: "object",
        required: ["url"],
        properties: {
          url: {
            title: "Fetch URL",
            description: "Relative path or absolute URL pointing to the directory tree to fetch",
            type: "string"
          },
          targetPath: {
            title: "Target Path",
            description: "Target path within the working directory to download the contents to.",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      var _a;
      ctx.logger.info("Fetching plain content from remote URL");
      const targetPath = (_a = ctx.input.targetPath) != null ? _a : "./";
      const outputPath = path__default['default'].resolve(ctx.workspacePath, targetPath);
      if (!outputPath.startsWith(ctx.workspacePath)) {
        throw new errors.InputError(`Fetch action targetPath may not specify a path outside the working directory`);
      }
      await fetchContents({
        reader,
        integrations,
        baseUrl: ctx.baseUrl,
        fetchUrl: ctx.input.url,
        outputPath
      });
    }
  });
}

function createFetchCookiecutterAction(options) {
  const {reader, templaters, integrations} = options;
  return createTemplateAction({
    id: "fetch:cookiecutter",
    description: "Downloads a template from the given URL into the workspace, and runs cookiecutter on it.",
    schema: {
      input: {
        type: "object",
        required: ["url"],
        properties: {
          url: {
            title: "Fetch URL",
            description: "Relative path or absolute URL pointing to the directory tree to fetch",
            type: "string"
          },
          targetPath: {
            title: "Target Path",
            description: "Target path within the working directory to download the contents to.",
            type: "string"
          },
          values: {
            title: "Template Values",
            description: "Values to pass on to cookiecutter for templating",
            type: "object"
          },
          copyWithoutRender: {
            title: "Copy Without Render",
            description: "Avoid rendering directories and files in the template",
            type: "array",
            items: {
              type: "string"
            }
          },
          extensions: {
            title: "Template Extensions",
            description: "Jinja2 extensions to add filters, tests, globals or extend the parser. Extensions must be installed in the container or on the host where Cookiecutter executes. See the contrib directory in Backstage's repo for more information",
            type: "array",
            items: {
              type: "string"
            }
          },
          imageName: {
            title: "Cookiecutter Docker image",
            description: "Specify a custom Docker image to run cookiecutter, to override the default: 'spotify/backstage-cookiecutter'. This can be used to execute cookiecutter with Template Extensions. Used only when a local cookiecutter is not found.",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      var _a;
      ctx.logger.info("Fetching and then templating using cookiecutter");
      const workDir = await ctx.createTemporaryDirectory();
      const templateDir = path.resolve(workDir, "template");
      const templateContentsDir = path.resolve(templateDir, "{{cookiecutter and 'contents'}}");
      const resultDir = path.resolve(workDir, "result");
      if (ctx.input.copyWithoutRender && !Array.isArray(ctx.input.copyWithoutRender)) {
        throw new errors.InputError("Fetch action input copyWithoutRender must be an Array");
      }
      if (ctx.input.extensions && !Array.isArray(ctx.input.extensions)) {
        throw new errors.InputError("Fetch action input extensions must be an Array");
      }
      await fetchContents({
        reader,
        integrations,
        baseUrl: ctx.baseUrl,
        fetchUrl: ctx.input.url,
        outputPath: templateContentsDir
      });
      const cookiecutter = templaters.get("cookiecutter");
      const values = {
        ...ctx.input.values,
        _copy_without_render: ctx.input.copyWithoutRender,
        _extensions: ctx.input.extensions,
        imageName: ctx.input.imageName
      };
      await cookiecutter.run({
        workspacePath: workDir,
        logStream: ctx.logStream,
        values
      });
      const targetPath = (_a = ctx.input.targetPath) != null ? _a : "./";
      const outputPath = path.resolve(ctx.workspacePath, targetPath);
      if (!outputPath.startsWith(ctx.workspacePath)) {
        throw new errors.InputError(`Fetch action targetPath may not specify a path outside the working directory`);
      }
      await fs__default['default'].copy(resultDir, outputPath);
    }
  });
}

async function initRepoAndPush({
  dir,
  remoteUrl,
  auth,
  logger
}) {
  const git = backendCommon.Git.fromAuth({
    username: auth.username,
    password: auth.password,
    logger
  });
  await git.init({
    dir
  });
  const paths = await globby__default['default'](["./**", "./**/.*", "!.git"], {
    cwd: dir,
    gitignore: true,
    dot: true
  });
  for (const filepath of paths) {
    await git.add({dir, filepath});
  }
  await git.commit({
    dir,
    message: "Initial commit",
    author: {name: "Scaffolder", email: "scaffolder@backstage.io"},
    committer: {name: "Scaffolder", email: "scaffolder@backstage.io"}
  });
  await git.addRemote({
    dir,
    url: remoteUrl,
    remote: "origin"
  });
  await git.push({
    dir,
    remote: "origin"
  });
}
const enableBranchProtectionOnDefaultRepoBranch = async ({
  repoName,
  client,
  owner,
  logger
}) => {
  const tryOnce = async () => {
    try {
      await client.repos.updateBranchProtection({
        mediaType: {
          previews: ["luke-cage-preview"]
        },
        owner,
        repo: repoName,
        branch: "master",
        required_status_checks: {strict: true, contexts: []},
        restrictions: null,
        enforce_admins: true,
        required_pull_request_reviews: {required_approving_review_count: 1}
      });
    } catch (e) {
      if (e.message.includes("Upgrade to GitHub Pro or make this repository public to enable this feature")) {
        logger.warn("Branch protection was not enabled as it requires GitHub Pro for private repositories");
      } else {
        throw e;
      }
    }
  };
  try {
    await tryOnce();
  } catch (e) {
    if (!e.message.includes("Branch not found")) {
      throw e;
    }
    await new Promise((resolve) => setTimeout(resolve, 600));
    await tryOnce();
  }
};

const getRepoSourceDirectory = (workspacePath, sourcePath) => {
  if (sourcePath) {
    const safeSuffix = path.normalize(sourcePath).replace(/^(\.\.(\/|\\|$))+/, "");
    return path.join(workspacePath, safeSuffix);
  }
  return workspacePath;
};
const parseRepoUrl = (repoUrl) => {
  var _a;
  let parsed;
  try {
    parsed = new URL(`https://${repoUrl}`);
  } catch (error) {
    throw new errors.InputError(`Invalid repo URL passed to publisher, got ${repoUrl}, ${error}`);
  }
  const host = parsed.host;
  const owner = parsed.searchParams.get("owner");
  if (!owner) {
    throw new errors.InputError(`Invalid repo URL passed to publisher: ${repoUrl}, missing owner`);
  }
  const repo = parsed.searchParams.get("repo");
  if (!repo) {
    throw new errors.InputError(`Invalid repo URL passed to publisher: ${repoUrl}, missing repo`);
  }
  const organization = (_a = parsed.searchParams.get("organization")) != null ? _a : void 0;
  return {host, owner, repo, organization};
};

function createPublishGithubAction(options) {
  const {integrations} = options;
  const credentialsProviders = new Map(integrations.github.list().map((integration$1) => {
    const provider = integration.GithubCredentialsProvider.create(integration$1.config);
    return [integration$1.config.host, provider];
  }));
  return createTemplateAction({
    id: "publish:github",
    description: "Initializes a git repository of contents in workspace and publishes it to GitHub.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          description: {
            title: "Repository Description",
            type: "string"
          },
          access: {
            title: "Repository Access",
            type: "string"
          },
          repoVisibility: {
            title: "Repository Visibility",
            type: "string",
            enum: ["private", "public", "internal"]
          },
          sourcePath: {
            title: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
            type: "string"
          },
          collaborators: {
            title: "Collaborators",
            description: "Provide users with permissions",
            type: "array",
            items: {
              type: "object",
              required: ["username", "access"],
              properties: {
                access: {
                  type: "string",
                  description: "The type of access for the user",
                  enum: ["push", "pull", "admin", "maintain", "triage"]
                },
                username: {
                  type: "string",
                  description: "The username or group"
                }
              }
            }
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      const {
        repoUrl,
        description,
        access,
        repoVisibility = "private",
        collaborators
      } = ctx.input;
      const {owner, repo, host} = parseRepoUrl(repoUrl);
      const credentialsProvider = credentialsProviders.get(host);
      const integrationConfig = integrations.github.byHost(host);
      if (!credentialsProvider || !integrationConfig) {
        throw new errors.InputError(`No matching integration configuration for host ${host}, please check your integrations config`);
      }
      const {token} = await credentialsProvider.getCredentials({
        url: `https://${host}/${encodeURIComponent(owner)}/${encodeURIComponent(repo)}`
      });
      if (!token) {
        throw new errors.InputError(`No token available for host: ${host}, with owner ${owner}, and repo ${repo}`);
      }
      const client = new rest.Octokit({
        auth: token,
        baseUrl: integrationConfig.config.apiBaseUrl,
        previews: ["nebula-preview"]
      });
      const user = await client.users.getByUsername({
        username: owner
      });
      const repoCreationPromise = user.data.type === "Organization" ? client.repos.createInOrg({
        name: repo,
        org: owner,
        private: repoVisibility === "private",
        visibility: repoVisibility,
        description
      }) : client.repos.createForAuthenticatedUser({
        name: repo,
        private: repoVisibility === "private",
        description
      });
      const {data: newRepo} = await repoCreationPromise;
      if (access == null ? void 0 : access.startsWith(`${owner}/`)) {
        const [, team] = access.split("/");
        await client.teams.addOrUpdateRepoPermissionsInOrg({
          org: owner,
          team_slug: team,
          owner,
          repo,
          permission: "admin"
        });
      } else if (access && access !== owner) {
        await client.repos.addCollaborator({
          owner,
          repo,
          username: access,
          permission: "admin"
        });
      }
      if (collaborators) {
        for (const {
          access: permission,
          username: team_slug
        } of collaborators) {
          try {
            await client.teams.addOrUpdateRepoPermissionsInOrg({
              org: owner,
              team_slug,
              owner,
              repo,
              permission
            });
          } catch (e) {
            ctx.logger.warn(`Skipping ${permission} access for ${team_slug}, ${e.message}`);
          }
        }
      }
      const remoteUrl = newRepo.clone_url;
      const repoContentsUrl = `${newRepo.html_url}/blob/master`;
      await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, ctx.input.sourcePath),
        remoteUrl,
        auth: {
          username: "x-access-token",
          password: token
        },
        logger: ctx.logger
      });
      try {
        await enableBranchProtectionOnDefaultRepoBranch({
          owner,
          client,
          repoName: newRepo.name,
          logger: ctx.logger
        });
      } catch (e) {
        throw new Error(`Failed to add branch protection to '${newRepo.name}', ${e}`);
      }
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
    }
  });
}

class GithubResponseError extends errors.CustomErrorBase {
}
const defaultClientFactory = async ({
  integrations,
  owner,
  repo,
  host = "github.com"
}) => {
  var _a;
  const integrationConfig = (_a = integrations.github.byHost(host)) == null ? void 0 : _a.config;
  if (!integrationConfig) {
    throw new errors.InputError(`No integration for host ${host}`);
  }
  const credentialsProvider = integration.GithubCredentialsProvider.create(integrationConfig);
  if (!credentialsProvider) {
    throw new errors.InputError(`No matching credentials for host ${host}, please check your integrations config`);
  }
  const {token} = await credentialsProvider.getCredentials({
    url: `https://${host}/${encodeURIComponent(owner)}/${encodeURIComponent(repo)}`
  });
  if (!token) {
    throw new errors.InputError(`No token available for host: ${host}, with owner ${owner}, and repo ${repo}`);
  }
  const OctokitPR = rest.Octokit.plugin(octokitPluginCreatePullRequest.createPullRequest);
  return new OctokitPR({
    auth: token,
    baseUrl: integrationConfig.apiBaseUrl
  });
};
const createPublishGithubPullRequestAction = ({
  integrations,
  clientFactory = defaultClientFactory
}) => {
  return createTemplateAction({
    id: "publish:github:pull-request",
    schema: {
      input: {
        required: ["owner", "repo", "title", "description", "branchName"],
        type: "object",
        properties: {
          owner: {
            type: "string",
            title: "Repository owner",
            description: "The owner of the target repository"
          },
          repo: {
            type: "string",
            title: "Repository",
            description: "The github repository to create the file in"
          },
          branchName: {
            type: "string",
            title: "Branch Name",
            description: "The name for the branch"
          },
          title: {
            type: "string",
            title: "Pull Request Name",
            description: "The name for the pull request"
          },
          description: {
            type: "string",
            title: "Pull Request Description",
            description: "The description of the pull request"
          },
          sourcePath: {
            type: "string",
            title: "Working Subdirectory",
            description: "Subdirectory of working directory to copy changes from"
          },
          targetPath: {
            type: "string",
            title: "Repository Subdirectory",
            description: "Subdirectory of repository to apply changes to"
          }
        }
      },
      output: {
        required: ["remoteUrl"],
        type: "object",
        properties: {
          remoteUrl: {
            type: "string",
            title: "Pull Request URL",
            description: "Link to the pull request in Github"
          }
        }
      }
    },
    async handler(ctx) {
      let {owner, repo} = ctx.input;
      let host = "github.com";
      const {
        repoUrl,
        branchName,
        title,
        description,
        targetPath,
        sourcePath
      } = ctx.input;
      if (repoUrl) {
        const parsed = parseRepoUrl(repoUrl);
        host = parsed.host;
        owner = parsed.owner;
        repo = parsed.repo;
      }
      if (!host || !owner || !repo) {
        throw new errors.InputError("must provide either valid repo URL or owner and repo as parameters");
      }
      const client = await clientFactory({integrations, host, owner, repo});
      const fileRoot = sourcePath ? path__default['default'].resolve(ctx.workspacePath, sourcePath) : ctx.workspacePath;
      const localFilePaths = await globby__default['default'](["./**", "./**/.*", "!.git"], {
        cwd: fileRoot,
        gitignore: true,
        dot: true
      });
      const fileContents = await Promise.all(localFilePaths.map((p) => fs.readFile(path__default['default'].resolve(fileRoot, p))));
      const repoFilePaths = localFilePaths.map((repoFilePath) => {
        return targetPath ? `${targetPath}/${repoFilePath}` : repoFilePath;
      });
      const changes = [
        {
          files: lodash.zipObject(repoFilePaths, fileContents.map((buf) => buf.toString())),
          commit: title
        }
      ];
      try {
        const response = await client.createPullRequest({
          owner,
          repo,
          title,
          changes,
          body: description,
          head: branchName
        });
        if (!response) {
          throw new GithubResponseError("null response from Github");
        }
        ctx.output("remoteUrl", response.data.html_url);
      } catch (e) {
        throw new GithubResponseError("Pull request creation failed", e);
      }
    }
  });
};

function createPublishAzureAction(options) {
  const {integrations} = options;
  return createTemplateAction({
    id: "publish:azure",
    description: "Initializes a git repository of the content in the workspace, and publishes it to Azure.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          description: {
            title: "Repository Description",
            type: "string"
          },
          sourcePath: {
            title: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
            type: "string"
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      const {owner, repo, host, organization} = parseRepoUrl(ctx.input.repoUrl);
      if (!organization) {
        throw new errors.InputError(`Invalid URL provider was included in the repo URL to create ${ctx.input.repoUrl}, missing organization`);
      }
      const integrationConfig = integrations.azure.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(`No matching integration configuration for host ${host}, please check your integrations config`);
      }
      if (!integrationConfig.config.token) {
        throw new errors.InputError(`No token provided for Azure Integration ${host}`);
      }
      const authHandler = azureDevopsNodeApi.getPersonalAccessTokenHandler(integrationConfig.config.token);
      const webApi = new azureDevopsNodeApi.WebApi(`https://${host}/${organization}`, authHandler);
      const client = await webApi.getGitApi();
      const createOptions = {name: repo};
      const returnedRepo = await client.createRepository(createOptions, owner);
      if (!returnedRepo) {
        throw new errors.InputError(`Unable to create the repository with Organization ${organization}, Project ${owner} and Repo ${repo}.
          Please make sure that both the Org and Project are typed corrected and exist.`);
      }
      const remoteUrl = returnedRepo.remoteUrl;
      if (!remoteUrl) {
        throw new errors.InputError("No remote URL returned from create repository for Azure");
      }
      const repoContentsUrl = remoteUrl;
      await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, ctx.input.sourcePath),
        remoteUrl,
        auth: {
          username: "notempty",
          password: integrationConfig.config.token
        },
        logger: ctx.logger
      });
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
    }
  });
}

function createPublishGitlabAction(options) {
  const {integrations} = options;
  return createTemplateAction({
    id: "publish:gitlab",
    description: "Initializes a git repository of the content in the workspace, and publishes it to GitLab.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          repoVisibility: {
            title: "Repository Visibility",
            type: "string",
            enum: ["private", "public", "internal"]
          },
          sourcePath: {
            title: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
            type: "string"
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      const {repoUrl, repoVisibility = "private"} = ctx.input;
      const {owner, repo, host} = parseRepoUrl(repoUrl);
      const integrationConfig = integrations.gitlab.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(`No matching integration configuration for host ${host}, please check your integrations config`);
      }
      if (!integrationConfig.config.token) {
        throw new errors.InputError(`No token available for host ${host}`);
      }
      const client = new node.Gitlab({
        host: integrationConfig.config.baseUrl,
        token: integrationConfig.config.token
      });
      let {id: targetNamespace} = await client.Namespaces.show(owner);
      if (!targetNamespace) {
        const {id} = await client.Users.current();
        targetNamespace = id;
      }
      const {http_url_to_repo} = await client.Projects.create({
        namespace_id: targetNamespace,
        name: repo,
        visibility: repoVisibility
      });
      const remoteUrl = http_url_to_repo.replace(/\.git$/, "");
      const repoContentsUrl = `${remoteUrl}/-/blob/master`;
      await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, ctx.input.sourcePath),
        remoteUrl: http_url_to_repo,
        auth: {
          username: "oauth2",
          password: integrationConfig.config.token
        },
        logger: ctx.logger
      });
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
    }
  });
}

const createBitbucketCloudRepository = async (opts) => {
  const {owner, repo, description, repoVisibility, authorization} = opts;
  const options = {
    method: "POST",
    body: JSON.stringify({
      scm: "git",
      description,
      is_private: repoVisibility === "private"
    }),
    headers: {
      Authorization: authorization,
      "Content-Type": "application/json"
    }
  };
  let response;
  try {
    response = await fetch__default['default'](`https://api.bitbucket.org/2.0/repositories/${owner}/${repo}`, options);
  } catch (e) {
    throw new Error(`Unable to create repository, ${e}`);
  }
  if (response.status !== 200) {
    throw new Error(`Unable to create repository, ${response.status} ${response.statusText}, ${await response.text()}`);
  }
  const r = await response.json();
  let remoteUrl = "";
  for (const link of r.links.clone) {
    if (link.name === "https") {
      remoteUrl = link.href;
    }
  }
  const repoContentsUrl = `${r.links.html.href}/src/master`;
  return {remoteUrl, repoContentsUrl};
};
const createBitbucketServerRepository = async (opts) => {
  const {
    host,
    owner,
    repo,
    description,
    authorization,
    repoVisibility
  } = opts;
  let response;
  const options = {
    method: "POST",
    body: JSON.stringify({
      name: repo,
      description,
      is_private: repoVisibility === "private"
    }),
    headers: {
      Authorization: authorization,
      "Content-Type": "application/json"
    }
  };
  try {
    response = await fetch__default['default'](`https://${host}/rest/api/1.0/projects/${owner}/repos`, options);
  } catch (e) {
    throw new Error(`Unable to create repository, ${e}`);
  }
  if (response.status !== 201) {
    throw new Error(`Unable to create repository, ${response.status} ${response.statusText}, ${await response.text()}`);
  }
  const r = await response.json();
  let remoteUrl = "";
  for (const link of r.links.clone) {
    if (link.name === "http") {
      remoteUrl = link.href;
    }
  }
  const repoContentsUrl = `${r.links.self[0].href}`;
  return {remoteUrl, repoContentsUrl};
};
const getAuthorizationHeader = (config) => {
  if (config.username && config.appPassword) {
    const buffer = Buffer.from(`${config.username}:${config.appPassword}`, "utf8");
    return `Basic ${buffer.toString("base64")}`;
  }
  if (config.token) {
    return `Bearer ${config.token}`;
  }
  throw new Error(`Authorization has not been provided for Bitbucket. Please add either username + appPassword or token to the Integrations config`);
};
function createPublishBitbucketAction(options) {
  const {integrations} = options;
  return createTemplateAction({
    id: "publish:bitbucket",
    description: "Initializes a git repository of the content in the workspace, and publishes it to Bitbucket.",
    schema: {
      input: {
        type: "object",
        required: ["repoUrl"],
        properties: {
          repoUrl: {
            title: "Repository Location",
            type: "string"
          },
          description: {
            title: "Repository Description",
            type: "string"
          },
          repoVisibility: {
            title: "Repository Visibility",
            type: "string",
            enum: ["private", "public"]
          },
          sourcePath: {
            title: "Path within the workspace that will be used as the repository root. If omitted, the entire workspace will be published as the repository.",
            type: "string"
          }
        }
      },
      output: {
        type: "object",
        properties: {
          remoteUrl: {
            title: "A URL to the repository with the provider",
            type: "string"
          },
          repoContentsUrl: {
            title: "A URL to the root of the repository",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      var _a;
      const {repoUrl, description, repoVisibility = "private"} = ctx.input;
      const {owner, repo, host} = parseRepoUrl(repoUrl);
      const integrationConfig = integrations.bitbucket.byHost(host);
      if (!integrationConfig) {
        throw new errors.InputError(`No matching integration configuration for host ${host}, please check your integrations config`);
      }
      const authorization = getAuthorizationHeader(integrationConfig.config);
      const createMethod = host === "bitbucket.org" ? createBitbucketCloudRepository : createBitbucketServerRepository;
      const {remoteUrl, repoContentsUrl} = await createMethod({
        authorization,
        host,
        owner,
        repo,
        repoVisibility,
        description
      });
      await initRepoAndPush({
        dir: getRepoSourceDirectory(ctx.workspacePath, ctx.input.sourcePath),
        remoteUrl,
        auth: {
          username: integrationConfig.config.username ? integrationConfig.config.username : "x-token-auth",
          password: integrationConfig.config.appPassword ? integrationConfig.config.appPassword : (_a = integrationConfig.config.token) != null ? _a : ""
        },
        logger: ctx.logger
      });
      ctx.output("remoteUrl", remoteUrl);
      ctx.output("repoContentsUrl", repoContentsUrl);
    }
  });
}

function createPublishFileAction() {
  return createTemplateAction({
    id: "publish:file",
    description: "Writes contents of the workspace to a local directory",
    schema: {
      input: {
        type: "object",
        required: ["path"],
        properties: {
          path: {
            title: "Path to a directory where the output will be written",
            type: "string"
          }
        }
      }
    },
    async handler(ctx) {
      const {path: path$1} = ctx.input;
      const exists = await fs__default['default'].pathExists(path$1);
      if (exists) {
        throw new errors.InputError("Output path already exists");
      }
      await fs__default['default'].ensureDir(path.dirname(path$1));
      await fs__default['default'].copy(ctx.workspacePath, path$1);
    }
  });
}

const createBuiltinActions = (options) => {
  const {reader, integrations, templaters, catalogClient} = options;
  return [
    createFetchPlainAction({
      reader,
      integrations
    }),
    createFetchCookiecutterAction({
      reader,
      integrations,
      templaters
    }),
    createPublishGithubAction({
      integrations
    }),
    createPublishGithubPullRequestAction({
      integrations
    }),
    createPublishGitlabAction({
      integrations
    }),
    createPublishBitbucketAction({
      integrations
    }),
    createPublishAzureAction({
      integrations
    }),
    createCatalogRegisterAction({catalogClient, integrations})
  ];
};

class TemplateActionRegistry {
  constructor() {
    this.actions = new Map();
  }
  register(action) {
    if (this.actions.has(action.id)) {
      throw new errors.ConflictError(`Template action with ID '${action.id}' has already been registered`);
    }
    this.actions.set(action.id, action);
  }
  get(actionId) {
    const action = this.actions.get(actionId);
    if (!action) {
      throw new errors.NotFoundError(`Template action with ID '${actionId}' is not registered.`);
    }
    return action;
  }
  list() {
    return [...this.actions.values()];
  }
}

class AzurePreparer {
  constructor(config) {
    this.config = config;
  }
  static fromConfig(config) {
    return new AzurePreparer({token: config.token});
  }
  async prepare({url, workspacePath, logger}) {
    var _a;
    const parsedGitUrl = parseGitUrl__default['default'](url);
    const checkoutPath = path__default['default'].join(workspacePath, "checkout");
    const targetPath = path__default['default'].join(workspacePath, "template");
    const fullPathToTemplate = path__default['default'].resolve(checkoutPath, (_a = parsedGitUrl.filepath) != null ? _a : "");
    const git = this.config.token ? backendCommon.Git.fromAuth({
      password: this.config.token,
      username: "notempty",
      logger
    }) : backendCommon.Git.fromAuth({logger});
    await git.clone({
      url: parsedGitUrl.toString("https"),
      ref: parsedGitUrl.ref,
      dir: checkoutPath
    });
    await fs__default['default'].move(fullPathToTemplate, targetPath);
    try {
      await fs__default['default'].rmdir(path__default['default'].join(targetPath, ".git"));
    } catch {
    }
  }
}

class BitbucketPreparer {
  constructor(config) {
    this.config = config;
  }
  static fromConfig(config) {
    return new BitbucketPreparer({
      username: config.username,
      token: config.token,
      appPassword: config.appPassword
    });
  }
  async prepare({url, workspacePath, logger}) {
    var _a;
    const parsedGitUrl = parseGitUrl__default['default'](url);
    const checkoutPath = path__default['default'].join(workspacePath, "checkout");
    const targetPath = path__default['default'].join(workspacePath, "template");
    const fullPathToTemplate = path__default['default'].resolve(checkoutPath, (_a = parsedGitUrl.filepath) != null ? _a : "");
    const git = backendCommon.Git.fromAuth({logger, ...this.getAuth()});
    await git.clone({
      url: parsedGitUrl.toString("https"),
      dir: checkoutPath,
      ref: parsedGitUrl.ref
    });
    await fs__default['default'].move(fullPathToTemplate, targetPath);
    try {
      await fs__default['default'].rmdir(path__default['default'].join(targetPath, ".git"));
    } catch {
    }
  }
  getAuth() {
    const {username, token, appPassword} = this.config;
    if (username && appPassword) {
      return {username, password: appPassword};
    }
    if (token) {
      return {
        username: "x-token-auth",
        password: token || appPassword
      };
    }
    return void 0;
  }
}

class FilePreparer {
  async prepare({url: url$1, workspacePath}) {
    if (!url$1.startsWith("file://")) {
      throw new errors.InputError(`Wrong location protocol, should be 'file', ${url$1}`);
    }
    const templatePath = url.fileURLToPath(url$1);
    const targetDir = path__default['default'].join(workspacePath, "template");
    await fs__default['default'].ensureDir(targetDir);
    await fs__default['default'].copy(templatePath, targetDir, {
      recursive: true
    });
  }
}

class GithubPreparer {
  constructor(config) {
    this.config = config;
  }
  static fromConfig(config) {
    const credentialsProvider = integration.GithubCredentialsProvider.create(config);
    return new GithubPreparer({credentialsProvider});
  }
  async prepare({url, workspacePath, logger}) {
    var _a;
    const parsedGitUrl = parseGitUrl__default['default'](url);
    const checkoutPath = path__default['default'].join(workspacePath, "checkout");
    const targetPath = path__default['default'].join(workspacePath, "template");
    const fullPathToTemplate = path__default['default'].resolve(checkoutPath, (_a = parsedGitUrl.filepath) != null ? _a : "");
    const {token} = await this.config.credentialsProvider.getCredentials({
      url
    });
    const git = token ? backendCommon.Git.fromAuth({
      username: "x-access-token",
      password: token,
      logger
    }) : backendCommon.Git.fromAuth({logger});
    await git.clone({
      url: parsedGitUrl.toString("https"),
      dir: checkoutPath,
      ref: parsedGitUrl.ref
    });
    await fs__default['default'].move(fullPathToTemplate, targetPath);
    try {
      await fs__default['default'].rmdir(path__default['default'].join(targetPath, ".git"));
    } catch {
    }
  }
}

class GitlabPreparer {
  constructor(config) {
    this.config = config;
  }
  static fromConfig(config) {
    return new GitlabPreparer({token: config.token});
  }
  async prepare({url, workspacePath, logger}) {
    var _a;
    const parsedGitUrl = parseGitUrl__default['default'](url);
    const checkoutPath = path__default['default'].join(workspacePath, "checkout");
    const targetPath = path__default['default'].join(workspacePath, "template");
    const fullPathToTemplate = path__default['default'].resolve(checkoutPath, (_a = parsedGitUrl.filepath) != null ? _a : "");
    parsedGitUrl.git_suffix = true;
    const git = this.config.token ? backendCommon.Git.fromAuth({
      password: this.config.token,
      username: "oauth2",
      logger
    }) : backendCommon.Git.fromAuth({logger});
    await git.clone({
      url: parsedGitUrl.toString("https"),
      dir: checkoutPath,
      ref: parsedGitUrl.ref
    });
    await fs__default['default'].move(fullPathToTemplate, targetPath);
    try {
      await fs__default['default'].rmdir(path__default['default'].join(targetPath, ".git"));
    } catch {
    }
  }
}

class Preparers {
  constructor() {
    this.preparerMap = new Map();
  }
  register(host, preparer) {
    this.preparerMap.set(host, preparer);
  }
  get(url) {
    const preparer = this.preparerMap.get(new URL(url).host);
    if (!preparer) {
      throw new Error(`Unable to find a preparer for URL: ${url}. Please make sure to register this host under an integration in app-config`);
    }
    return preparer;
  }
  static async fromConfig(config, _) {
    const preparers = new Preparers();
    const scm = integration.ScmIntegrations.fromConfig(config);
    for (const integration of scm.azure.list()) {
      preparers.register(integration.config.host, AzurePreparer.fromConfig(integration.config));
    }
    for (const integration of scm.github.list()) {
      preparers.register(integration.config.host, GithubPreparer.fromConfig(integration.config));
    }
    for (const integration of scm.gitlab.list()) {
      preparers.register(integration.config.host, GitlabPreparer.fromConfig(integration.config));
    }
    for (const integration of scm.bitbucket.list()) {
      preparers.register(integration.config.host, BitbucketPreparer.fromConfig(integration.config));
    }
    return preparers;
  }
}

function createLegacyActions(options) {
  const {preparers, templaters, publishers} = options;
  return [
    createTemplateAction({
      id: "legacy:prepare",
      async handler(ctx) {
        ctx.logger.info("Preparing the skeleton");
        const {protocol, url} = ctx.input;
        const preparer = protocol === "file" ? new FilePreparer() : preparers.get(url);
        await preparer.prepare({
          url,
          logger: ctx.logger,
          workspacePath: ctx.workspacePath
        });
      }
    }),
    createTemplateAction({
      id: "legacy:template",
      async handler(ctx) {
        ctx.logger.info("Running the templater");
        const templater = templaters.get(ctx.input.templater);
        await templater.run({
          workspacePath: ctx.workspacePath,
          logStream: ctx.logStream,
          values: ctx.input.values
        });
      }
    }),
    createTemplateAction({
      id: "legacy:publish",
      async handler(ctx) {
        const {values} = ctx.input;
        if (typeof values !== "object" || values === null || Array.isArray(values)) {
          throw new Error(`Invalid values passed to publish, got ${typeof values}`);
        }
        const storePath = values.storePath;
        if (typeof storePath !== "string") {
          throw new Error(`Invalid store path passed to publish, got ${typeof storePath}`);
        }
        const owner = values.owner;
        if (typeof owner !== "string") {
          throw new Error(`Invalid owner passed to publish, got ${typeof owner}`);
        }
        const publisher = publishers.get(storePath);
        ctx.logger.info("Will now store the template");
        const {remoteUrl, catalogInfoUrl} = await publisher.publish({
          values: {
            ...values,
            owner,
            storePath
          },
          workspacePath: ctx.workspacePath,
          logger: ctx.logger
        });
        ctx.output("remoteUrl", remoteUrl);
        if (catalogInfoUrl) {
          ctx.output("catalogInfoUrl", catalogInfoUrl);
        }
      }
    })
  ];
}

class AzurePublisher {
  constructor(config) {
    this.config = config;
  }
  static async fromConfig(config) {
    if (!config.token) {
      return void 0;
    }
    return new AzurePublisher({token: config.token});
  }
  async publish({
    values,
    workspacePath,
    logger
  }) {
    const {owner, name, organization, resource} = parseGitUrl__default['default'](values.storePath);
    const authHandler = azureDevopsNodeApi.getPersonalAccessTokenHandler(this.config.token);
    const webApi = new azureDevopsNodeApi.WebApi(`https://${resource}/${organization}`, authHandler);
    const client = await webApi.getGitApi();
    const remoteUrl = await this.createRemote({
      project: owner,
      name,
      client
    });
    const catalogInfoUrl = `${remoteUrl}?path=%2Fcatalog-info.yaml`;
    await initRepoAndPush({
      dir: path__default['default'].join(workspacePath, "result"),
      remoteUrl,
      auth: {
        username: "notempty",
        password: this.config.token
      },
      logger
    });
    return {remoteUrl, catalogInfoUrl};
  }
  async createRemote(opts) {
    const {name, project, client} = opts;
    const createOptions = {name};
    const repo = await client.createRepository(createOptions, project);
    return repo.remoteUrl || "";
  }
}

class BitbucketPublisher {
  constructor(config) {
    this.config = config;
  }
  static async fromConfig(config, {repoVisibility}) {
    if (config.host !== "bitbucket.org" && !config.username)
      throw new Error("Bitbucket server requires the username to be set in your config");
    return new BitbucketPublisher({
      host: config.host,
      token: config.token,
      appPassword: config.appPassword,
      username: config.username,
      apiBaseUrl: config.apiBaseUrl,
      repoVisibility
    });
  }
  async publish({
    values,
    workspacePath,
    logger
  }) {
    var _a;
    const {owner: project, name} = parseGitUrl__default['default'](values.storePath);
    const description = values.description;
    const result = await this.createRemote({
      project,
      name,
      description
    });
    await initRepoAndPush({
      dir: path__default['default'].join(workspacePath, "result"),
      remoteUrl: result.remoteUrl,
      auth: {
        username: this.config.username ? this.config.username : "x-token-auth",
        password: this.config.appPassword ? this.config.appPassword : (_a = this.config.token) != null ? _a : ""
      },
      logger
    });
    return result;
  }
  async createRemote(opts) {
    if (this.config.host === "bitbucket.org") {
      return this.createBitbucketCloudRepository(opts);
    }
    return this.createBitbucketServerRepository(opts);
  }
  async createBitbucketCloudRepository(opts) {
    const {project, name, description} = opts;
    let response;
    const options = {
      method: "POST",
      body: JSON.stringify({
        scm: "git",
        description,
        is_private: this.config.repoVisibility === "private"
      }),
      headers: {
        Authorization: this.getAuthorizationHeader(),
        "Content-Type": "application/json"
      }
    };
    try {
      response = await fetch__default['default'](`https://api.bitbucket.org/2.0/repositories/${project}/${name}`, options);
    } catch (e) {
      throw new Error(`Unable to create repository, ${e}`);
    }
    if (response.status === 200) {
      const r = await response.json();
      let remoteUrl = "";
      for (const link of r.links.clone) {
        if (link.name === "https") {
          remoteUrl = link.href;
        }
      }
      const catalogInfoUrl = `${r.links.html.href}/src/master/catalog-info.yaml`;
      return {remoteUrl, catalogInfoUrl};
    }
    throw new Error(`Not a valid response code ${await response.text()}`);
  }
  getAuthorizationHeader() {
    if (this.config.username && this.config.appPassword) {
      const buffer = Buffer.from(`${this.config.username}:${this.config.appPassword}`, "utf8");
      return `Basic ${buffer.toString("base64")}`;
    }
    if (this.config.token) {
      return `Bearer ${this.config.token}`;
    }
    throw new Error(`Authorization has not been provided for Bitbucket. Please add either username + appPassword or token to the Integrations config`);
  }
  async createBitbucketServerRepository(opts) {
    const {project, name, description} = opts;
    let response;
    const options = {
      method: "POST",
      body: JSON.stringify({
        name,
        description,
        is_private: this.config.repoVisibility === "private"
      }),
      headers: {
        Authorization: this.getAuthorizationHeader(),
        "Content-Type": "application/json"
      }
    };
    try {
      const baseUrl = this.config.apiBaseUrl ? this.config.apiBaseUrl : `https://${this.config.host}/rest/api/1.0`;
      response = await fetch__default['default'](`${baseUrl}/projects/${project}/repos`, options);
    } catch (e) {
      throw new Error(`Unable to create repository, ${e}`);
    }
    if (response.status === 201) {
      const r = await response.json();
      let remoteUrl = "";
      for (const link of r.links.clone) {
        if (link.name === "http") {
          remoteUrl = link.href;
        }
      }
      const catalogInfoUrl = `${r.links.self[0].href}/catalog-info.yaml`;
      return {remoteUrl, catalogInfoUrl};
    }
    throw new Error(`Not a valid response code ${await response.text()}`);
  }
}

class GithubPublisher {
  constructor(config) {
    this.config = config;
  }
  static async fromConfig(config, {repoVisibility}) {
    if (!config.token && !config.apps) {
      return void 0;
    }
    const credentialsProvider = integration.GithubCredentialsProvider.create(config);
    return new GithubPublisher({
      credentialsProvider,
      repoVisibility,
      apiBaseUrl: config.apiBaseUrl
    });
  }
  async publish({
    values,
    workspacePath,
    logger
  }) {
    const {owner, name} = parseGitUrl__default['default'](values.storePath);
    const {token} = await this.config.credentialsProvider.getCredentials({
      url: values.storePath
    });
    if (!token) {
      throw new Error(`No token could be acquired for URL: ${values.storePath}`);
    }
    const client = new rest.Octokit({
      auth: token,
      baseUrl: this.config.apiBaseUrl,
      previews: ["nebula-preview"]
    });
    const description = values.description;
    const access = values.access;
    const remoteUrl = await this.createRemote({
      client,
      description,
      access,
      name,
      owner
    });
    await initRepoAndPush({
      dir: path__default['default'].join(workspacePath, "result"),
      remoteUrl,
      auth: {
        username: "x-access-token",
        password: token
      },
      logger
    });
    const catalogInfoUrl = remoteUrl.replace(/\.git$/, "/blob/master/catalog-info.yaml");
    try {
      await enableBranchProtectionOnDefaultRepoBranch({
        owner,
        client,
        repoName: name,
        logger
      });
    } catch (e) {
      throw new Error(`Failed to add branch protection to '${name}', ${e}`);
    }
    return {remoteUrl, catalogInfoUrl};
  }
  async createRemote(opts) {
    const {client, access, description, owner, name} = opts;
    const user = await client.users.getByUsername({
      username: owner
    });
    const repoCreationPromise = user.data.type === "Organization" ? client.repos.createInOrg({
      name,
      org: owner,
      private: this.config.repoVisibility !== "public",
      visibility: this.config.repoVisibility,
      description
    }) : client.repos.createForAuthenticatedUser({
      name,
      private: this.config.repoVisibility === "private",
      description
    });
    const {data: newRepo} = await repoCreationPromise;
    try {
      if (access == null ? void 0 : access.startsWith(`${owner}/`)) {
        const [, team] = access.split("/");
        await client.teams.addOrUpdateRepoPermissionsInOrg({
          org: owner,
          team_slug: team,
          owner,
          repo: name,
          permission: "admin"
        });
      } else if (access && access !== owner) {
        await client.repos.addCollaborator({
          owner,
          repo: name,
          username: access,
          permission: "admin"
        });
      }
    } catch (e) {
      throw new Error(`Failed to add access to '${access}'. Status ${e.status} ${e.message}`);
    }
    return newRepo.clone_url;
  }
}

class GitlabPublisher {
  constructor(config) {
    this.config = config;
  }
  static async fromConfig(config, {repoVisibility}) {
    if (!config.token) {
      return void 0;
    }
    const client = new node.Gitlab({host: config.baseUrl, token: config.token});
    return new GitlabPublisher({
      token: config.token,
      client,
      repoVisibility
    });
  }
  async publish({
    values,
    workspacePath,
    logger
  }) {
    const {owner, name} = parseGitUrl__default['default'](values.storePath);
    const remoteUrl = await this.createRemote({
      owner,
      name
    });
    await initRepoAndPush({
      dir: path__default['default'].join(workspacePath, "result"),
      remoteUrl,
      auth: {
        username: "oauth2",
        password: this.config.token
      },
      logger
    });
    const catalogInfoUrl = remoteUrl.replace(/\.git$/, "/-/blob/master/catalog-info.yaml");
    return {remoteUrl, catalogInfoUrl};
  }
  async createRemote(opts) {
    const {owner, name} = opts;
    let targetNamespace = (await this.config.client.Namespaces.show(owner)).id;
    if (!targetNamespace) {
      targetNamespace = (await this.config.client.Users.current()).id;
    }
    const project = await this.config.client.Projects.create({
      namespace_id: targetNamespace,
      name,
      visibility: this.config.repoVisibility
    });
    return project == null ? void 0 : project.http_url_to_repo;
  }
}

class Publishers {
  constructor() {
    this.publisherMap = new Map();
  }
  register(host, preparer) {
    this.publisherMap.set(host, preparer);
  }
  get(url) {
    const preparer = this.publisherMap.get(new URL(url).host);
    if (!preparer) {
      throw new Error(`Unable to find a publisher for URL: ${url}. Please make sure to register this host under an integration in app-config`);
    }
    return preparer;
  }
  static async fromConfig(config, _options) {
    var _a, _b, _c;
    const publishers = new Publishers();
    const scm = integration.ScmIntegrations.fromConfig(config);
    for (const integration of scm.azure.list()) {
      const publisher = await AzurePublisher.fromConfig(integration.config);
      if (publisher) {
        publishers.register(integration.config.host, publisher);
      }
    }
    for (const integration of scm.github.list()) {
      const repoVisibility = (_a = config.getOptionalString("scaffolder.github.visibility")) != null ? _a : "public";
      const publisher = await GithubPublisher.fromConfig(integration.config, {
        repoVisibility
      });
      if (publisher) {
        publishers.register(integration.config.host, publisher);
      }
    }
    for (const integration of scm.gitlab.list()) {
      const repoVisibility = (_b = config.getOptionalString("scaffolder.gitlab.visibility")) != null ? _b : "public";
      const publisher = await GitlabPublisher.fromConfig(integration.config, {
        repoVisibility
      });
      if (publisher) {
        publishers.register(integration.config.host, publisher);
      }
    }
    for (const integration of scm.bitbucket.list()) {
      const repoVisibility = (_c = config.getOptionalString("scaffolder.bitbucket.visibility")) != null ? _c : "public";
      const publisher = await BitbucketPublisher.fromConfig(integration.config, {
        repoVisibility
      });
      if (publisher) {
        publishers.register(integration.config.host, publisher);
      }
    }
    return publishers;
  }
}

const getTemplaterKey = (entity) => {
  const {templater} = entity.spec;
  if (!templater) {
    throw new errors.InputError("Template does not have a required templating key");
  }
  return templater;
};
const runCommand = async ({
  command,
  args,
  logStream = new stream.PassThrough()
}) => {
  await new Promise((resolve, reject) => {
    const process = child_process.spawn(command, args);
    process.stdout.on("data", (stream) => {
      logStream.write(stream);
    });
    process.stderr.on("data", (stream) => {
      logStream.write(stream);
    });
    process.on("error", (error) => {
      return reject(error);
    });
    process.on("close", (code) => {
      if (code !== 0) {
        return reject(`Command ${command} failed, exit code: ${code}`);
      }
      return resolve();
    });
  });
};

const commandExists = require("command-exists-promise");
class CookieCutter {
  constructor({containerRunner}) {
    this.containerRunner = containerRunner;
  }
  async fetchTemplateCookieCutter(directory) {
    try {
      return await fs__default['default'].readJSON(path__default['default'].join(directory, "cookiecutter.json"));
    } catch (ex) {
      if (ex.code !== "ENOENT") {
        throw ex;
      }
      return {};
    }
  }
  async run({
    workspacePath,
    values,
    logStream
  }) {
    const templateDir = path__default['default'].join(workspacePath, "template");
    const intermediateDir = path__default['default'].join(workspacePath, "intermediate");
    await fs__default['default'].ensureDir(intermediateDir);
    const resultDir = path__default['default'].join(workspacePath, "result");
    const cookieCutterJson = await this.fetchTemplateCookieCutter(templateDir);
    const {imageName, ...valuesForCookieCutterJson} = values;
    const cookieInfo = {
      ...cookieCutterJson,
      ...valuesForCookieCutterJson
    };
    await fs__default['default'].writeJSON(path__default['default'].join(templateDir, "cookiecutter.json"), cookieInfo);
    const mountDirs = {
      [templateDir]: "/input",
      [intermediateDir]: "/output"
    };
    const cookieCutterInstalled = await commandExists("cookiecutter");
    if (cookieCutterInstalled) {
      await runCommand({
        command: "cookiecutter",
        args: ["--no-input", "-o", intermediateDir, templateDir, "--verbose"],
        logStream
      });
    } else {
      await this.containerRunner.runContainer({
        imageName: imageName || "spotify/backstage-cookiecutter",
        command: "cookiecutter",
        args: ["--no-input", "-o", "/output", "/input", "--verbose"],
        mountDirs,
        workingDir: "/input",
        envVars: {HOME: "/tmp"},
        logStream
      });
    }
    const [generated] = await fs__default['default'].readdir(intermediateDir);
    if (generated === void 0) {
      throw new Error("No data generated by cookiecutter");
    }
    await fs__default['default'].move(path__default['default'].join(intermediateDir, generated), resultDir);
  }
}

class Templaters {
  constructor() {
    this.templaterMap = new Map();
  }
  register(templaterKey, templater) {
    this.templaterMap.set(templaterKey, templater);
  }
  get(templaterId) {
    const templater = this.templaterMap.get(templaterId);
    if (!templater) {
      throw new Error(`No templater registered for template: "${templaterId}"`);
    }
    return templater;
  }
}

const GITHUB_ACTIONS_ANNOTATION = "github.com/project-slug";
class CreateReactAppTemplater {
  constructor({containerRunner}) {
    this.containerRunner = containerRunner;
  }
  async run({
    workspacePath,
    values,
    logStream
  }) {
    var _a, _b, _c, _d;
    const {
      component_id: componentName,
      use_typescript: withTypescript,
      use_github_actions: withGithubActions,
      description,
      owner
    } = values;
    const intermediateDir = path__default['default'].join(workspacePath, "template");
    await fs__default['default'].ensureDir(intermediateDir);
    const mountDirs = {
      [intermediateDir]: "/template",
      [intermediateDir]: "/result"
    };
    await this.containerRunner.runContainer({
      imageName: "node:lts-alpine",
      command: ["npx"],
      args: [
        "create-react-app",
        componentName,
        withTypescript ? " --template typescript" : ""
      ],
      mountDirs,
      workingDir: "/result",
      logStream,
      envVars: {HOME: "/tmp"}
    });
    const [generated] = await fs__default['default'].readdir(intermediateDir);
    if (generated === void 0) {
      throw new Error("No data generated by cookiecutter");
    }
    const resultDir = path__default['default'].join(workspacePath, "result");
    await fs__default['default'].move(path__default['default'].join(intermediateDir, generated), resultDir);
    const extraAnnotations = {};
    if (withGithubActions) {
      await fs__default['default'].mkdir(`${resultDir}/.github`);
      await fs__default['default'].mkdir(`${resultDir}/.github/workflows`);
      const githubActionsYaml = `
name: CRA Build

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        node-version: [12.x]

    steps:
    - name: checkout code
      uses: actions/checkout@v1
    - name: get yarn cache
      id: yarn-cache
      run: echo "::set-output name=dir::$(yarn cache dir)"
    - uses: actions/cache@v2
      with:
        path: \${{ steps.yarn-cache.outputs.dir }}
        key: \${{ runner.os }}-yarn-\${{ hashFiles('**/yarn.lock') }}
        restore-keys: |
          \${{ runner.os }}-yarn-
    - name: use node.js \${{ matrix.node-version }}
      uses: actions/setup-node@v1
      with:
        node-version: \${{ matrix.node-version }}
    - name: yarn install, build, and test
      working-directory: .
      run: |
        yarn install
        yarn build
        yarn test
      env:
        CI: true
      `;
      await fs__default['default'].writeFile(`${resultDir}/.github/workflows/main.yml`, githubActionsYaml);
      extraAnnotations[GITHUB_ACTIONS_ANNOTATION] = `${(_b = (_a = values == null ? void 0 : values.destination) == null ? void 0 : _a.git) == null ? void 0 : _b.owner}/${(_d = (_c = values == null ? void 0 : values.destination) == null ? void 0 : _c.git) == null ? void 0 : _d.name}`;
    }
    const componentInfo = {
      apiVersion: "backstage.io/v1alpha1",
      kind: "Component",
      metadata: {
        name: componentName,
        description,
        annotations: {
          ...extraAnnotations
        }
      },
      spec: {
        type: "website",
        lifecycle: "experimental",
        owner
      }
    };
    await fs__default['default'].writeFile(`${resultDir}/catalog-info.yaml`, yaml.stringify(componentInfo));
  }
}

const parseLocationAnnotation = (entity) => {
  var _a;
  const annotation = (_a = entity.metadata.annotations) == null ? void 0 : _a[catalogModel.LOCATION_ANNOTATION];
  if (!annotation) {
    throw new errors.InputError(`No location annotation provided in entity: ${entity.metadata.name}`);
  }
  const {type, target} = catalogModel.parseLocationReference(annotation);
  return {
    protocol: type,
    location: target
  };
};
function joinGitUrlPath(repoUrl, path$1) {
  const parsed = new URL(repoUrl);
  if (parsed.hostname.endsWith("azure.com")) {
    const templatePath = path.posix.normalize(path.posix.join(path.posix.dirname(parsed.searchParams.get("path") || "/"), path$1 || "."));
    parsed.searchParams.set("path", templatePath);
    return parsed.toString();
  }
  return new URL(path$1 || ".", repoUrl).toString().replace(/\/$/, "");
}

const makeLogStream = (meta) => {
  const log = [];
  const stream$1 = new stream.PassThrough();
  stream$1.on("data", (chunk) => {
    const textValue = chunk.toString().trim();
    if ((textValue == null ? void 0 : textValue.length) > 1)
      log.push(textValue);
  });
  const logger = winston.createLogger({
    level: process.env.LOG_LEVEL || "info",
    format: winston.format.combine(winston.format.colorize(), winston.format.timestamp(), winston.format.simple()),
    defaultMeta: meta
  });
  logger.add(new winston.transports.Stream({stream: stream$1}));
  return {
    log,
    stream: stream$1,
    logger
  };
};

class JobProcessor {
  static async fromConfig({
    config,
    logger
  }) {
    let workingDirectory;
    if (config.has("backend.workingDirectory")) {
      workingDirectory = config.getString("backend.workingDirectory");
      try {
        await fs__default['default'].promises.access(workingDirectory, fs__default['default'].constants.F_OK | fs__default['default'].constants.W_OK);
        logger.info(`using working directory: ${workingDirectory}`);
      } catch (err) {
        logger.error(`working directory ${workingDirectory} ${err.code === "ENOENT" ? "does not exist" : "is not writable"}`);
        throw err;
      }
    } else {
      workingDirectory = os__default['default'].tmpdir();
    }
    return new JobProcessor(workingDirectory);
  }
  constructor(workingDirectory) {
    this.workingDirectory = workingDirectory;
    this.jobs = new Map();
  }
  create({
    entity,
    values,
    stages
  }) {
    const id = uuid.v4();
    const {logger, stream} = makeLogStream({id});
    const context = {
      entity,
      values,
      logger,
      logStream: stream,
      workspacePath: path__default['default'].join(this.workingDirectory, id)
    };
    const job = {
      id,
      context,
      stages: stages.map((stage) => ({
        handler: stage.handler,
        log: [],
        name: stage.name,
        status: "PENDING"
      })),
      status: "PENDING"
    };
    this.jobs.set(job.id, job);
    return job;
  }
  get(id) {
    return this.jobs.get(id);
  }
  async run(job) {
    if (job.status !== "PENDING") {
      throw new Error("Job is not in a 'PENDING' state");
    }
    await fs__default['default'].mkdir(job.context.workspacePath);
    job.status = "STARTED";
    try {
      for (const stage of job.stages) {
        const {logger, log, stream} = makeLogStream({
          id: job.id,
          stage: stage.name
        });
        stage.log = log;
        stage.startedAt = Date.now();
        try {
          stage.status = "STARTED";
          const handlerResponse = await stage.handler({
            ...job.context,
            logger,
            logStream: stream
          });
          if (handlerResponse) {
            job.context = {
              ...job.context,
              ...handlerResponse
            };
          }
          stage.status = "COMPLETED";
        } catch (error) {
          stage.status = "FAILED";
          logger.error(`Stage failed with error: ${error.message}`);
          logger.debug(error.stack);
          throw error;
        } finally {
          stage.endedAt = Date.now();
        }
      }
      job.status = "COMPLETED";
    } catch (error) {
      job.error = {name: error.name, message: error.message};
      job.status = "FAILED";
    } finally {
      await fs__default['default'].remove(job.context.workspacePath);
    }
  }
}

class CatalogEntityClient {
  constructor(catalogClient) {
    this.catalogClient = catalogClient;
  }
  async findTemplate(templateName, options) {
    const {items: templates} = await this.catalogClient.getEntities({
      filter: {
        kind: "template",
        "metadata.name": templateName
      }
    }, options);
    if (templates.length !== 1) {
      if (templates.length > 1) {
        throw new errors.ConflictError("Templates lookup resulted in multiple matches");
      } else {
        throw new errors.NotFoundError("Template not found");
      }
    }
    return templates[0];
  }
}

const migrationsDir = backendCommon.resolvePackagePath("@backstage/plugin-scaffolder-backend", "migrations");
class DatabaseTaskStore {
  constructor(db) {
    this.db = db;
  }
  static async create(knex) {
    await knex.migrate.latest({
      directory: migrationsDir
    });
    return new DatabaseTaskStore(knex);
  }
  async getTask(taskId) {
    const [result] = await this.db("tasks").where({id: taskId}).select();
    if (!result) {
      throw new errors.NotFoundError(`No task with id '${taskId}' found`);
    }
    try {
      const spec = JSON.parse(result.spec);
      const secrets = result.secrets ? JSON.parse(result.secrets) : void 0;
      return {
        id: result.id,
        spec,
        status: result.status,
        lastHeartbeatAt: result.last_heartbeat_at,
        createdAt: result.created_at,
        secrets
      };
    } catch (error) {
      throw new Error(`Failed to parse spec of task '${taskId}', ${error}`);
    }
  }
  async createTask(spec, secrets) {
    const taskId = uuid.v4();
    await this.db("tasks").insert({
      id: taskId,
      spec: JSON.stringify(spec),
      secrets: secrets ? JSON.stringify(secrets) : void 0,
      status: "open"
    });
    return {taskId};
  }
  async claimTask() {
    return this.db.transaction(async (tx) => {
      const [task] = await tx("tasks").where({
        status: "open"
      }).limit(1).select();
      if (!task) {
        return void 0;
      }
      const updateCount = await tx("tasks").where({id: task.id, status: "open"}).update({
        status: "processing",
        last_heartbeat_at: this.db.fn.now()
      });
      if (updateCount < 1) {
        return void 0;
      }
      try {
        const spec = JSON.parse(task.spec);
        const secrets = task.secrets ? JSON.parse(task.secrets) : void 0;
        return {
          id: task.id,
          spec,
          status: "processing",
          lastHeartbeatAt: task.last_heartbeat_at,
          createdAt: task.created_at,
          secrets
        };
      } catch (error) {
        throw new Error(`Failed to parse spec of task '${task.id}', ${error}`);
      }
    });
  }
  async heartbeatTask(taskId) {
    const updateCount = await this.db("tasks").where({id: taskId, status: "processing"}).update({
      last_heartbeat_at: this.db.fn.now()
    });
    if (updateCount === 0) {
      throw new errors.ConflictError(`No running task with taskId ${taskId} found`);
    }
  }
  async listStaleTasks({
    timeoutS
  }) {
    const rawRows = await this.db("tasks").where("status", "processing").andWhere("last_heartbeat_at", "<=", this.db.client.config.client === "sqlite3" ? this.db.raw(`datetime('now', ?)`, [`-${timeoutS} seconds`]) : this.db.raw(`dateadd('second', ?, ?)`, [
      `-${timeoutS}`,
      this.db.fn.now()
    ]));
    const tasks = rawRows.map((row) => ({
      taskId: row.id
    }));
    return {tasks};
  }
  async completeTask({
    taskId,
    status,
    eventBody
  }) {
    let oldStatus;
    if (status === "failed" || status === "completed") {
      oldStatus = "processing";
    } else {
      throw new Error(`Invalid status update of run '${taskId}' to status '${status}'`);
    }
    await this.db.transaction(async (tx) => {
      const [task] = await tx("tasks").where({
        id: taskId
      }).limit(1).select();
      if (!task) {
        throw new Error(`No task with taskId ${taskId} found`);
      }
      if (task.status !== oldStatus) {
        throw new errors.ConflictError(`Refusing to update status of run '${taskId}' to status '${status}' as it is currently '${task.status}', expected '${oldStatus}'`);
      }
      const updateCount = await tx("tasks").where({
        id: taskId,
        status: oldStatus
      }).update({
        status,
        secrets: null
      });
      if (updateCount !== 1) {
        throw new errors.ConflictError(`Failed to update status to '${status}' for taskId ${taskId}`);
      }
      await tx("task_events").insert({
        task_id: taskId,
        event_type: "completion",
        body: JSON.stringify(eventBody)
      });
    });
  }
  async emitLogEvent({taskId, body}) {
    const serliazedBody = JSON.stringify(body);
    await this.db("task_events").insert({
      task_id: taskId,
      event_type: "log",
      body: serliazedBody
    });
  }
  async listEvents({
    taskId,
    after
  }) {
    const rawEvents = await this.db("task_events").where({
      task_id: taskId
    }).andWhere((builder) => {
      if (typeof after === "number") {
        builder.where("id", ">", after).orWhere("event_type", "completion");
      }
    }).orderBy("id").select();
    const events = rawEvents.map((event) => {
      try {
        const body = JSON.parse(event.body);
        return {
          id: Number(event.id),
          taskId,
          body,
          type: event.event_type,
          createdAt: typeof event.created_at === "string" ? luxon.DateTime.fromSQL(event.created_at, {zone: "UTC"}).toISO() : event.created_at
        };
      } catch (error) {
        throw new Error(`Failed to parse event body from event taskId=${taskId} id=${event.id}, ${error}`);
      }
    });
    return {events};
  }
}

class TaskAgent {
  constructor(state, storage, logger) {
    this.state = state;
    this.storage = storage;
    this.logger = logger;
    this.isDone = false;
  }
  static create(state, storage, logger) {
    const agent = new TaskAgent(state, storage, logger);
    agent.startTimeout();
    return agent;
  }
  get spec() {
    return this.state.spec;
  }
  get secrets() {
    return this.state.secrets;
  }
  async getWorkspaceName() {
    return this.state.taskId;
  }
  get done() {
    return this.isDone;
  }
  async emitLog(message, metadata) {
    await this.storage.emitLogEvent({
      taskId: this.state.taskId,
      body: {message, ...metadata}
    });
  }
  async complete(result, metadata) {
    await this.storage.completeTask({
      taskId: this.state.taskId,
      status: result === "failed" ? "failed" : "completed",
      eventBody: {
        message: `Run completed with status: ${result}`,
        ...metadata
      }
    });
    this.isDone = true;
    if (this.heartbeatTimeoutId) {
      clearTimeout(this.heartbeatTimeoutId);
    }
  }
  startTimeout() {
    this.heartbeatTimeoutId = setTimeout(async () => {
      try {
        await this.storage.heartbeatTask(this.state.taskId);
        this.startTimeout();
      } catch (error) {
        this.isDone = true;
        this.logger.error(`Heartbeat for task ${this.state.taskId} failed`, error);
      }
    }, 1e3);
  }
}
function defer() {
  let resolve = () => {
  };
  const promise = new Promise((_resolve) => {
    resolve = _resolve;
  });
  return {promise, resolve};
}
class StorageTaskBroker {
  constructor(storage, logger) {
    this.storage = storage;
    this.logger = logger;
    this.deferredDispatch = defer();
  }
  async claim() {
    for (; ; ) {
      const pendingTask = await this.storage.claimTask();
      if (pendingTask) {
        return TaskAgent.create({
          taskId: pendingTask.id,
          spec: pendingTask.spec,
          secrets: pendingTask.secrets
        }, this.storage, this.logger);
      }
      await this.waitForDispatch();
    }
  }
  async dispatch(spec, secrets) {
    const taskRow = await this.storage.createTask(spec, secrets);
    this.signalDispatch();
    return {
      taskId: taskRow.taskId
    };
  }
  async get(taskId) {
    return this.storage.getTask(taskId);
  }
  observe(options, callback) {
    const {taskId} = options;
    let cancelled = false;
    const unsubscribe = () => {
      cancelled = true;
    };
    (async () => {
      let after = options.after;
      while (!cancelled) {
        const result = await this.storage.listEvents({taskId, after});
        const {events} = result;
        if (events.length) {
          after = events[events.length - 1].id;
          try {
            callback(void 0, result);
          } catch (error) {
            callback(error, {events: []});
          }
        }
        await new Promise((resolve) => setTimeout(resolve, 1e3));
      }
    })();
    return unsubscribe;
  }
  async vacuumTasks(timeoutS) {
    const {tasks} = await this.storage.listStaleTasks(timeoutS);
    await Promise.all(tasks.map(async (task) => {
      try {
        await this.storage.completeTask({
          taskId: task.taskId,
          status: "failed",
          eventBody: {
            message: "The task was cancelled because the task worker lost connection to the task broker"
          }
        });
      } catch (error) {
        this.logger.warn(`Failed to cancel task '${task.taskId}', ${error}`);
      }
    }));
  }
  waitForDispatch() {
    return this.deferredDispatch.promise;
  }
  signalDispatch() {
    this.deferredDispatch.resolve();
    this.deferredDispatch = defer();
  }
}

class TaskWorker {
  constructor(options) {
    this.options = options;
    this.handlebars = Handlebars.create();
    this.handlebars.registerHelper("parseRepoUrl", (repoUrl) => {
      return JSON.stringify(parseRepoUrl(repoUrl));
    });
    this.handlebars.registerHelper("json", (obj) => JSON.stringify(obj));
  }
  start() {
    (async () => {
      for (; ; ) {
        const task = await this.options.taskBroker.claim();
        await this.runOneTask(task);
      }
    })();
  }
  async runOneTask(task) {
    var _a, _b;
    let workspacePath = void 0;
    try {
      const {actionRegistry} = this.options;
      workspacePath = path__default['default'].join(this.options.workingDirectory, await task.getWorkspaceName());
      await fs__default['default'].ensureDir(workspacePath);
      await task.emitLog(`Starting up task with ${task.spec.steps.length} steps`);
      const templateCtx = {parameters: task.spec.values, steps: {}};
      for (const step of task.spec.steps) {
        const metadata = {stepId: step.id};
        try {
          const taskLogger = winston.createLogger({
            level: process.env.LOG_LEVEL || "info",
            format: winston.format.combine(winston.format.colorize(), winston.format.timestamp(), winston.format.simple()),
            defaultMeta: {}
          });
          const stream$1 = new stream.PassThrough();
          stream$1.on("data", async (data) => {
            const message = data.toString().trim();
            if ((message == null ? void 0 : message.length) > 1) {
              await task.emitLog(message, metadata);
            }
          });
          taskLogger.add(new winston.transports.Stream({stream: stream$1}));
          await task.emitLog(`Beginning step ${step.name}`, {
            ...metadata,
            status: "processing"
          });
          const action = actionRegistry.get(step.action);
          if (!action) {
            throw new Error(`Action '${step.action}' does not exist`);
          }
          const input = step.input && JSON.parse(JSON.stringify(step.input), (_key, value) => {
            if (typeof value === "string") {
              const templated = this.handlebars.compile(value, {
                noEscape: true,
                strict: true,
                data: false,
                preventIndent: true
              })(templateCtx);
              if (templated.startsWith("{") && templated.endsWith("}") || templated.startsWith("[") && templated.endsWith("]")) {
                try {
                  return JSON.parse(templated);
                } catch {
                  return templated;
                }
              }
              return templated;
            }
            return value;
          });
          if ((_a = action.schema) == null ? void 0 : _a.input) {
            const validateResult = jsonschema.validate(input, action.schema.input);
            if (!validateResult.valid) {
              const errors$1 = validateResult.errors.join(", ");
              throw new errors.InputError(`Invalid input passed to action ${action.id}, ${errors$1}`);
            }
          }
          const stepOutputs = {};
          const tmpDirs = new Array();
          await action.handler({
            baseUrl: task.spec.baseUrl,
            logger: taskLogger,
            logStream: stream$1,
            input,
            token: (_b = task.secrets) == null ? void 0 : _b.token,
            workspacePath,
            async createTemporaryDirectory() {
              const tmpDir = await fs__default['default'].mkdtemp(`${workspacePath}_step-${step.id}-`);
              tmpDirs.push(tmpDir);
              return tmpDir;
            },
            output(name, value) {
              stepOutputs[name] = value;
            }
          });
          for (const tmpDir of tmpDirs) {
            await fs__default['default'].remove(tmpDir);
          }
          templateCtx.steps[step.id] = {output: stepOutputs};
          await task.emitLog(`Finished step ${step.name}`, {
            ...metadata,
            status: "completed"
          });
        } catch (error) {
          await task.emitLog(String(error.stack), {
            ...metadata,
            status: "failed"
          });
          throw error;
        }
      }
      const output = JSON.parse(JSON.stringify(task.spec.output), (_key, value) => {
        if (typeof value === "string") {
          return this.handlebars.compile(value, {
            noEscape: true,
            strict: true,
            data: false,
            preventIndent: true
          })(templateCtx);
        }
        return value;
      });
      await task.complete("completed", {output});
    } catch (error) {
      await task.complete("failed", {
        error: {name: error.name, message: error.message}
      });
    } finally {
      if (workspacePath) {
        await fs__default['default'].remove(workspacePath);
      }
    }
  }
}

function templateEntityToSpec(template, inputValues) {
  const steps = [];
  const {protocol, location} = parseLocationAnnotation(template);
  let url;
  if (protocol === "file") {
    const path$1 = path.resolve(path.dirname(location), template.spec.path || ".");
    url = `file://${path$1}`;
  } else {
    url = joinGitUrlPath(location, template.spec.path);
  }
  const templater = getTemplaterKey(template);
  const values = {
    ...inputValues,
    destination: {
      git: parseGitUrl__default['default'](inputValues.storePath)
    }
  };
  steps.push({
    id: "prepare",
    name: "Prepare",
    action: "legacy:prepare",
    input: {
      protocol,
      url
    }
  });
  steps.push({
    id: "template",
    name: "Template",
    action: "legacy:template",
    input: {
      templater,
      values
    }
  });
  steps.push({
    id: "publish",
    name: "Publish",
    action: "legacy:publish",
    input: {
      values
    }
  });
  steps.push({
    id: "register",
    name: "Register",
    action: "catalog:register",
    input: {
      catalogInfoUrl: "{{ steps.publish.output.catalogInfoUrl }}"
    }
  });
  return {
    baseUrl: void 0,
    values: {},
    steps,
    output: {
      remoteUrl: "{{ steps.publish.output.remoteUrl }}",
      catalogInfoUrl: "{{ steps.register.output.catalogInfoUrl }}",
      entityRef: "{{ steps.register.output.entityRef }}"
    }
  };
}

async function getWorkingDirectory(config, logger) {
  if (!config.has("backend.workingDirectory")) {
    return os__default['default'].tmpdir();
  }
  const workingDirectory = config.getString("backend.workingDirectory");
  try {
    await fs__default['default'].access(workingDirectory, fs__default['default'].constants.F_OK | fs__default['default'].constants.W_OK);
    logger.info(`using working directory: ${workingDirectory}`);
  } catch (err) {
    logger.error(`working directory ${workingDirectory} ${err.code === "ENOENT" ? "does not exist" : "is not writable"}`);
    throw err;
  }
  return workingDirectory;
}
function getEntityBaseUrl(entity) {
  var _a, _b;
  let location = (_a = entity.metadata.annotations) == null ? void 0 : _a[catalogModel.SOURCE_LOCATION_ANNOTATION];
  if (!location) {
    location = (_b = entity.metadata.annotations) == null ? void 0 : _b[catalogModel.LOCATION_ANNOTATION];
  }
  if (!location) {
    return void 0;
  }
  const {type, target} = catalogModel.parseLocationReference(location);
  if (type === "url") {
    return target;
  } else if (type === "file") {
    return `file://${target}`;
  }
  return void 0;
}

function isAlpha1Template(entity) {
  return entity.apiVersion === "backstage.io/v1alpha1" || entity.apiVersion === "backstage.io/v1beta1";
}
function isBeta2Template(entity) {
  return entity.apiVersion === "backstage.io/v1beta2";
}
async function createRouter(options) {
  const router = Router__default['default']();
  router.use(express__default['default'].json());
  const {
    preparers,
    templaters,
    publishers,
    logger: parentLogger,
    config,
    reader,
    database,
    catalogClient,
    actions,
    taskWorkers
  } = options;
  const logger = parentLogger.child({plugin: "scaffolder"});
  const workingDirectory = await getWorkingDirectory(config, logger);
  const entityClient = new CatalogEntityClient(catalogClient);
  const integrations = integration.ScmIntegrations.fromConfig(config);
  const databaseTaskStore = await DatabaseTaskStore.create(await database.getClient());
  const taskBroker = new StorageTaskBroker(databaseTaskStore, logger);
  const actionRegistry = new TemplateActionRegistry();
  const workers = [];
  for (let i = 0; i < (taskWorkers || 1); i++) {
    const worker = new TaskWorker({
      logger,
      taskBroker,
      actionRegistry,
      workingDirectory
    });
    workers.push(worker);
  }
  const actionsToRegister = Array.isArray(actions) ? actions : [
    ...createLegacyActions({
      preparers,
      publishers,
      templaters
    }),
    ...createBuiltinActions({
      integrations,
      catalogClient,
      templaters,
      reader
    })
  ];
  actionsToRegister.forEach((action) => actionRegistry.register(action));
  workers.forEach((worker) => worker.start());
  router.get("/v2/templates/:namespace/:kind/:name/parameter-schema", async (req, res) => {
    var _a, _b, _c;
    const {namespace, kind, name} = req.params;
    if (namespace !== "default") {
      throw new errors.InputError(`Invalid namespace, only 'default' namespace is supported`);
    }
    if (kind.toLowerCase() !== "template") {
      throw new errors.InputError(`Invalid kind, only 'Template' kind is supported`);
    }
    const template = await entityClient.findTemplate(name, {
      token: getBearerToken(req.headers.authorization)
    });
    if (isBeta2Template(template)) {
      const parameters = [(_a = template.spec.parameters) != null ? _a : []].flat();
      res.json({
        title: (_b = template.metadata.title) != null ? _b : template.metadata.name,
        steps: parameters.map((schema) => {
          var _a2;
          return {
            title: (_a2 = schema.title) != null ? _a2 : "Fill in template parameters",
            schema
          };
        })
      });
    } else if (isAlpha1Template(template)) {
      res.json({
        title: (_c = template.metadata.title) != null ? _c : template.metadata.name,
        steps: [
          {
            title: "Fill in template parameters",
            schema: template.spec.schema
          },
          {
            title: "Choose owner and repo",
            schema: {
              type: "object",
              required: ["storePath", "owner"],
              properties: {
                owner: {
                  type: "string",
                  title: "Owner",
                  description: "Who is going to own this component"
                },
                storePath: {
                  type: "string",
                  title: "Store path",
                  description: "A full URL to the repository that should be created. e.g https://github.com/backstage/new-repo"
                },
                access: {
                  type: "string",
                  title: "Access",
                  description: "Who should have access, in org/team or user format"
                }
              }
            }
          }
        ]
      });
    } else {
      throw new errors.InputError(`Unsupported apiVersion field in schema entity, ${template.apiVersion}`);
    }
  }).get("/v2/actions", async (_req, res) => {
    const actionsList = actionRegistry.list().map((action) => {
      return {
        id: action.id,
        description: action.description,
        schema: action.schema
      };
    });
    res.json(actionsList);
  }).post("/v2/tasks", async (req, res) => {
    var _a, _b;
    const templateName = req.body.templateName;
    const values = req.body.values;
    const token = getBearerToken(req.headers.authorization);
    const template = await entityClient.findTemplate(templateName, {
      token
    });
    let taskSpec;
    if (isAlpha1Template(template)) {
      logger.warn(`[DEPRECATION] - Template: ${template.metadata.name} has version ${template.apiVersion} which is going to be deprecated. Please refer to https://backstage.io/docs/features/software-templates/migrating-from-v1alpha1-to-v1beta2 for help on migrating`);
      const result2 = jsonschema.validate(values, template.spec.schema);
      if (!result2.valid) {
        res.status(400).json({errors: result2.errors});
        return;
      }
      taskSpec = templateEntityToSpec(template, values);
    } else if (isBeta2Template(template)) {
      for (const parameters of [(_a = template.spec.parameters) != null ? _a : []].flat()) {
        const result2 = jsonschema.validate(values, parameters);
        if (!result2.valid) {
          res.status(400).json({errors: result2.errors});
          return;
        }
      }
      const baseUrl = getEntityBaseUrl(template);
      taskSpec = {
        baseUrl,
        values,
        steps: template.spec.steps.map((step, index) => {
          var _a2, _b2;
          return {
            ...step,
            id: (_a2 = step.id) != null ? _a2 : `step-${index + 1}`,
            name: (_b2 = step.name) != null ? _b2 : step.action
          };
        }),
        output: (_b = template.spec.output) != null ? _b : {}
      };
    } else {
      throw new errors.InputError(`Unsupported apiVersion field in schema entity, ${template.apiVersion}`);
    }
    const result = await taskBroker.dispatch(taskSpec, {
      token
    });
    res.status(201).json({id: result.taskId});
  }).get("/v2/tasks/:taskId", async (req, res) => {
    const {taskId} = req.params;
    const task = await taskBroker.get(taskId);
    if (!task) {
      throw new errors.NotFoundError(`Task with id ${taskId} does not exist`);
    }
    delete task.secrets;
    res.status(200).json(task);
  }).get("/v2/tasks/:taskId/eventstream", async (req, res) => {
    const {taskId} = req.params;
    const after = Number(req.query.after) || void 0;
    logger.debug(`Event stream observing taskId '${taskId}' opened`);
    res.writeHead(200, {
      Connection: "keep-alive",
      "Cache-Control": "no-cache",
      "Content-Type": "text/event-stream"
    });
    const unsubscribe = taskBroker.observe({taskId, after}, (error, {events}) => {
      if (error) {
        logger.error(`Received error from event stream when observing taskId '${taskId}', ${error}`);
      }
      for (const event of events) {
        res.write(`event: ${event.type}
data: ${JSON.stringify(event)}

`);
        if (event.type === "completion") {
          unsubscribe();
        }
      }
      res.flush();
    });
    req.on("close", () => {
      unsubscribe();
      logger.debug(`Event stream observing taskId '${taskId}' closed`);
    });
  });
  const app = express__default['default']();
  app.set("logger", logger);
  app.use("/", router);
  return app;
}
function getBearerToken(header) {
  var _a;
  return (_a = header == null ? void 0 : header.match(/Bearer\s+(\S+)/i)) == null ? void 0 : _a[1];
}

exports.AzurePreparer = AzurePreparer;
exports.AzurePublisher = AzurePublisher;
exports.BitbucketPreparer = BitbucketPreparer;
exports.BitbucketPublisher = BitbucketPublisher;
exports.CatalogEntityClient = CatalogEntityClient;
exports.CookieCutter = CookieCutter;
exports.CreateReactAppTemplater = CreateReactAppTemplater;
exports.FilePreparer = FilePreparer;
exports.GithubPreparer = GithubPreparer;
exports.GithubPublisher = GithubPublisher;
exports.GitlabPreparer = GitlabPreparer;
exports.GitlabPublisher = GitlabPublisher;
exports.JobProcessor = JobProcessor;
exports.Preparers = Preparers;
exports.Publishers = Publishers;
exports.TemplateActionRegistry = TemplateActionRegistry;
exports.Templaters = Templaters;
exports.createBuiltinActions = createBuiltinActions;
exports.createCatalogRegisterAction = createCatalogRegisterAction;
exports.createFetchCookiecutterAction = createFetchCookiecutterAction;
exports.createFetchPlainAction = createFetchPlainAction;
exports.createLegacyActions = createLegacyActions;
exports.createPublishAzureAction = createPublishAzureAction;
exports.createPublishBitbucketAction = createPublishBitbucketAction;
exports.createPublishFileAction = createPublishFileAction;
exports.createPublishGithubAction = createPublishGithubAction;
exports.createPublishGithubPullRequestAction = createPublishGithubPullRequestAction;
exports.createPublishGitlabAction = createPublishGitlabAction;
exports.createRouter = createRouter;
exports.createTemplateAction = createTemplateAction;
exports.getTemplaterKey = getTemplaterKey;
exports.joinGitUrlPath = joinGitUrlPath;
exports.parseLocationAnnotation = parseLocationAnnotation;
exports.runCommand = runCommand;
//# sourceMappingURL=index.cjs.js.map
